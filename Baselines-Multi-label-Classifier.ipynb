{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-trained Image Transformer",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/Bio-VI-BERT/blob/main/Baselines-Multi-label-Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "399tkRUuCe_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f26b304-d4f1-4e66-c093-45c9e3f423bb"
      },
      "source": [
        "!pip install git+https://github.com/rwightman/pytorch-image-models.git -q\n",
        "!pip install pytorch-lightning -q\n",
        "!git clone https://github.com/1Konny/gradcam_plus_plus-pytorch\n",
        "!cp /content/gradcam_plus_plus-pytorch/*.py ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for timm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 849kB 10.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 829kB 18.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 37.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 40.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3MB 44.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 41.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 42.4MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'gradcam_plus_plus-pytorch'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Total 79 (delta 0), reused 0 (delta 0), pack-reused 79\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVjc4Kju84S5",
        "outputId": "0033afb3-5123-48f9-c402-9524036cca87"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AmbiTyga/Bio-VI-BERT/main/Train.7z\n",
        "!7z x /content/Train.7z"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 09:58:32--  https://raw.githubusercontent.com/AmbiTyga/Bio-VI-BERT/main/Train.7z\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13524763 (13M) [application/octet-stream]\n",
            "Saving to: ‘Train.7z’\n",
            "\n",
            "Train.7z            100%[===================>]  12.90M  83.7MB/s    in 0.2s    \n",
            "\n",
            "2021-04-29 09:58:33 (83.7 MB/s) - ‘Train.7z’ saved [13524763/13524763]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 13524763 bytes (13 MiB)\n",
            "\n",
            "Extracting archive: /content/Train.7z\n",
            "--\n",
            "Path = /content/Train.7z\n",
            "Type = 7z\n",
            "Physical Size = 13524763\n",
            "Headers Size = 13084\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 22% 17\b\b\b\b\b\b\b       \b\b\b\b\b\b\b 44% 377 - train/Dibothriocephalus latus/Diph_egg_2_0_99.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 771 - train/Hymenolepis spp/H_nana_egg_wtmt4_4_193.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 1262 - train/Plasmodium vivax/Pv_troph_thinE_0_309.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 17\n",
            "Files: 1451\n",
            "Size:       15238342\n",
            "Compressed: 13524763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K3nmmNSCsza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5860006-00b8-49b8-9403-cbc315f0680e"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AmbiTyga/Bio-VI-BERT/main/Val.7z\n",
        "!7z x /content/Val.7z"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 09:58:34--  https://raw.githubusercontent.com/AmbiTyga/Bio-VI-BERT/main/Val.7z\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4593856 (4.4M) [application/octet-stream]\n",
            "Saving to: ‘Val.7z’\n",
            "\n",
            "Val.7z              100%[===================>]   4.38M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-04-29 09:58:35 (54.0 MB/s) - ‘Val.7z’ saved [4593856/4593856]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 4593856 bytes (4487 KiB)\n",
            "\n",
            "Extracting archive: /content/Val.7z\n",
            "--\n",
            "Path = /content/Val.7z\n",
            "Type = 7z\n",
            "Physical Size = 4593856\n",
            "Headers Size = 5093\n",
            "Method = LZMA2:6m\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 67% 17\b\b\b\b\b\b\b       \b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 17\n",
            "Files: 486\n",
            "Size:       5092491\n",
            "Compressed: 4593856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVc3_O_n_In6"
      },
      "source": [
        "import timm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, sampler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAHwzGXx_7y-"
      },
      "source": [
        "## Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aObD7UFjoJZR"
      },
      "source": [
        "from glob import glob\n",
        "images = [x for x in glob('./val/*/*') if 'val.csv' not in x]\n",
        "for i in images:\n",
        "  Image.open(i).convert('RGB').save(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H1f9w06nA78"
      },
      "source": [
        "train = pd.read_csv('/content/train/train.csv')\n",
        "val = pd.read_csv('/content/val/val.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvqUZNOLVljR"
      },
      "source": [
        "le = LabelEncoder()\n",
        "train['class_label'] = le.fit_transform(train['class'])\n",
        "val['class_label'] = le.transform(val['class'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK7xudnEBvy7"
      },
      "source": [
        "train_transformer = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "val_transformer = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "#         transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt18u1gBEWp1"
      },
      "source": [
        "class SpeciesDataset(Dataset):\n",
        "  def __init__(self,csv_file,transform):\n",
        "    super().__init__()\n",
        "    csv = csv_file[['class_label','img_path']]\n",
        "    self.labels = csv['class_label'].values\n",
        "\n",
        "    self.images = csv['img_path'].values\n",
        "    self.transform = transform\n",
        "\n",
        "    # self.LE = LabelEncoder()\n",
        "    # self.labels = self.LE.fit_transform(labels)    \n",
        "\n",
        "  def __len__(self):\n",
        "    # return size of dataset\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.images[index])\n",
        "    img = self.transform(img)\n",
        "\n",
        "    label = self.labels[index]\n",
        "\n",
        "    return {'images':img, 'labels':label}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhx14nCACBna"
      },
      "source": [
        "\n",
        "class_counts = train['class_label'].value_counts().to_dict()\n",
        "train_weights = torch.tensor([1/class_counts[label] for label in train['class_label'].values])\n",
        "\n",
        "train_dataset = SpeciesDataset(train,transform=train_transformer)\n",
        "\n",
        "class_counts = val['class_label'].value_counts().to_dict()\n",
        "val_weights = torch.tensor([1/class_counts[label] for label in val['class_label'].values])\n",
        "\n",
        "val_dataset = SpeciesDataset(val,transform=val_transformer)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUTjB9FsCQ2D"
      },
      "source": [
        "class ResNet200d(pl.LightningModule):\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_classes_classifier,\n",
        "      train_weights,\n",
        "      val_weights,\n",
        "      train_dataset,\n",
        "      val_dataset):\n",
        "    super().__init__()\n",
        "\n",
        "    self.tw = train_weights\n",
        "    self.vw = val_weights\n",
        "\n",
        "    self.train_dataset = train_dataset\n",
        "    self.val_dataset = val_dataset\n",
        "\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    self.img_transformer = timm.models.resnet200d(pretrained=True,num_classes = num_classes_classifier)\n",
        "    \n",
        "  def forward(self,img):  \n",
        "    return self.img_transformer(img)\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=64,\n",
        "        sampler=torch.utils.data.WeightedRandomSampler(self.tw,num_samples=3360),\n",
        "        num_workers = os.cpu_count()\n",
        "        )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return torch.utils.data.DataLoader(\n",
        "        self.val_dataset,\n",
        "        batch_size = 51,\n",
        "        sampler = torch.utils.data.WeightedRandomSampler(self.vw,num_samples=1155),\n",
        "        num_workers = os.cpu_count()\n",
        "        )\n",
        "    \n",
        "  def training_step(self, batch ,batch_idx):\n",
        "    images = batch[\"images\"]\n",
        "    labels = batch['labels']\n",
        "    outputs = self(img=images)\n",
        "    loss = self.loss_fn(outputs,labels)\n",
        "    acc = (outputs.argmax(dim=1).view(labels.size()).data == labels.data).sum()/labels.size(0)\n",
        "    \n",
        "    # self.log(\"loss\",loss,prog_bar=True)\n",
        "    self.log(\"accuracy\",acc,prog_bar=True)\n",
        "    return {\"loss\": loss,'accuracy':acc}\n",
        "\n",
        "  def validation_step(self, batch ,batch_idx):\n",
        "    images = batch[\"images\"]\n",
        "    labels = batch['labels']\n",
        "    outputs = self(img=images)\n",
        "    loss = self.loss_fn(outputs,labels)\n",
        "    acc = (outputs.argmax(dim=1).view(labels.size()).data == labels.data).sum()/labels.size(0)\n",
        "    \n",
        "    return {\"val_loss\": loss.item(),'val_accuracy':acc.item()}\n",
        "  \n",
        "  def validation_epoch_end(self, outputs):\n",
        "    avg_loss = torch.tensor(\n",
        "            [output[\"val_loss\"] \n",
        "            for output in outputs]\n",
        "            ).mean()\n",
        "    avg_acc = torch.tensor(\n",
        "            [output[\"val_accuracy\"] \n",
        "            for output in outputs]\n",
        "            ).mean()\n",
        "    \n",
        "    self.log(\"val_loss\",avg_loss,prog_bar=True)\n",
        "    self.log(\"val_accuracy\",avg_acc,prog_bar=True)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = [torch.optim.AdamW(\n",
        "            self.parameters(), \n",
        "            lr=1e-4\n",
        "        )]\n",
        "    return optimizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw-DWrN4CtM3",
        "outputId": "5b6beb34-1bcd-4bf2-fbed-0f7b018ccad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = ResNet200d(\n",
        "    num_classes_classifier=7,\n",
        "    train_weights=train_weights,\n",
        "    val_weights=val_weights,\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset\n",
        "    )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet200d_ra2-bdba9bf9.pth\" to /root/.cache/torch/hub/checkpoints/resnet200d_ra2-bdba9bf9.pth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAgh8b0qEguc",
        "outputId": "bad4f628-ad5c-4d61-d379-79041009038a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 29 09:59:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    59W / 149W |  11164MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNWvQ51bCyqY"
      },
      "source": [
        "early_stop_callback = EarlyStopping(\n",
        "   monitor='val_accuracy',\n",
        "   min_delta=0.00,\n",
        "   patience=20,\n",
        "   verbose=False,\n",
        "   mode='max'\n",
        ")\n",
        "\n",
        "model_ckpt = ModelCheckpoint(\n",
        "    monitor='val_accuracy',\n",
        "    dirpath='./',\n",
        "    filename='resnet-{val-loss:.2f}-{val_accuracy:.2f}',\n",
        "    mode='max')\n",
        "\n",
        "trainer = pl.Trainer(gpus=1,max_epochs=120,accumulate_grad_batches=2,num_sanity_val_steps=2,callbacks=[early_stop_callback,model_ckpt])\n",
        "trainer.fit(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nslJ7NsdDFar"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "val_dataset = SpeciesDataset(val,transform=val_transformer)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=51)\n",
        "\n",
        "model = ResNet200d.load_from_checkpoint(\"/content/*.ckpt\",num_classes_classifier=7,\n",
        "    train_weights=None,\n",
        "    val_weights=None,\n",
        "    train_dataset=None,\n",
        "    val_dataset=None\n",
        "    )\n",
        "model.cuda()\n",
        "model.eval()\n",
        "preds = np.array([])\n",
        "label = np.array([])\n",
        "with torch.no_grad():\n",
        "  for batch in val_loader:\n",
        "    images = batch[\"images\"].cuda()\n",
        "    labels = batch['labels']\n",
        "    label = np.append(label,labels)\n",
        "    prediction = model(images)\n",
        "    preds = np.append(preds,prediction.argmax(dim=1).view(labels.size()).cpu().numpy())\n",
        "\n",
        "\n",
        "print(classification_report(label,preds,target_names=le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBs9fFF5DOL2"
      },
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "confusion = confusion_matrix(label,preds)\n",
        "df_cm = pd.DataFrame(confusion, index = le.classes_,\n",
        "                  columns = le.classes_)\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CKq8rvDDl5R"
      },
      "source": [
        "from utils import visualize_cam, Normalize\n",
        "from gradcam import GradCAM, GradCAMpp\n",
        "resnet_model_dict = dict(type='resnet', arch=resnet, layer_name='layer4', input_size=(224, 224))\n",
        "resnet_gradcam = GradCAM(resnet_model_dict, True)\n",
        "resnet_gradcampp = GradCAMpp(resnet_model_dict, True)\n",
        "\n",
        "mask_pp, _ = resnet_gradcampp(img_tensor,class_index = _)\n",
        "heatmap_pp, result_pp = visualize_cam(mask_pp.cpu(), torch_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}