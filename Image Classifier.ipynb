{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/Bio-VI-BERT/blob/main/Image%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_baimJsBy1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952dbd20-270b-4326-fe3e-62238260ba03"
      },
      "source": [
        "!7z x /content/Dataset.7z"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 17231696 bytes (17 MiB)\n",
            "\n",
            "Extracting archive: /content/Dataset.7z\n",
            "--\n",
            "Path = /content/Dataset.7z\n",
            "Type = 7z\n",
            "Physical Size = 17231696\n",
            "Headers Size = 6422\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 18% 23 - Dataset/all_meta_data.csv\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 144 - Dataset/Dibothriocephalus/Diphyllobothrium_tissue_WA_500x2.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 252 - Dataset/Giardia/Giardia_cyst_tric6.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 355 - Dataset/Plasmodium/Pm_gametocyte_thinB.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 461 - Dataset/Strongyloides/S_stercoralis_adult_larva_BAM1.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 23\n",
            "Files: 528\n",
            "Size:       21325876\n",
            "Compressed: 17231696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJZGjtWHewjj"
      },
      "source": [
        "# Installing and Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyzxsYmKgAO"
      },
      "source": [
        "!pip install einops -q\r\n",
        "!pip install tez -q\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "import pandas as pd\r\n",
        "import PIL\r\n",
        "from PIL import Image\r\n",
        "import time\r\n",
        "import torch\r\n",
        "from torchvision import transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "from einops import rearrange\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\r\n",
        "import torchvision.models as models\r\n",
        "import tez\r\n",
        "from tez.callbacks import Callback, CallbackRunner\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSfgsoF0fH-m"
      },
      "source": [
        "# Vision Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce_ZFu3cCmT6"
      },
      "source": [
        "class Residual(nn.Module):\r\n",
        "    def __init__(self, fn):\r\n",
        "        super().__init__()\r\n",
        "        self.fn = fn\r\n",
        "    def forward(self, x, **kwargs):\r\n",
        "        return self.fn(x, **kwargs) + x\r\n",
        "\r\n",
        "class LayerNormalize(nn.Module):\r\n",
        "    def __init__(self, dim, fn):\r\n",
        "        super().__init__()\r\n",
        "        self.norm = nn.LayerNorm(dim)\r\n",
        "        self.fn = fn\r\n",
        "    def forward(self, x, **kwargs):\r\n",
        "        return self.fn(self.norm(x), **kwargs)\r\n",
        "\r\n",
        "class MLP_Block(nn.Module):\r\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.1):\r\n",
        "        super().__init__()\r\n",
        "        self.nn1 = nn.Linear(dim, hidden_dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "        torch.nn.init.normal_(self.nn1.bias, std = 1e-6)\r\n",
        "        self.af1 = nn.GELU()\r\n",
        "        self.do1 = nn.Dropout(dropout)\r\n",
        "        self.nn2 = nn.Linear(hidden_dim, dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn2.weight)\r\n",
        "        torch.nn.init.normal_(self.nn2.bias, std = 1e-6)\r\n",
        "        self.do2 = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.nn1(x)\r\n",
        "        x = self.af1(x)\r\n",
        "        x = self.do1(x)\r\n",
        "        x = self.nn2(x)\r\n",
        "        x = self.do2(x)\r\n",
        "        \r\n",
        "        return x\r\n",
        "\r\n",
        "class Attention(nn.Module):\r\n",
        "    def __init__(self, dim, heads = 8, dropout = 0.1):\r\n",
        "        super().__init__()\r\n",
        "        self.heads = heads\r\n",
        "        self.scale = dim ** -0.5  # 1/sqrt(dim)\r\n",
        "\r\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias = True) # Wq,Wk,Wv for each vector, thats why *3\r\n",
        "        torch.nn.init.xavier_uniform_(self.to_qkv.weight)\r\n",
        "        torch.nn.init.zeros_(self.to_qkv.bias)\r\n",
        "        \r\n",
        "        self.nn1 = nn.Linear(dim, dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "        torch.nn.init.zeros_(self.nn1.bias)        \r\n",
        "        self.do1 = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x, mask = None):\r\n",
        "        b, n, _, h = *x.shape, self.heads\r\n",
        "        qkv = self.to_qkv(x) #gets q = Q = Wq matmul x1, k = Wk mm x2, v = Wv mm x3\r\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv = 3, h = h) # split into multi head attentions\r\n",
        "\r\n",
        "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\r\n",
        "\r\n",
        "        if mask is not None:\r\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\r\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\r\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\r\n",
        "            dots.masked_fill_(~mask, float('-inf'))\r\n",
        "            del mask\r\n",
        "\r\n",
        "        attn = dots.softmax(dim=-1) #follow the softmax,q,d,v equation in the paper\r\n",
        "\r\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v) #product of v times whatever inside softmax\r\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)') #concat heads into one matrix, ready for next encoder block\r\n",
        "        out =  self.nn1(out)\r\n",
        "        out = self.do1(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(self, dim, depth, heads, mlp_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        self.layers = nn.ModuleList([])\r\n",
        "        for _ in range(depth):\r\n",
        "            self.layers.append(nn.ModuleList([\r\n",
        "                Residual(LayerNormalize(dim, Attention(dim, heads = heads, dropout = dropout))),\r\n",
        "                Residual(LayerNormalize(dim, MLP_Block(dim, mlp_dim, dropout = dropout)))\r\n",
        "            ]))\r\n",
        "    def forward(self, x, mask = None):\r\n",
        "        for attention, mlp in self.layers:\r\n",
        "            x = attention(x, mask = mask) # go to attention\r\n",
        "            x = mlp(x) #go to MLP_Block\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class ViT(tez.Model):\r\n",
        "  def __init__(self,*, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dropout = 0.1, emb_dropout = 0.1):\r\n",
        "    super().__init__()\r\n",
        "    assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\r\n",
        "    num_patches = (image_size // patch_size) ** 2  # e.g. (32/4)**2= 64\r\n",
        "    patch_dim = channels * patch_size ** 2  # e.g. 3*8**2 = 64*3\r\n",
        "\r\n",
        "    self.patch_size = patch_size\r\n",
        "    self.pos_embedding = nn.Parameter(torch.empty(1, (num_patches + 1), dim))\r\n",
        "    torch.nn.init.normal_(self.pos_embedding, std = .02) # initialized based on the paper\r\n",
        "    self.patch_conv= nn.Conv2d(3,dim, patch_size, stride = patch_size) #eqivalent to x matmul E, E= embedd matrix, this is the linear patch projection\r\n",
        "    \r\n",
        "    self.cls_token = nn.Parameter(torch.zeros(1, 1, dim)) #initialized based on the paper\r\n",
        "    self.dropout = nn.Dropout(emb_dropout)\r\n",
        "\r\n",
        "    self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)\r\n",
        "\r\n",
        "    self.to_cls_token = nn.Identity()\r\n",
        "\r\n",
        "    self.nn1 = nn.Linear(dim, num_classes)  # if finetuning, just use a linear layer without further hidden layers (paper)\r\n",
        "    torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "    torch.nn.init.normal_(self.nn1.bias, std = 1e-6)\r\n",
        "    \r\n",
        "  def monitor_metrics(self, outputs, targets):\r\n",
        "    outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\r\n",
        "    targets = targets.cpu().detach().numpy()\r\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\r\n",
        "    precision = metrics.precision_score(targets, outputs,average='weighted')\r\n",
        "    recall = metrics.recall_score(targets, outputs,average='weighted')\r\n",
        "    f1 = metrics.f1_score(targets, outputs,average='weighted')\r\n",
        "    return {\"accuracy\": accuracy,\r\n",
        "            \"precision\":precision,\r\n",
        "            \"recall\":recall,\r\n",
        "            \"f1\":f1}\r\n",
        "  def fetch_optimizer(self):\r\n",
        "    opt = torch.optim.Adam(self.parameters(), lr=1e-3)\r\n",
        "    return opt\r\n",
        "\r\n",
        "  def forward(self, img,targets, mask = None):\r\n",
        "    p = self.patch_size\r\n",
        "\r\n",
        "    x = self.patch_conv(img) # each of 64 vecotrs is linearly transformed with a FFN equiv to E matmul\r\n",
        "    #x = torch.matmul(x, self.E)\r\n",
        "    x = rearrange(x, 'b c h w -> b (h w) c') # 64 vectors in rows representing 64 patches, each 64*3 long\r\n",
        "\r\n",
        "    cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\r\n",
        "    x = torch.cat((cls_tokens, x), dim=1)\r\n",
        "    x += self.pos_embedding\r\n",
        "    x = self.dropout(x)\r\n",
        "\r\n",
        "    x = self.transformer(x, mask) #main game\r\n",
        "\r\n",
        "    x = self.to_cls_token(x[:, 0])\r\n",
        "    \r\n",
        "    outputs = self.nn1(x)\r\n",
        "    \r\n",
        "    if targets is not None:\r\n",
        "      loss = nn.CrossEntropyLoss()(outputs, targets)\r\n",
        "      metrics = self.monitor_metrics(outputs, targets)\r\n",
        "      return outputs, loss, metrics\r\n",
        "    return outputs, 0, {}\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2bC1ymaGnks"
      },
      "source": [
        "## Training VBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUCyR0pxG4kl"
      },
      "source": [
        "class CIFAR(torchvision.datasets.CIFAR10):\r\n",
        "  def __init__(self, path, transform, train=True,download=True):\r\n",
        "      super().__init__(path, train, download=True)\r\n",
        "      self.transforms = transform\r\n",
        "  def __getitem__(self, index):\r\n",
        "      im, label = super().__getitem__(index)\r\n",
        "      return {'img':self.transforms(im),'targets':label}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jqi1TuAGpuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd28275e-6d5c-42ab-b119-a2fe5b02977c"
      },
      "source": [
        "BATCH_SIZE_TRAIN = 100\r\n",
        "BATCH_SIZE_TEST = 100\r\n",
        "\r\n",
        "DL_PATH = \"/content/CIFAR10_data\" # Use your own path\r\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\r\n",
        "transform = torchvision.transforms.Compose(\r\n",
        "     [torchvision.transforms.RandomHorizontalFlip(),\r\n",
        "     torchvision.transforms.RandomRotation(10, resample=PIL.Image.BILINEAR),\r\n",
        "     torchvision.transforms.RandomAffine(8, translate=(.15,.15)),\r\n",
        "     torchvision.transforms.ToTensor(),\r\n",
        "     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\r\n",
        "\r\n",
        "\r\n",
        "train_dataset = CIFAR(DL_PATH, train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "\r\n",
        "test_dataset = CIFAR(DL_PATH, train=False,\r\n",
        "                                       download=True, transform=transform)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZC3V59yAqCt",
        "outputId": "b8f8dd0b-716f-4a2e-ff5a-fe8b2088f576"
      },
      "source": [
        "model = ViT(image_size=32, patch_size=4, num_classes=10, channels=3,\r\n",
        "            dim=64, depth=6, heads=8, mlp_dim=128)\r\n",
        "es = tez.callbacks.EarlyStopping(monitor=\"valid_loss\", model_path=\"ViT-CIFAR10.bin\")\r\n",
        "model.fit(\r\n",
        "        train_dataset,\r\n",
        "        valid_dataset=test_dataset,\r\n",
        "        train_bs=100,\r\n",
        "        device=\"cuda\",\r\n",
        "        epochs=150,\r\n",
        "        callbacks=[es],\r\n",
        "        fp16=True,\r\n",
        "    )\r\n",
        "torch.save(model.state_dict(), '/content/ViT-CIFAR10-final.bin')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/500 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 500/500 [00:32<00:00, 15.20it/s, accuracy=0.28, f1=0.264, loss=1.99, precision=0.302, recall=0.28, stage=train]\n",
            "  0%|          | 0/625 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.47it/s, accuracy=0.365, f1=0.349, loss=1.73, precision=0.402, recall=0.365, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (inf --> 1.7325006895065307). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 15.08it/s, accuracy=0.376, f1=0.363, loss=1.67, precision=0.413, recall=0.376, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 53.06it/s, accuracy=0.437, f1=0.425, loss=1.52, precision=0.491, recall=0.437, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.7325006895065307 --> 1.519312686252594). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.443, f1=0.435, loss=1.52, precision=0.479, recall=0.443, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.22it/s, accuracy=0.489, f1=0.478, loss=1.41, precision=0.546, recall=0.489, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.519312686252594 --> 1.4115574386596679). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:32<00:00, 15.19it/s, accuracy=0.481, f1=0.473, loss=1.42, precision=0.515, recall=0.481, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.65it/s, accuracy=0.511, f1=0.5, loss=1.35, precision=0.566, recall=0.511, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.4115574386596679 --> 1.3535720553398132). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.97it/s, accuracy=0.509, f1=0.503, loss=1.35, precision=0.543, recall=0.509, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.64it/s, accuracy=0.552, f1=0.542, loss=1.26, precision=0.603, recall=0.552, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.3535720553398132 --> 1.2606240270614624). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.91it/s, accuracy=0.535, f1=0.53, loss=1.28, precision=0.568, recall=0.535, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.25it/s, accuracy=0.554, f1=0.543, loss=1.24, precision=0.608, recall=0.554, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.2606240270614624 --> 1.2362172849178314). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 15.10it/s, accuracy=0.552, f1=0.547, loss=1.24, precision=0.585, recall=0.552, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.85it/s, accuracy=0.579, f1=0.577, loss=1.17, precision=0.647, recall=0.579, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.2362172849178314 --> 1.1709228728294372). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 15.07it/s, accuracy=0.572, f1=0.568, loss=1.19, precision=0.604, recall=0.572, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 52.00it/s, accuracy=0.568, f1=0.559, loss=1.21, precision=0.63, recall=0.568, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.585, f1=0.58, loss=1.15, precision=0.615, recall=0.585, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 52.01it/s, accuracy=0.606, f1=0.6, loss=1.11, precision=0.667, recall=0.606, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.1709228728294372 --> 1.1051185081481933). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.92it/s, accuracy=0.596, f1=0.593, loss=1.12, precision=0.627, recall=0.596, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.53it/s, accuracy=0.622, f1=0.615, loss=1.07, precision=0.678, recall=0.622, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.1051185081481933 --> 1.074740308904648). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.94it/s, accuracy=0.609, f1=0.605, loss=1.09, precision=0.638, recall=0.609, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.19it/s, accuracy=0.623, f1=0.622, loss=1.04, precision=0.693, recall=0.623, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.074740308904648 --> 1.0428570340633392). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.92it/s, accuracy=0.62, f1=0.617, loss=1.06, precision=0.65, recall=0.62, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.19it/s, accuracy=0.632, f1=0.621, loss=1.05, precision=0.68, recall=0.632, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.83it/s, accuracy=0.632, f1=0.629, loss=1.03, precision=0.661, recall=0.632, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.56it/s, accuracy=0.649, f1=0.644, loss=0.98, precision=0.708, recall=0.649, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (1.0428570340633392 --> 0.9803798525333405). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.99it/s, accuracy=0.642, f1=0.64, loss=1, precision=0.67, recall=0.642, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.50it/s, accuracy=0.646, f1=0.641, loss=1.01, precision=0.706, recall=0.646, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.88it/s, accuracy=0.646, f1=0.644, loss=0.992, precision=0.676, recall=0.646, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.24it/s, accuracy=0.657, f1=0.652, loss=0.964, precision=0.718, recall=0.657, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.9803798525333405 --> 0.9637532660484314). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 15.14it/s, accuracy=0.655, f1=0.653, loss=0.969, precision=0.682, recall=0.655, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.74it/s, accuracy=0.674, f1=0.671, loss=0.918, precision=0.735, recall=0.674, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.9637532660484314 --> 0.917978306889534). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.658, f1=0.656, loss=0.957, precision=0.685, recall=0.658, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.83it/s, accuracy=0.665, f1=0.658, loss=0.953, precision=0.722, recall=0.665, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.96it/s, accuracy=0.667, f1=0.665, loss=0.933, precision=0.693, recall=0.667, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.62it/s, accuracy=0.677, f1=0.673, loss=0.919, precision=0.734, recall=0.677, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 2 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.92it/s, accuracy=0.67, f1=0.668, loss=0.924, precision=0.697, recall=0.67, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.68it/s, accuracy=0.676, f1=0.669, loss=0.932, precision=0.729, recall=0.676, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 3 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.89it/s, accuracy=0.676, f1=0.675, loss=0.906, precision=0.703, recall=0.676, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.70it/s, accuracy=0.688, f1=0.685, loss=0.896, precision=0.746, recall=0.688, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.917978306889534 --> 0.8964451391220093). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.98it/s, accuracy=0.682, f1=0.68, loss=0.894, precision=0.708, recall=0.682, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.68it/s, accuracy=0.702, f1=0.697, loss=0.873, precision=0.756, recall=0.702, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8964451391220093 --> 0.8730661675214767). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.91it/s, accuracy=0.688, f1=0.687, loss=0.878, precision=0.713, recall=0.688, stage=train]\n",
            "100%|██████████| 625/625 [00:11<00:00, 52.22it/s, accuracy=0.683, f1=0.679, loss=0.908, precision=0.743, recall=0.683, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.87it/s, accuracy=0.689, f1=0.687, loss=0.873, precision=0.715, recall=0.689, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.00it/s, accuracy=0.691, f1=0.686, loss=0.878, precision=0.745, recall=0.691, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 2 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.67it/s, accuracy=0.695, f1=0.693, loss=0.857, precision=0.719, recall=0.695, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.37it/s, accuracy=0.695, f1=0.691, loss=0.876, precision=0.754, recall=0.695, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 3 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.699, f1=0.697, loss=0.846, precision=0.723, recall=0.699, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.36it/s, accuracy=0.7, f1=0.695, loss=0.856, precision=0.754, recall=0.7, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8730661675214767 --> 0.8555283711194992). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.69it/s, accuracy=0.702, f1=0.7, loss=0.837, precision=0.725, recall=0.702, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.17it/s, accuracy=0.709, f1=0.707, loss=0.834, precision=0.767, recall=0.709, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8555283711194992 --> 0.8335060261487961). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.62it/s, accuracy=0.709, f1=0.708, loss=0.82, precision=0.733, recall=0.709, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.19it/s, accuracy=0.715, f1=0.712, loss=0.815, precision=0.772, recall=0.715, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8335060261487961 --> 0.8154819578886032). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.66it/s, accuracy=0.707, f1=0.706, loss=0.818, precision=0.732, recall=0.707, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 50.97it/s, accuracy=0.715, f1=0.714, loss=0.816, precision=0.773, recall=0.715, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.84it/s, accuracy=0.716, f1=0.715, loss=0.804, precision=0.74, recall=0.716, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 50.97it/s, accuracy=0.708, f1=0.703, loss=0.841, precision=0.762, recall=0.708, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 2 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.70it/s, accuracy=0.714, f1=0.714, loss=0.803, precision=0.74, recall=0.714, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.14it/s, accuracy=0.721, f1=0.717, loss=0.806, precision=0.774, recall=0.721, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8154819578886032 --> 0.8057922671556472). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.78it/s, accuracy=0.716, f1=0.715, loss=0.792, precision=0.741, recall=0.716, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 50.91it/s, accuracy=0.723, f1=0.723, loss=0.798, precision=0.783, recall=0.723, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.8057922671556472 --> 0.7984835857868194). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.71it/s, accuracy=0.718, f1=0.717, loss=0.788, precision=0.741, recall=0.718, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.31it/s, accuracy=0.728, f1=0.726, loss=0.797, precision=0.781, recall=0.728, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (0.7984835857868194 --> 0.7974020432710648). Saving model!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.69it/s, accuracy=0.723, f1=0.722, loss=0.779, precision=0.746, recall=0.723, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.31it/s, accuracy=0.712, f1=0.708, loss=0.831, precision=0.768, recall=0.712, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.66it/s, accuracy=0.726, f1=0.725, loss=0.77, precision=0.748, recall=0.726, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.93it/s, accuracy=0.719, f1=0.713, loss=0.814, precision=0.769, recall=0.719, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 2 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.55it/s, accuracy=0.729, f1=0.728, loss=0.765, precision=0.751, recall=0.729, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.98it/s, accuracy=0.716, f1=0.715, loss=0.822, precision=0.774, recall=0.716, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 3 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:33<00:00, 14.72it/s, accuracy=0.731, f1=0.73, loss=0.755, precision=0.753, recall=0.731, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 50.88it/s, accuracy=0.726, f1=0.719, loss=0.809, precision=0.774, recall=0.726, stage=valid]\n",
            "  0%|          | 0/500 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 4 out of 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:34<00:00, 14.67it/s, accuracy=0.732, f1=0.731, loss=0.753, precision=0.755, recall=0.732, stage=train]\n",
            "100%|██████████| 625/625 [00:12<00:00, 51.22it/s, accuracy=0.73, f1=0.726, loss=0.805, precision=0.782, recall=0.73, stage=valid]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 5 out of 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awFlWDFFOFc-"
      },
      "source": [
        "### Kaggle Dataset Downloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3taMWoR4Qk8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7615d10-d38c-4831-81da-24acd6c62525"
      },
      "source": [
        "!mkdir HPA\r\n",
        "! pip install -q kaggle\r\n",
        "from google.colab import files\r\n",
        "files.upload()\r\n",
        "! mkdir ~/.kaggle\r\n",
        "! cp kaggle.json ~/.kaggle/\r\n",
        "! chmod 600 ~/.kaggle/kaggle.json\r\n",
        "! kaggle competitions download -f train.csv hpa-single-cell-image-classification -p /content/HPA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv to /content/HPA\n",
            "\r  0% 0.00/872k [00:00<?, ?B/s]\n",
            "\r100% 872k/872k [00:00<00:00, 151MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjQHZj8y_WRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe047f83-fce3-4054-89ad-04401ed8b772"
      },
      "source": [
        "alpha = pd.read_csv(\"/content/HPA/train.csv\")\r\n",
        "alpha.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21806, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KidkJeaLFWoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed91ba2-c26f-4ea2-a8d2-4dc7cd3932ce"
      },
      "source": [
        "want = alpha.sample(frac=1/2.8)\r\n",
        "want.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7788, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lXupz4mF7ys"
      },
      "source": [
        "images_name = want['ID'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP2PoBjKDbeF"
      },
      "source": [
        "import os\r\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\r\n",
        "import pandas as pd\r\n",
        "api = KaggleApi()\r\n",
        "api.authenticate()\r\n",
        "for i in images_name:\r\n",
        "  if not os.path.exists(f'/content/HPA/{i}'):\r\n",
        "    os.mkdir(f'/content/HPA/{i}')\r\n",
        "    api.competition_download_file('hpa-single-cell-image-classification',\r\n",
        "                                  f'train/{i}_blue.png',\r\n",
        "                                  path = f'/content/HPA/{i}',\r\n",
        "                                  quiet = True,\r\n",
        "                                  force = True)\r\n",
        "    \r\n",
        "    api.competition_download_file('hpa-single-cell-image-classification',\r\n",
        "                                  f'train/{i}_red.png',\r\n",
        "                                  path = f'/content/HPA/{i}',\r\n",
        "                                  quiet = True,\r\n",
        "                                  force = True)\r\n",
        "    \r\n",
        "    api.competition_download_file('hpa-single-cell-image-classification',\r\n",
        "                                  f'train/{i}_green.png',\r\n",
        "                                  path = f'/content/HPA/{i}',\r\n",
        "                                  quiet = True,\r\n",
        "                                  force = True)\r\n",
        "    \r\n",
        "    api.competition_download_file('hpa-single-cell-image-classification',\r\n",
        "                                  f'train/{i}_yellow.png',\r\n",
        "                                  path = f'/content/HPA/{i}',\r\n",
        "                                  quiet = True,\r\n",
        "                                  force = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gG_0tWue05f"
      },
      "source": [
        "# Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtJ3g1lcVah5"
      },
      "source": [
        "## Getting images(file path) from the directories \r\n",
        "import os\r\n",
        "imgs = []\r\n",
        "for path, subdirs, files in os.walk('./Dataset'):\r\n",
        "    for name in files:\r\n",
        "        imgs.append(os.path.join(path, name))\r\n",
        "imgs = [x for x in imgs if '.jpg' in x]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1zUOBkABzv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "99415ab5-64a9-4d4b-eb63-a90bccda055a"
      },
      "source": [
        "data = pd.read_csv(\"/content/Dataset/all_meta_data.csv\")\r\n",
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phylum</th>\n",
              "      <th>class</th>\n",
              "      <th>genus</th>\n",
              "      <th>species</th>\n",
              "      <th>form</th>\n",
              "      <th>sample</th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_url</th>\n",
              "      <th>img_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_worm4_HB.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_worm4_HB.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_HBa.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_HBa.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_wtmt.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_wtmt.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_SC_egg.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_SC_egg.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_UVa.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_UVa.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     phylum  ...                                         img_path\n",
              "0  Nematoda  ...  ./Dataset/Enterobius/Evermicularis_worm4_HB.jpg\n",
              "1  Nematoda  ...   ./Dataset/Enterobius/Evermicularis_egg_HBa.jpg\n",
              "2  Nematoda  ...  ./Dataset/Enterobius/Evermicularis_egg_wtmt.jpg\n",
              "3  Nematoda  ...    ./Dataset/Enterobius/Evermicularis_SC_egg.jpg\n",
              "4  Nematoda  ...   ./Dataset/Enterobius/Evermicularis_egg_UVa.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vLckKFYxvU"
      },
      "source": [
        "# Dropping unnecessary datapoints\r\n",
        "def check_file(x):\r\n",
        "  if x not in imgs:\r\n",
        "    return 'N\\A'\r\n",
        "  else:\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "data['img_path'] = data['img_path'].apply(check_file)\r\n",
        "data.drop(index = data[data['img_path']=='N\\A'].index,inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh--CXKMZadn"
      },
      "source": [
        "data.to_csv('/content/Parasitesv1.csv',index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hya_LqIH6HOw"
      },
      "source": [
        "del data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVArMwgZ7OF7"
      },
      "source": [
        "data = pd.read_csv('/content/Parasitesv1.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0vFVAvkJt2H",
        "outputId": "cdd3e0d3-812a-40c5-90e4-22e48842b37d"
      },
      "source": [
        "for i in data.columns:\r\n",
        "  print(i,data[i].nunique(),sep = '->')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "phylum->6\n",
            "class->11\n",
            "genus->21\n",
            "species->27\n",
            "form->13\n",
            "sample->15\n",
            "image_name->476\n",
            "image_url->477\n",
            "img_path->476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAUr1Q5FsW2x"
      },
      "source": [
        "X = data[['phylum','genus','species','form','class','image_name','image_url','img_path']].copy()\r\n",
        "Y = data[['sample']]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYxxbhAfQrI"
      },
      "source": [
        "## Custom Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPUz2T2qEXTS"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, sampler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "class SpeciesLoader(Dataset):\r\n",
        "  def __init__(self,csv_file,transform):\r\n",
        "    super().__init__()\r\n",
        "    csv = pd.read_csv(csv_file)[['sample','img_path']]\r\n",
        "    labels = csv['sample'].values\r\n",
        "\r\n",
        "    self.images = csv['img_path'].values\r\n",
        "    self.transform = transform\r\n",
        "\r\n",
        "    self.LE = LabelEncoder()\r\n",
        "    self.labels = self.LE.fit_transform(labels)    \r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    # return size of dataset\r\n",
        "    return len(self.images)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    img = Image.open(self.images[index])\r\n",
        "    img = self.transform(img)\r\n",
        "\r\n",
        "    label = self.labels[index]\r\n",
        "\r\n",
        "    return {'img':img,'targets':label}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOL5NtArJ8QY"
      },
      "source": [
        "train_transformer = transforms.Compose([\r\n",
        "        transforms.Resize((32,32)),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        # transforms.\r\n",
        "        # transforms.ColorJitter(hue=.05, saturation=.05),\r\n",
        "        transforms.RandomRotation(90),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])\r\n",
        "\r\n",
        "val_transformer = transforms.Compose([\r\n",
        "        transforms.Resize((32,32)),\r\n",
        "#         transforms.CenterCrop(224),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W7rAlWdfU6-"
      },
      "source": [
        "## Train and Test splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3lIa4_r--y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "    X, Y, test_size=0.2, random_state=2021,stratify = Y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjwGMBtPtNtw"
      },
      "source": [
        "train = X_train.merge(y_train,right_index=True,left_index = True)\r\n",
        "train.to_csv('/content/train.csv',index = False)\r\n",
        "\r\n",
        "test = X_test.merge(y_test,right_index=True,left_index = True)\r\n",
        "test.to_csv('/content/test.csv',index = False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrnFW7ocwEbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433bcde3-2dd0-4883-fe69-40956ad47d08"
      },
      "source": [
        "data.loc[204,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "phylum                                                 Nematoda\n",
              "class                                                   Enoplea\n",
              "genus                                                 Trichuris\n",
              "species                                     Trichuris Trichuria\n",
              "form                                                        egg\n",
              "sample                                                    feces\n",
              "image_name                Trichuris_trichiura_egg_atypical3.jpg\n",
              "image_url     https://www.cdc.gov//dpdx/trichuriasis/images/...\n",
              "img_path      ./Dataset/Trichuris/Trichuris_trichiura_egg_at...\n",
              "Name: 204, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0krE_cWXmq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94407dbb-dcdf-4b87-a11e-54d3b0396c4b"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0NXmSK2EFKh"
      },
      "source": [
        "train_dataset = SpeciesLoader('/content/train.csv',transform=train_transformer)\r\n",
        "test_dataset = SpeciesLoader('/content/test.csv',transform=val_transformer)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLedxgr9fiWx"
      },
      "source": [
        "# Train and Eval Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_USddH2fmWz"
      },
      "source": [
        "# ImageTransformer - trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mONSFXGxLQxz"
      },
      "source": [
        "model = ViT(image_size=32, patch_size=4, num_classes=10, channels=3,\r\n",
        "            dim=64, depth=6, heads=8, mlp_dim=128,dropout = 0.45,emb_dropout = 0.4)\r\n",
        "# \r\n",
        "model.load_state_dict(torch.load('/content/ViT-CIFAR10-final.bin'))\r\n",
        "model.nn1 = nn.Linear(64,15)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taCF0wxC6XKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4713768f-2e9f-4982-9f35-ba33af4be01c"
      },
      "source": [
        "esP = tez.callbacks.EarlyStopping(monitor=\"valid_loss\",patience=10, model_path=\"ViT-CIFAR10.bin\")\r\n",
        "model.fit(\r\n",
        "        train_dataset,\r\n",
        "        valid_dataset=test_dataset,\r\n",
        "        train_bs=100,\r\n",
        "        device=\"cuda\",\r\n",
        "        epochs=150,\r\n",
        "        fp16=True,\r\n",
        "    )\r\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            " 25%|██▌       | 1/4 [00:00<00:02,  1.33it/s, accuracy=0.08, f1=0.0665, loss=3.62, precision=0.0613, recall=0.08, stage=train]/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.117, f1=0.117, loss=3.08, precision=0.239, recall=0.117, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.17it/s, accuracy=0, f1=0, loss=5.25, precision=0, recall=0, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.98it/s, accuracy=0.315, f1=0.266, loss=2.27, precision=0.266, recall=0.315, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.91it/s, accuracy=0.0417, f1=0.0222, loss=6.49, precision=0.0156, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, accuracy=0.429, f1=0.348, loss=1.96, precision=0.309, recall=0.429, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.13it/s, accuracy=0.0417, f1=0.0265, loss=6.7, precision=0.0203, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.427, f1=0.371, loss=1.74, precision=0.362, recall=0.427, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.29it/s, accuracy=0.0417, f1=0.0255, loss=6.45, precision=0.0195, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.464, f1=0.418, loss=1.58, precision=0.4, recall=0.464, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.97it/s, accuracy=0.0417, f1=0.022, loss=6.69, precision=0.0155, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.469, f1=0.414, loss=1.61, precision=0.394, recall=0.469, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.53it/s, accuracy=0.0417, f1=0.022, loss=7.2, precision=0.0155, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.513, f1=0.453, loss=1.51, precision=0.434, recall=0.513, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.42it/s, accuracy=0.0312, f1=0.017, loss=7.57, precision=0.0125, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.484, f1=0.43, loss=1.54, precision=0.408, recall=0.484, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.62it/s, accuracy=0.0312, f1=0.0136, loss=7.69, precision=0.00888, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.538, f1=0.479, loss=1.39, precision=0.455, recall=0.538, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.02it/s, accuracy=0.0312, f1=0.0165, loss=7.84, precision=0.0122, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.538, f1=0.498, loss=1.39, precision=0.486, recall=0.538, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.21it/s, accuracy=0.0312, f1=0.0159, loss=7.82, precision=0.0117, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.557, f1=0.514, loss=1.36, precision=0.504, recall=0.557, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.93it/s, accuracy=0.0312, f1=0.0136, loss=8.01, precision=0.00888, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.547, f1=0.511, loss=1.3, precision=0.509, recall=0.547, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.30it/s, accuracy=0.0312, f1=0.0128, loss=8.11, precision=0.00818, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.575, f1=0.523, loss=1.27, precision=0.524, recall=0.575, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.21it/s, accuracy=0.0208, f1=0.00992, loss=8.44, precision=0.00694, recall=0.0208, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.523, f1=0.47, loss=1.3, precision=0.454, recall=0.523, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.61it/s, accuracy=0.0208, f1=0.00942, loss=8.52, precision=0.00625, recall=0.0208, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, accuracy=0.582, f1=0.541, loss=1.24, precision=0.537, recall=0.582, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.25it/s, accuracy=0.0208, f1=0.0104, loss=8.29, precision=0.00729, recall=0.0208, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.568, f1=0.534, loss=1.27, precision=0.521, recall=0.568, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.26it/s, accuracy=0.0208, f1=0.00992, loss=8.64, precision=0.00694, recall=0.0208, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.581, f1=0.541, loss=1.22, precision=0.568, recall=0.581, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.72it/s, accuracy=0.0208, f1=0.00942, loss=8.55, precision=0.00625, recall=0.0208, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.595, f1=0.562, loss=1.16, precision=0.559, recall=0.595, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.30it/s, accuracy=0.0312, f1=0.0198, loss=8.34, precision=0.0167, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.586, f1=0.547, loss=1.21, precision=0.535, recall=0.586, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.10it/s, accuracy=0.0312, f1=0.0222, loss=8.54, precision=0.0194, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.565, f1=0.529, loss=1.2, precision=0.517, recall=0.565, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.52it/s, accuracy=0.0312, f1=0.0208, loss=8.73, precision=0.0177, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.595, f1=0.558, loss=1.18, precision=0.546, recall=0.595, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.50it/s, accuracy=0.0312, f1=0.0208, loss=8.73, precision=0.0177, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, accuracy=0.64, f1=0.61, loss=1.13, precision=0.612, recall=0.64, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.41it/s, accuracy=0.0312, f1=0.0208, loss=9.13, precision=0.0177, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.62, f1=0.583, loss=1.14, precision=0.581, recall=0.62, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.57it/s, accuracy=0.0312, f1=0.0198, loss=8.97, precision=0.0167, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.582, f1=0.558, loss=1.16, precision=0.562, recall=0.582, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.46it/s, accuracy=0.0312, f1=0.0198, loss=8.83, precision=0.0167, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.654, f1=0.617, loss=1.09, precision=0.616, recall=0.654, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.16it/s, accuracy=0.0312, f1=0.0222, loss=9.04, precision=0.0194, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.625, f1=0.594, loss=1.04, precision=0.595, recall=0.625, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.97it/s, accuracy=0.0312, f1=0.0208, loss=8.89, precision=0.0177, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.622, f1=0.587, loss=1.1, precision=0.582, recall=0.622, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.47it/s, accuracy=0.0312, f1=0.0222, loss=8.92, precision=0.0194, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.633, f1=0.611, loss=1.1, precision=0.605, recall=0.633, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.08it/s, accuracy=0.0312, f1=0.0217, loss=9.04, precision=0.0191, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.665, f1=0.637, loss=1.02, precision=0.634, recall=0.665, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.55it/s, accuracy=0.0521, f1=0.0299, loss=8.71, precision=0.0243, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, accuracy=0.629, f1=0.59, loss=1.06, precision=0.584, recall=0.629, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.18it/s, accuracy=0.0312, f1=0.0203, loss=9.16, precision=0.0174, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.68, f1=0.643, loss=0.986, precision=0.637, recall=0.68, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.33it/s, accuracy=0.0312, f1=0.0208, loss=8.88, precision=0.0177, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, accuracy=0.631, f1=0.596, loss=1.03, precision=0.597, recall=0.631, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.26it/s, accuracy=0.0521, f1=0.041, loss=8.78, precision=0.0368, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.65, f1=0.63, loss=1.02, precision=0.63, recall=0.65, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.40it/s, accuracy=0.0417, f1=0.0292, loss=9.08, precision=0.0247, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.677, f1=0.647, loss=0.983, precision=0.643, recall=0.677, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.07it/s, accuracy=0.0521, f1=0.0304, loss=9.13, precision=0.0247, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.654, f1=0.624, loss=0.99, precision=0.626, recall=0.654, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.22it/s, accuracy=0.0417, f1=0.0292, loss=9.18, precision=0.0247, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.689, f1=0.665, loss=0.901, precision=0.671, recall=0.689, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.31it/s, accuracy=0.0417, f1=0.0268, loss=8.78, precision=0.0219, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.642, f1=0.62, loss=0.992, precision=0.623, recall=0.642, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.27it/s, accuracy=0.0521, f1=0.0321, loss=9.41, precision=0.0264, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.652, f1=0.627, loss=1, precision=0.634, recall=0.652, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.41it/s, accuracy=0.0625, f1=0.0408, loss=9.49, precision=0.0351, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.663, f1=0.639, loss=0.924, precision=0.65, recall=0.663, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.58it/s, accuracy=0.0417, f1=0.026, loss=9.43, precision=0.0212, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.675, f1=0.65, loss=0.956, precision=0.662, recall=0.675, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.54it/s, accuracy=0.0417, f1=0.026, loss=9.35, precision=0.0212, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.98it/s, accuracy=0.683, f1=0.658, loss=0.976, precision=0.661, recall=0.683, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.34it/s, accuracy=0.0417, f1=0.026, loss=9.37, precision=0.0212, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.696, f1=0.679, loss=0.934, precision=0.698, recall=0.696, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.31it/s, accuracy=0.0417, f1=0.026, loss=9.45, precision=0.0212, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.665, f1=0.645, loss=0.978, precision=0.653, recall=0.665, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.95it/s, accuracy=0.0417, f1=0.026, loss=9.32, precision=0.0212, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.05it/s, accuracy=0.682, f1=0.668, loss=0.914, precision=0.68, recall=0.682, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.95it/s, accuracy=0.0417, f1=0.0268, loss=9.7, precision=0.0219, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.682, f1=0.651, loss=0.954, precision=0.674, recall=0.682, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.63it/s, accuracy=0.0521, f1=0.0367, loss=9.47, precision=0.0319, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.664, f1=0.641, loss=0.921, precision=0.641, recall=0.664, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.55it/s, accuracy=0.0521, f1=0.0382, loss=9.58, precision=0.0333, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.705, f1=0.687, loss=0.85, precision=0.693, recall=0.705, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.28it/s, accuracy=0.0521, f1=0.041, loss=10.1, precision=0.0368, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.695, f1=0.664, loss=0.88, precision=0.687, recall=0.695, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.24it/s, accuracy=0.0521, f1=0.0284, loss=9.65, precision=0.0224, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.698, f1=0.682, loss=0.903, precision=0.693, recall=0.698, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.12it/s, accuracy=0.0521, f1=0.041, loss=10.1, precision=0.0368, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.664, f1=0.634, loss=0.906, precision=0.651, recall=0.664, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.10it/s, accuracy=0.0417, f1=0.0278, loss=9.95, precision=0.0229, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.685, f1=0.669, loss=0.877, precision=0.687, recall=0.685, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.88it/s, accuracy=0.0417, f1=0.0289, loss=9.95, precision=0.0241, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.69, f1=0.667, loss=0.896, precision=0.684, recall=0.69, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.93it/s, accuracy=0.0417, f1=0.0312, loss=10.4, precision=0.0269, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.71, f1=0.691, loss=0.838, precision=0.689, recall=0.71, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.07it/s, accuracy=0.0417, f1=0.0281, loss=9.93, precision=0.0234, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, accuracy=0.7, f1=0.686, loss=0.86, precision=0.706, recall=0.7, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.80it/s, accuracy=0.0417, f1=0.031, loss=10.8, precision=0.0276, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.696, f1=0.673, loss=0.853, precision=0.69, recall=0.696, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.00it/s, accuracy=0.0521, f1=0.0379, loss=10.2, precision=0.0328, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.667, f1=0.65, loss=0.895, precision=0.657, recall=0.667, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.22it/s, accuracy=0.0521, f1=0.0403, loss=10.2, precision=0.0356, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.699, f1=0.681, loss=0.877, precision=0.694, recall=0.699, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.37it/s, accuracy=0.0521, f1=0.0369, loss=10.7, precision=0.0318, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.715, f1=0.698, loss=0.85, precision=0.714, recall=0.715, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.13it/s, accuracy=0.0521, f1=0.0322, loss=10.2, precision=0.0259, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.719, f1=0.694, loss=0.847, precision=0.706, recall=0.719, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.69it/s, accuracy=0.0521, f1=0.0368, loss=10.4, precision=0.0304, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, accuracy=0.712, f1=0.707, loss=0.816, precision=0.736, recall=0.712, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.30it/s, accuracy=0.0521, f1=0.0333, loss=9.78, precision=0.0269, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.727, f1=0.708, loss=0.833, precision=0.71, recall=0.727, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.44it/s, accuracy=0.0417, f1=0.0319, loss=10.4, precision=0.0286, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, accuracy=0.719, f1=0.696, loss=0.821, precision=0.709, recall=0.719, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.31it/s, accuracy=0.0417, f1=0.0281, loss=10.2, precision=0.0234, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.03it/s, accuracy=0.733, f1=0.709, loss=0.836, precision=0.713, recall=0.733, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.08it/s, accuracy=0.0521, f1=0.0393, loss=10.6, precision=0.0345, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.708, f1=0.694, loss=0.85, precision=0.712, recall=0.708, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.26it/s, accuracy=0.0521, f1=0.0393, loss=10.6, precision=0.0345, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.746, f1=0.73, loss=0.774, precision=0.738, recall=0.746, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.72it/s, accuracy=0.0625, f1=0.0338, loss=10.4, precision=0.0259, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.73, f1=0.715, loss=0.763, precision=0.728, recall=0.73, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.27it/s, accuracy=0.0417, f1=0.0285, loss=10.5, precision=0.0233, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.713, f1=0.697, loss=0.788, precision=0.7, recall=0.713, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.31it/s, accuracy=0.0625, f1=0.0338, loss=10.1, precision=0.0259, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.747, f1=0.729, loss=0.74, precision=0.73, recall=0.747, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.29it/s, accuracy=0.0625, f1=0.0412, loss=10.5, precision=0.0346, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.728, f1=0.706, loss=0.767, precision=0.736, recall=0.728, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.32it/s, accuracy=0.0625, f1=0.0412, loss=10.5, precision=0.0346, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.719, f1=0.712, loss=0.77, precision=0.721, recall=0.719, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.31it/s, accuracy=0.0625, f1=0.0415, loss=10.5, precision=0.0356, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.04it/s, accuracy=0.732, f1=0.716, loss=0.777, precision=0.726, recall=0.732, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.13it/s, accuracy=0.0625, f1=0.0426, loss=10.9, precision=0.0363, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.758, f1=0.736, loss=0.749, precision=0.737, recall=0.758, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.09it/s, accuracy=0.0625, f1=0.0424, loss=10.8, precision=0.0356, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.739, f1=0.716, loss=0.757, precision=0.725, recall=0.739, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.47it/s, accuracy=0.0625, f1=0.0403, loss=10.7, precision=0.0339, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.718, f1=0.7, loss=0.736, precision=0.722, recall=0.718, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.89it/s, accuracy=0.0521, f1=0.0376, loss=10.6, precision=0.0325, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.741, f1=0.73, loss=0.729, precision=0.746, recall=0.741, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.24it/s, accuracy=0.0625, f1=0.0426, loss=10.8, precision=0.0363, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.755, f1=0.739, loss=0.692, precision=0.757, recall=0.755, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.07it/s, accuracy=0.0521, f1=0.0399, loss=10.6, precision=0.0347, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.742, f1=0.725, loss=0.74, precision=0.728, recall=0.742, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0521, f1=0.0421, loss=10.7, precision=0.0372, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.762, f1=0.745, loss=0.689, precision=0.752, recall=0.762, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.28it/s, accuracy=0.0521, f1=0.0413, loss=11.3, precision=0.0365, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.769, f1=0.752, loss=0.682, precision=0.76, recall=0.769, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0417, f1=0.0316, loss=11.5, precision=0.0267, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.723, f1=0.711, loss=0.741, precision=0.721, recall=0.723, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.18it/s, accuracy=0.0521, f1=0.0318, loss=11.5, precision=0.025, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.742, f1=0.728, loss=0.711, precision=0.745, recall=0.742, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.77it/s, accuracy=0.0625, f1=0.0412, loss=11.3, precision=0.0346, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.741, f1=0.735, loss=0.733, precision=0.758, recall=0.741, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.10it/s, accuracy=0.0521, f1=0.0413, loss=11.8, precision=0.0365, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.74, f1=0.731, loss=0.703, precision=0.757, recall=0.74, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.95it/s, accuracy=0.0625, f1=0.0434, loss=12.1, precision=0.0365, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.76, f1=0.741, loss=0.767, precision=0.754, recall=0.76, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.23it/s, accuracy=0.0625, f1=0.0452, loss=12, precision=0.0387, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, accuracy=0.767, f1=0.749, loss=0.729, precision=0.749, recall=0.767, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.49it/s, accuracy=0.0417, f1=0.0396, loss=12.1, precision=0.0382, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.723, f1=0.715, loss=0.799, precision=0.734, recall=0.723, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.97it/s, accuracy=0.0625, f1=0.0443, loss=12, precision=0.0397, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.758, f1=0.74, loss=0.725, precision=0.75, recall=0.758, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.11it/s, accuracy=0.0521, f1=0.0366, loss=11.8, precision=0.0316, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, accuracy=0.751, f1=0.742, loss=0.661, precision=0.753, recall=0.751, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0521, f1=0.0372, loss=11.8, precision=0.0319, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.757, f1=0.751, loss=0.687, precision=0.776, recall=0.757, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.94it/s, accuracy=0.0625, f1=0.0436, loss=12.3, precision=0.0372, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.06it/s, accuracy=0.765, f1=0.743, loss=0.625, precision=0.761, recall=0.765, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.28it/s, accuracy=0.0625, f1=0.0424, loss=11.9, precision=0.0356, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.78, f1=0.764, loss=0.66, precision=0.777, recall=0.78, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.20it/s, accuracy=0.0625, f1=0.0424, loss=11.5, precision=0.0354, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  4.00it/s, accuracy=0.765, f1=0.748, loss=0.654, precision=0.756, recall=0.765, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.59it/s, accuracy=0.0417, f1=0.0361, loss=11.8, precision=0.033, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.765, f1=0.757, loss=0.688, precision=0.777, recall=0.765, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.42it/s, accuracy=0.0312, f1=0.0312, loss=11.6, precision=0.0312, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.748, f1=0.74, loss=0.702, precision=0.76, recall=0.748, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.37it/s, accuracy=0.0417, f1=0.0417, loss=11.8, precision=0.0417, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.748, f1=0.738, loss=0.665, precision=0.744, recall=0.748, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.02it/s, accuracy=0.0417, f1=0.0347, loss=11.8, precision=0.0312, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.785, f1=0.774, loss=0.642, precision=0.789, recall=0.785, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.00it/s, accuracy=0.0417, f1=0.0361, loss=12.3, precision=0.033, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.769, f1=0.759, loss=0.626, precision=0.773, recall=0.769, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.21it/s, accuracy=0.0521, f1=0.0399, loss=12, precision=0.0347, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.786, f1=0.774, loss=0.655, precision=0.78, recall=0.786, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.48it/s, accuracy=0.0417, f1=0.033, loss=12.2, precision=0.0295, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.78, f1=0.773, loss=0.718, precision=0.79, recall=0.78, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.20it/s, accuracy=0.0521, f1=0.0396, loss=12.3, precision=0.0347, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.759, f1=0.75, loss=0.631, precision=0.767, recall=0.759, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.27it/s, accuracy=0.0521, f1=0.0396, loss=12.5, precision=0.0347, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, accuracy=0.762, f1=0.741, loss=0.654, precision=0.766, recall=0.762, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.96it/s, accuracy=0.0417, f1=0.0396, loss=12.3, precision=0.0382, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.99it/s, accuracy=0.786, f1=0.778, loss=0.604, precision=0.786, recall=0.786, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.55it/s, accuracy=0.0625, f1=0.0408, loss=11.8, precision=0.0345, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.79, f1=0.781, loss=0.62, precision=0.79, recall=0.79, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.09it/s, accuracy=0.0521, f1=0.0441, loss=12.2, precision=0.0406, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, accuracy=0.798, f1=0.786, loss=0.582, precision=0.794, recall=0.798, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.94it/s, accuracy=0.0625, f1=0.0414, loss=12.6, precision=0.0355, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.775, f1=0.761, loss=0.638, precision=0.763, recall=0.775, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.87it/s, accuracy=0.0312, f1=0.0292, loss=12.7, precision=0.0278, recall=0.0312, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.95it/s, accuracy=0.762, f1=0.751, loss=0.63, precision=0.755, recall=0.762, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.09it/s, accuracy=0.0417, f1=0.0337, loss=12.4, precision=0.0302, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, accuracy=0.776, f1=0.77, loss=0.629, precision=0.787, recall=0.776, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.92it/s, accuracy=0.0521, f1=0.0407, loss=12.8, precision=0.0354, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.778, f1=0.766, loss=0.623, precision=0.781, recall=0.778, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.06it/s, accuracy=0.0521, f1=0.0451, loss=12.9, precision=0.0417, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.811, f1=0.806, loss=0.587, precision=0.818, recall=0.811, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.57it/s, accuracy=0.0625, f1=0.0412, loss=12.5, precision=0.0347, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.794, f1=0.791, loss=0.648, precision=0.805, recall=0.794, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.32it/s, accuracy=0.0521, f1=0.0396, loss=12.5, precision=0.0347, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.791, f1=0.78, loss=0.639, precision=0.791, recall=0.791, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.30it/s, accuracy=0.0521, f1=0.0417, loss=12.3, precision=0.0385, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.773, f1=0.767, loss=0.634, precision=0.793, recall=0.773, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0625, f1=0.0469, loss=12.8, precision=0.042, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.79, f1=0.775, loss=0.553, precision=0.787, recall=0.79, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.01it/s, accuracy=0.0625, f1=0.0411, loss=12.7, precision=0.0353, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.779, f1=0.768, loss=0.633, precision=0.792, recall=0.779, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.41it/s, accuracy=0.0625, f1=0.0412, loss=12.6, precision=0.0347, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.02it/s, accuracy=0.772, f1=0.771, loss=0.612, precision=0.798, recall=0.772, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.52it/s, accuracy=0.0729, f1=0.0481, loss=13.3, precision=0.0399, recall=0.0729, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.804, f1=0.792, loss=0.535, precision=0.802, recall=0.804, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.24it/s, accuracy=0.0625, f1=0.0423, loss=13.5, precision=0.036, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, accuracy=0.813, f1=0.803, loss=0.6, precision=0.821, recall=0.813, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.82it/s, accuracy=0.0417, f1=0.0396, loss=13.5, precision=0.0382, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, accuracy=0.823, f1=0.821, loss=0.583, precision=0.835, recall=0.823, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.02it/s, accuracy=0.0417, f1=0.0308, loss=13.5, precision=0.0278, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.809, f1=0.804, loss=0.598, precision=0.819, recall=0.809, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.16it/s, accuracy=0.0625, f1=0.048, loss=13.4, precision=0.0413, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.81it/s, accuracy=0.809, f1=0.797, loss=0.531, precision=0.811, recall=0.809, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.34it/s, accuracy=0.0729, f1=0.0466, loss=12.9, precision=0.0387, recall=0.0729, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, accuracy=0.847, f1=0.838, loss=0.502, precision=0.844, recall=0.847, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.10it/s, accuracy=0.0729, f1=0.0454, loss=13.2, precision=0.0378, recall=0.0729, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, accuracy=0.805, f1=0.793, loss=0.583, precision=0.807, recall=0.805, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.40it/s, accuracy=0.0521, f1=0.0413, loss=13.5, precision=0.0365, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.82, f1=0.812, loss=0.483, precision=0.826, recall=0.82, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.96it/s, accuracy=0.0625, f1=0.042, loss=13.3, precision=0.0357, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.90it/s, accuracy=0.816, f1=0.805, loss=0.494, precision=0.816, recall=0.816, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.25it/s, accuracy=0.0521, f1=0.0389, loss=13.7, precision=0.0337, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.81, f1=0.799, loss=0.548, precision=0.81, recall=0.81, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.21it/s, accuracy=0.0417, f1=0.032, loss=13.5, precision=0.0285, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.815, f1=0.806, loss=0.525, precision=0.813, recall=0.815, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.84it/s, accuracy=0.0417, f1=0.0361, loss=14.5, precision=0.033, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.796, f1=0.788, loss=0.541, precision=0.808, recall=0.796, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.05it/s, accuracy=0.0417, f1=0.0361, loss=14.6, precision=0.033, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.86it/s, accuracy=0.827, f1=0.824, loss=0.534, precision=0.837, recall=0.827, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.86it/s, accuracy=0.0521, f1=0.0356, loss=14.4, precision=0.031, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.8, f1=0.793, loss=0.526, precision=0.802, recall=0.8, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.85it/s, accuracy=0.0417, f1=0.0347, loss=14.5, precision=0.0312, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.92it/s, accuracy=0.808, f1=0.807, loss=0.565, precision=0.821, recall=0.808, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.71it/s, accuracy=0.0417, f1=0.0347, loss=14.5, precision=0.0312, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.833, f1=0.827, loss=0.494, precision=0.841, recall=0.833, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.67it/s, accuracy=0.0417, f1=0.0344, loss=14.4, precision=0.0312, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:00<00:00,  4.01it/s, accuracy=0.809, f1=0.799, loss=0.575, precision=0.807, recall=0.809, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.89it/s, accuracy=0.0625, f1=0.0408, loss=14.8, precision=0.0345, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.96it/s, accuracy=0.828, f1=0.82, loss=0.513, precision=0.839, recall=0.828, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.41it/s, accuracy=0.0625, f1=0.0437, loss=15, precision=0.0372, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.98it/s, accuracy=0.83, f1=0.824, loss=0.452, precision=0.832, recall=0.83, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.35it/s, accuracy=0.0521, f1=0.0403, loss=14.8, precision=0.0354, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.824, f1=0.822, loss=0.533, precision=0.842, recall=0.824, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.71it/s, accuracy=0.0625, f1=0.045, loss=14.7, precision=0.0389, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.803, f1=0.797, loss=0.533, precision=0.815, recall=0.803, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.21it/s, accuracy=0.0625, f1=0.0437, loss=14.8, precision=0.0372, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.83it/s, accuracy=0.818, f1=0.813, loss=0.513, precision=0.825, recall=0.818, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0625, f1=0.0398, loss=14.6, precision=0.0336, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.87it/s, accuracy=0.816, f1=0.815, loss=0.515, precision=0.836, recall=0.816, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.75it/s, accuracy=0.0625, f1=0.0437, loss=14.8, precision=0.0372, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.839, f1=0.829, loss=0.497, precision=0.84, recall=0.839, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.57it/s, accuracy=0.0521, f1=0.0367, loss=15.2, precision=0.0319, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.91it/s, accuracy=0.849, f1=0.847, loss=0.441, precision=0.855, recall=0.849, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.49it/s, accuracy=0.0417, f1=0.0312, loss=15.3, precision=0.0281, recall=0.0417, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.84it/s, accuracy=0.824, f1=0.813, loss=0.516, precision=0.816, recall=0.824, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.26it/s, accuracy=0.0521, f1=0.0373, loss=14.6, precision=0.0327, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.85it/s, accuracy=0.824, f1=0.819, loss=0.491, precision=0.838, recall=0.824, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.57it/s, accuracy=0.0521, f1=0.0377, loss=14.7, precision=0.033, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.76it/s, accuracy=0.827, f1=0.819, loss=0.532, precision=0.834, recall=0.827, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.70it/s, accuracy=0.0521, f1=0.0356, loss=14.4, precision=0.031, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.832, f1=0.828, loss=0.529, precision=0.84, recall=0.832, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.86it/s, accuracy=0.0521, f1=0.0345, loss=14.1, precision=0.0301, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.833, f1=0.835, loss=0.491, precision=0.86, recall=0.833, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.85it/s, accuracy=0.0521, f1=0.0356, loss=14.7, precision=0.031, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.93it/s, accuracy=0.843, f1=0.837, loss=0.486, precision=0.847, recall=0.843, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 11.04it/s, accuracy=0.0625, f1=0.0451, loss=14.8, precision=0.0385, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.94it/s, accuracy=0.844, f1=0.837, loss=0.459, precision=0.841, recall=0.844, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.64it/s, accuracy=0.0521, f1=0.0356, loss=14.5, precision=0.031, recall=0.0521, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.89it/s, accuracy=0.829, f1=0.823, loss=0.465, precision=0.838, recall=0.829, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.83it/s, accuracy=0.0625, f1=0.0402, loss=14.7, precision=0.034, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.97it/s, accuracy=0.812, f1=0.809, loss=0.478, precision=0.82, recall=0.812, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.69it/s, accuracy=0.0625, f1=0.0412, loss=15.2, precision=0.0347, recall=0.0625, stage=valid]\n",
            "100%|██████████| 4/4 [00:01<00:00,  3.88it/s, accuracy=0.852, f1=0.846, loss=0.467, precision=0.867, recall=0.852, stage=train]\n",
            "100%|██████████| 6/6 [00:00<00:00, 10.60it/s, accuracy=0.0521, f1=0.0356, loss=14.9, precision=0.031, recall=0.0521, stage=valid]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOS_qW029u_E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AddUuTVVtX4Q"
      },
      "source": [
        "# ImageTransformer - Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbdWhvDVtX4Y"
      },
      "source": [
        "model = ViT(image_size=32, patch_size=4, num_classes=27, channels=3,\r\n",
        "            dim=64, depth=6, heads=8, mlp_dim=128)\r\n",
        "\r\n",
        "esP = tez.callbacks.EarlyStopping(monitor=\"valid_loss\", model_path=\"ViT-CIFAR10.bin\")\r\n",
        "model.fit(\r\n",
        "        train_dataset,\r\n",
        "        valid_dataset=test_dataset,\r\n",
        "        train_bs=100,\r\n",
        "        device=\"cuda\",\r\n",
        "        epochs=150,\r\n",
        "        callbacks=[esP],\r\n",
        "        fp16=True,\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6jzvBbItX4a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT13lRZ99QRs"
      },
      "source": [
        "# VGG19-Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI8huyCo9QRu"
      },
      "source": [
        "N_EPOCHS = 150\r\n",
        "\r\n",
        "model = models.vgg19_bn(num_classes = 27)\r\n",
        "model.cuda()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNidRDsm9QRv",
        "outputId": "6aae4550-cd53-4184-e9b1-8956f30c1b44"
      },
      "source": [
        "train_loss_history, test_loss_history = [], []\r\n",
        "\r\n",
        "e_start = time.time()\r\n",
        "for epoch in range(1, N_EPOCHS + 1):\r\n",
        "    print('Epoch:', epoch)\r\n",
        "    start_time = time.time()\r\n",
        "    train(model, optimizer, train_loader, train_loss_history)\r\n",
        "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\r\n",
        "    evaluate(model, validation_loader, test_loss_history)\r\n",
        "\r\n",
        "print(f'Execution time {time.time()-e_start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[    0/   16 (  0%)]  Loss: 3.7793\n",
            "[  256/  272 ( 67%)]  Loss: 3.2558\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 3.2763  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 2\n",
            "[    0/   16 (  0%)]  Loss: 3.3121\n",
            "[  256/  272 ( 67%)]  Loss: 2.9432\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 3.1884  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 3\n",
            "[    0/   16 (  0%)]  Loss: 3.5999\n",
            "[  256/  272 ( 67%)]  Loss: 3.5572\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 3.1979  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 4\n",
            "[    0/   16 (  0%)]  Loss: 3.2192\n",
            "[  256/  272 ( 67%)]  Loss: 3.0254\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 3.1438  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 5\n",
            "[    0/   16 (  0%)]  Loss: 2.8820\n",
            "[  256/  272 ( 67%)]  Loss: 3.7351\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 3.1041  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 6\n",
            "[    0/   16 (  0%)]  Loss: 2.7266\n",
            "[  256/  272 ( 67%)]  Loss: 3.2384\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.9441  Accuracy:   10/   95 (10.53%)\n",
            "\n",
            "Epoch: 7\n",
            "[    0/   16 (  0%)]  Loss: 3.4089\n",
            "[  256/  272 ( 67%)]  Loss: 3.5191\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.8645  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 8\n",
            "[    0/   16 (  0%)]  Loss: 3.3854\n",
            "[  256/  272 ( 67%)]  Loss: 3.3993\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.8653  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 9\n",
            "[    0/   16 (  0%)]  Loss: 2.9057\n",
            "[  256/  272 ( 67%)]  Loss: 2.2653\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.7918  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 10\n",
            "[    0/   16 (  0%)]  Loss: 2.9445\n",
            "[  256/  272 ( 67%)]  Loss: 3.1213\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.7830  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 11\n",
            "[    0/   16 (  0%)]  Loss: 2.6296\n",
            "[  256/  272 ( 67%)]  Loss: 2.8314\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.7758  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 12\n",
            "[    0/   16 (  0%)]  Loss: 2.9286\n",
            "[  256/  272 ( 67%)]  Loss: 2.9835\n",
            "Execution time:  1.74 seconds\n",
            "\n",
            "Average test loss: 2.7386  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 13\n",
            "[    0/   16 (  0%)]  Loss: 2.9063\n",
            "[  256/  272 ( 67%)]  Loss: 2.8293\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.6963  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 14\n",
            "[    0/   16 (  0%)]  Loss: 3.3992\n",
            "[  256/  272 ( 67%)]  Loss: 2.9188\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.7006  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 15\n",
            "[    0/   16 (  0%)]  Loss: 2.6312\n",
            "[  256/  272 ( 67%)]  Loss: 2.5784\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.6436  Accuracy:   20/   95 (21.05%)\n",
            "\n",
            "Epoch: 16\n",
            "[    0/   16 (  0%)]  Loss: 2.4807\n",
            "[  256/  272 ( 67%)]  Loss: 2.9317\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.6481  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 17\n",
            "[    0/   16 (  0%)]  Loss: 3.1071\n",
            "[  256/  272 ( 67%)]  Loss: 3.0617\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.5960  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 18\n",
            "[    0/   16 (  0%)]  Loss: 2.6967\n",
            "[  256/  272 ( 67%)]  Loss: 3.0922\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.6187  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 19\n",
            "[    0/   16 (  0%)]  Loss: 2.6445\n",
            "[  256/  272 ( 67%)]  Loss: 2.8137\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.6528  Accuracy:   22/   95 (23.16%)\n",
            "\n",
            "Epoch: 20\n",
            "[    0/   16 (  0%)]  Loss: 2.3093\n",
            "[  256/  272 ( 67%)]  Loss: 2.5922\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.5784  Accuracy:   21/   95 (22.11%)\n",
            "\n",
            "Epoch: 21\n",
            "[    0/   16 (  0%)]  Loss: 2.5533\n",
            "[  256/  272 ( 67%)]  Loss: 2.7954\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.6329  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 22\n",
            "[    0/   16 (  0%)]  Loss: 2.4382\n",
            "[  256/  272 ( 67%)]  Loss: 2.6661\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.5732  Accuracy:   24/   95 (25.26%)\n",
            "\n",
            "Epoch: 23\n",
            "[    0/   16 (  0%)]  Loss: 2.5413\n",
            "[  256/  272 ( 67%)]  Loss: 2.7400\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.5725  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 24\n",
            "[    0/   16 (  0%)]  Loss: 2.6800\n",
            "[  256/  272 ( 67%)]  Loss: 2.8879\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5681  Accuracy:   23/   95 (24.21%)\n",
            "\n",
            "Epoch: 25\n",
            "[    0/   16 (  0%)]  Loss: 2.6777\n",
            "[  256/  272 ( 67%)]  Loss: 2.8669\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 2.5318  Accuracy:   21/   95 (22.11%)\n",
            "\n",
            "Epoch: 26\n",
            "[    0/   16 (  0%)]  Loss: 2.5839\n",
            "[  256/  272 ( 67%)]  Loss: 2.8245\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5546  Accuracy:   25/   95 (26.32%)\n",
            "\n",
            "Epoch: 27\n",
            "[    0/   16 (  0%)]  Loss: 2.3151\n",
            "[  256/  272 ( 67%)]  Loss: 3.0889\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5550  Accuracy:   20/   95 (21.05%)\n",
            "\n",
            "Epoch: 28\n",
            "[    0/   16 (  0%)]  Loss: 2.5866\n",
            "[  256/  272 ( 67%)]  Loss: 2.6395\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.5398  Accuracy:   26/   95 (27.37%)\n",
            "\n",
            "Epoch: 29\n",
            "[    0/   16 (  0%)]  Loss: 2.1507\n",
            "[  256/  272 ( 67%)]  Loss: 2.4815\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4993  Accuracy:   25/   95 (26.32%)\n",
            "\n",
            "Epoch: 30\n",
            "[    0/   16 (  0%)]  Loss: 2.3848\n",
            "[  256/  272 ( 67%)]  Loss: 1.9143\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4882  Accuracy:   23/   95 (24.21%)\n",
            "\n",
            "Epoch: 31\n",
            "[    0/   16 (  0%)]  Loss: 2.0825\n",
            "[  256/  272 ( 67%)]  Loss: 2.7445\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.4140  Accuracy:   31/   95 (32.63%)\n",
            "\n",
            "Epoch: 32\n",
            "[    0/   16 (  0%)]  Loss: 2.1060\n",
            "[  256/  272 ( 67%)]  Loss: 2.1406\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4045  Accuracy:   26/   95 (27.37%)\n",
            "\n",
            "Epoch: 33\n",
            "[    0/   16 (  0%)]  Loss: 2.4251\n",
            "[  256/  272 ( 67%)]  Loss: 2.6015\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3602  Accuracy:   31/   95 (32.63%)\n",
            "\n",
            "Epoch: 34\n",
            "[    0/   16 (  0%)]  Loss: 1.8692\n",
            "[  256/  272 ( 67%)]  Loss: 2.6736\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4703  Accuracy:   29/   95 (30.53%)\n",
            "\n",
            "Epoch: 35\n",
            "[    0/   16 (  0%)]  Loss: 2.5383\n",
            "[  256/  272 ( 67%)]  Loss: 2.2046\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4377  Accuracy:   31/   95 (32.63%)\n",
            "\n",
            "Epoch: 36\n",
            "[    0/   16 (  0%)]  Loss: 2.2515\n",
            "[  256/  272 ( 67%)]  Loss: 2.2339\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4169  Accuracy:   30/   95 (31.58%)\n",
            "\n",
            "Epoch: 37\n",
            "[    0/   16 (  0%)]  Loss: 2.6879\n",
            "[  256/  272 ( 67%)]  Loss: 1.8946\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 2.4078  Accuracy:   27/   95 (28.42%)\n",
            "\n",
            "Epoch: 38\n",
            "[    0/   16 (  0%)]  Loss: 2.1959\n",
            "[  256/  272 ( 67%)]  Loss: 3.3558\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3841  Accuracy:   35/   95 (36.84%)\n",
            "\n",
            "Epoch: 39\n",
            "[    0/   16 (  0%)]  Loss: 2.8489\n",
            "[  256/  272 ( 67%)]  Loss: 2.0878\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3616  Accuracy:   30/   95 (31.58%)\n",
            "\n",
            "Epoch: 40\n",
            "[    0/   16 (  0%)]  Loss: 2.0605\n",
            "[  256/  272 ( 67%)]  Loss: 1.8833\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2334  Accuracy:   32/   95 (33.68%)\n",
            "\n",
            "Epoch: 41\n",
            "[    0/   16 (  0%)]  Loss: 2.1104\n",
            "[  256/  272 ( 67%)]  Loss: 2.1962\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.3856  Accuracy:   31/   95 (32.63%)\n",
            "\n",
            "Epoch: 42\n",
            "[    0/   16 (  0%)]  Loss: 2.2725\n",
            "[  256/  272 ( 67%)]  Loss: 2.1941\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.3438  Accuracy:   30/   95 (31.58%)\n",
            "\n",
            "Epoch: 43\n",
            "[    0/   16 (  0%)]  Loss: 1.9483\n",
            "[  256/  272 ( 67%)]  Loss: 2.0671\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 2.2917  Accuracy:   31/   95 (32.63%)\n",
            "\n",
            "Epoch: 44\n",
            "[    0/   16 (  0%)]  Loss: 2.3037\n",
            "[  256/  272 ( 67%)]  Loss: 1.7894\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3097  Accuracy:   32/   95 (33.68%)\n",
            "\n",
            "Epoch: 45\n",
            "[    0/   16 (  0%)]  Loss: 2.8223\n",
            "[  256/  272 ( 67%)]  Loss: 2.0937\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.2745  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 46\n",
            "[    0/   16 (  0%)]  Loss: 2.0035\n",
            "[  256/  272 ( 67%)]  Loss: 2.3689\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.2835  Accuracy:   36/   95 (37.89%)\n",
            "\n",
            "Epoch: 47\n",
            "[    0/   16 (  0%)]  Loss: 1.8178\n",
            "[  256/  272 ( 67%)]  Loss: 1.8649\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.1712  Accuracy:   36/   95 (37.89%)\n",
            "\n",
            "Epoch: 48\n",
            "[    0/   16 (  0%)]  Loss: 2.2764\n",
            "[  256/  272 ( 67%)]  Loss: 1.5948\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.2103  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 49\n",
            "[    0/   16 (  0%)]  Loss: 2.0539\n",
            "[  256/  272 ( 67%)]  Loss: 2.1850\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2692  Accuracy:   30/   95 (31.58%)\n",
            "\n",
            "Epoch: 50\n",
            "[    0/   16 (  0%)]  Loss: 1.1933\n",
            "[  256/  272 ( 67%)]  Loss: 2.2025\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3021  Accuracy:   32/   95 (33.68%)\n",
            "\n",
            "Epoch: 51\n",
            "[    0/   16 (  0%)]  Loss: 2.0254\n",
            "[  256/  272 ( 67%)]  Loss: 1.6145\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2625  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 52\n",
            "[    0/   16 (  0%)]  Loss: 1.5953\n",
            "[  256/  272 ( 67%)]  Loss: 2.1743\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2463  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 53\n",
            "[    0/   16 (  0%)]  Loss: 1.4863\n",
            "[  256/  272 ( 67%)]  Loss: 2.1757\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3076  Accuracy:   33/   95 (34.74%)\n",
            "\n",
            "Epoch: 54\n",
            "[    0/   16 (  0%)]  Loss: 1.5864\n",
            "[  256/  272 ( 67%)]  Loss: 1.8807\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2348  Accuracy:   35/   95 (36.84%)\n",
            "\n",
            "Epoch: 55\n",
            "[    0/   16 (  0%)]  Loss: 1.7746\n",
            "[  256/  272 ( 67%)]  Loss: 0.9528\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3262  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 56\n",
            "[    0/   16 (  0%)]  Loss: 2.1561\n",
            "[  256/  272 ( 67%)]  Loss: 3.0918\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2541  Accuracy:   35/   95 (36.84%)\n",
            "\n",
            "Epoch: 57\n",
            "[    0/   16 (  0%)]  Loss: 2.0084\n",
            "[  256/  272 ( 67%)]  Loss: 1.6997\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3708  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 58\n",
            "[    0/   16 (  0%)]  Loss: 1.8073\n",
            "[  256/  272 ( 67%)]  Loss: 1.4024\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2585  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 59\n",
            "[    0/   16 (  0%)]  Loss: 1.9457\n",
            "[  256/  272 ( 67%)]  Loss: 2.1952\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.1122  Accuracy:   36/   95 (37.89%)\n",
            "\n",
            "Epoch: 60\n",
            "[    0/   16 (  0%)]  Loss: 2.3000\n",
            "[  256/  272 ( 67%)]  Loss: 1.7605\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2351  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 61\n",
            "[    0/   16 (  0%)]  Loss: 1.9782\n",
            "[  256/  272 ( 67%)]  Loss: 2.0432\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 2.1860  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 62\n",
            "[    0/   16 (  0%)]  Loss: 1.5133\n",
            "[  256/  272 ( 67%)]  Loss: 1.2086\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.3278  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 63\n",
            "[    0/   16 (  0%)]  Loss: 1.4915\n",
            "[  256/  272 ( 67%)]  Loss: 1.5587\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2868  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 64\n",
            "[    0/   16 (  0%)]  Loss: 1.9311\n",
            "[  256/  272 ( 67%)]  Loss: 2.1202\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3144  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 65\n",
            "[    0/   16 (  0%)]  Loss: 2.0435\n",
            "[  256/  272 ( 67%)]  Loss: 1.7653\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2860  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 66\n",
            "[    0/   16 (  0%)]  Loss: 1.4117\n",
            "[  256/  272 ( 67%)]  Loss: 1.9080\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3062  Accuracy:   37/   95 (38.95%)\n",
            "\n",
            "Epoch: 67\n",
            "[    0/   16 (  0%)]  Loss: 1.5219\n",
            "[  256/  272 ( 67%)]  Loss: 1.7831\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2413  Accuracy:   33/   95 (34.74%)\n",
            "\n",
            "Epoch: 68\n",
            "[    0/   16 (  0%)]  Loss: 1.4106\n",
            "[  256/  272 ( 67%)]  Loss: 2.1075\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2599  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 69\n",
            "[    0/   16 (  0%)]  Loss: 1.8975\n",
            "[  256/  272 ( 67%)]  Loss: 1.6021\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 2.2422  Accuracy:   36/   95 (37.89%)\n",
            "\n",
            "Epoch: 70\n",
            "[    0/   16 (  0%)]  Loss: 1.9607\n",
            "[  256/  272 ( 67%)]  Loss: 1.1355\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2631  Accuracy:   36/   95 (37.89%)\n",
            "\n",
            "Epoch: 71\n",
            "[    0/   16 (  0%)]  Loss: 1.3100\n",
            "[  256/  272 ( 67%)]  Loss: 1.8754\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2102  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 72\n",
            "[    0/   16 (  0%)]  Loss: 1.3724\n",
            "[  256/  272 ( 67%)]  Loss: 1.6695\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2233  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 73\n",
            "[    0/   16 (  0%)]  Loss: 1.2569\n",
            "[  256/  272 ( 67%)]  Loss: 2.1712\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4058  Accuracy:   34/   95 (35.79%)\n",
            "\n",
            "Epoch: 74\n",
            "[    0/   16 (  0%)]  Loss: 1.1967\n",
            "[  256/  272 ( 67%)]  Loss: 1.9770\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3140  Accuracy:   35/   95 (36.84%)\n",
            "\n",
            "Epoch: 75\n",
            "[    0/   16 (  0%)]  Loss: 1.6398\n",
            "[  256/  272 ( 67%)]  Loss: 1.8845\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3769  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 76\n",
            "[    0/   16 (  0%)]  Loss: 1.1752\n",
            "[  256/  272 ( 67%)]  Loss: 1.1146\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.2735  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 77\n",
            "[    0/   16 (  0%)]  Loss: 1.6329\n",
            "[  256/  272 ( 67%)]  Loss: 1.9873\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2417  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 78\n",
            "[    0/   16 (  0%)]  Loss: 1.4606\n",
            "[  256/  272 ( 67%)]  Loss: 1.3445\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.1994  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 79\n",
            "[    0/   16 (  0%)]  Loss: 1.8236\n",
            "[  256/  272 ( 67%)]  Loss: 1.4124\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4014  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 80\n",
            "[    0/   16 (  0%)]  Loss: 1.5773\n",
            "[  256/  272 ( 67%)]  Loss: 1.4977\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.3376  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 81\n",
            "[    0/   16 (  0%)]  Loss: 1.6170\n",
            "[  256/  272 ( 67%)]  Loss: 1.5294\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2605  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Epoch: 82\n",
            "[    0/   16 (  0%)]  Loss: 1.5693\n",
            "[  256/  272 ( 67%)]  Loss: 1.7367\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.2233  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 83\n",
            "[    0/   16 (  0%)]  Loss: 1.3018\n",
            "[  256/  272 ( 67%)]  Loss: 1.6349\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2542  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 84\n",
            "[    0/   16 (  0%)]  Loss: 1.4424\n",
            "[  256/  272 ( 67%)]  Loss: 1.0837\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2821  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 85\n",
            "[    0/   16 (  0%)]  Loss: 1.7791\n",
            "[  256/  272 ( 67%)]  Loss: 1.8909\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2535  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 86\n",
            "[    0/   16 (  0%)]  Loss: 1.5398\n",
            "[  256/  272 ( 67%)]  Loss: 1.8447\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.2234  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 87\n",
            "[    0/   16 (  0%)]  Loss: 1.5265\n",
            "[  256/  272 ( 67%)]  Loss: 1.0631\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.3285  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 88\n",
            "[    0/   16 (  0%)]  Loss: 1.9610\n",
            "[  256/  272 ( 67%)]  Loss: 1.6272\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4448  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 89\n",
            "[    0/   16 (  0%)]  Loss: 0.6984\n",
            "[  256/  272 ( 67%)]  Loss: 1.3570\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3580  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 90\n",
            "[    0/   16 (  0%)]  Loss: 1.4921\n",
            "[  256/  272 ( 67%)]  Loss: 1.9508\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4133  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 91\n",
            "[    0/   16 (  0%)]  Loss: 1.0087\n",
            "[  256/  272 ( 67%)]  Loss: 1.8962\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2628  Accuracy:   46/   95 (48.42%)\n",
            "\n",
            "Epoch: 92\n",
            "[    0/   16 (  0%)]  Loss: 0.8796\n",
            "[  256/  272 ( 67%)]  Loss: 1.7347\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2522  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 93\n",
            "[    0/   16 (  0%)]  Loss: 1.5938\n",
            "[  256/  272 ( 67%)]  Loss: 1.3939\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3010  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 94\n",
            "[    0/   16 (  0%)]  Loss: 1.3210\n",
            "[  256/  272 ( 67%)]  Loss: 1.6476\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2450  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 95\n",
            "[    0/   16 (  0%)]  Loss: 1.5041\n",
            "[  256/  272 ( 67%)]  Loss: 1.2883\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.5135  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 96\n",
            "[    0/   16 (  0%)]  Loss: 1.0596\n",
            "[  256/  272 ( 67%)]  Loss: 1.0145\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.2320  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 97\n",
            "[    0/   16 (  0%)]  Loss: 1.1137\n",
            "[  256/  272 ( 67%)]  Loss: 0.5967\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3224  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 98\n",
            "[    0/   16 (  0%)]  Loss: 1.3232\n",
            "[  256/  272 ( 67%)]  Loss: 1.0081\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.4380  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 99\n",
            "[    0/   16 (  0%)]  Loss: 1.2948\n",
            "[  256/  272 ( 67%)]  Loss: 0.8930\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4536  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 100\n",
            "[    0/   16 (  0%)]  Loss: 1.2983\n",
            "[  256/  272 ( 67%)]  Loss: 1.1006\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2623  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 101\n",
            "[    0/   16 (  0%)]  Loss: 1.8334\n",
            "[  256/  272 ( 67%)]  Loss: 1.0874\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3207  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 102\n",
            "[    0/   16 (  0%)]  Loss: 1.4429\n",
            "[  256/  272 ( 67%)]  Loss: 1.3920\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3402  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 103\n",
            "[    0/   16 (  0%)]  Loss: 1.4063\n",
            "[  256/  272 ( 67%)]  Loss: 0.7113\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3178  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 104\n",
            "[    0/   16 (  0%)]  Loss: 1.0141\n",
            "[  256/  272 ( 67%)]  Loss: 1.4637\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3843  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 105\n",
            "[    0/   16 (  0%)]  Loss: 1.2544\n",
            "[  256/  272 ( 67%)]  Loss: 2.0826\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.1846  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Epoch: 106\n",
            "[    0/   16 (  0%)]  Loss: 1.2211\n",
            "[  256/  272 ( 67%)]  Loss: 0.9201\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 2.3107  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 107\n",
            "[    0/   16 (  0%)]  Loss: 1.2067\n",
            "[  256/  272 ( 67%)]  Loss: 0.9710\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4602  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 108\n",
            "[    0/   16 (  0%)]  Loss: 1.4095\n",
            "[  256/  272 ( 67%)]  Loss: 0.8981\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.3737  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 109\n",
            "[    0/   16 (  0%)]  Loss: 1.2471\n",
            "[  256/  272 ( 67%)]  Loss: 1.3475\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.2784  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 110\n",
            "[    0/   16 (  0%)]  Loss: 0.8018\n",
            "[  256/  272 ( 67%)]  Loss: 0.8618\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3149  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 111\n",
            "[    0/   16 (  0%)]  Loss: 1.6601\n",
            "[  256/  272 ( 67%)]  Loss: 1.0109\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.3842  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Epoch: 112\n",
            "[    0/   16 (  0%)]  Loss: 1.0024\n",
            "[  256/  272 ( 67%)]  Loss: 0.9681\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3902  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 113\n",
            "[    0/   16 (  0%)]  Loss: 1.0014\n",
            "[  256/  272 ( 67%)]  Loss: 0.9215\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.2961  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Epoch: 114\n",
            "[    0/   16 (  0%)]  Loss: 0.7976\n",
            "[  256/  272 ( 67%)]  Loss: 1.4551\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.5317  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Epoch: 115\n",
            "[    0/   16 (  0%)]  Loss: 0.6730\n",
            "[  256/  272 ( 67%)]  Loss: 0.9761\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.4438  Accuracy:   45/   95 (47.37%)\n",
            "\n",
            "Epoch: 116\n",
            "[    0/   16 (  0%)]  Loss: 0.4557\n",
            "[  256/  272 ( 67%)]  Loss: 2.1716\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3655  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 117\n",
            "[    0/   16 (  0%)]  Loss: 1.1380\n",
            "[  256/  272 ( 67%)]  Loss: 0.8003\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3305  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 118\n",
            "[    0/   16 (  0%)]  Loss: 1.2251\n",
            "[  256/  272 ( 67%)]  Loss: 1.4236\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4296  Accuracy:   46/   95 (48.42%)\n",
            "\n",
            "Epoch: 119\n",
            "[    0/   16 (  0%)]  Loss: 1.3009\n",
            "[  256/  272 ( 67%)]  Loss: 1.1886\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.3677  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 120\n",
            "[    0/   16 (  0%)]  Loss: 0.7893\n",
            "[  256/  272 ( 67%)]  Loss: 0.5640\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.2587  Accuracy:   46/   95 (48.42%)\n",
            "\n",
            "Epoch: 121\n",
            "[    0/   16 (  0%)]  Loss: 0.5269\n",
            "[  256/  272 ( 67%)]  Loss: 0.8553\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.5876  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 122\n",
            "[    0/   16 (  0%)]  Loss: 0.8287\n",
            "[  256/  272 ( 67%)]  Loss: 1.4936\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.4847  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 123\n",
            "[    0/   16 (  0%)]  Loss: 0.6543\n",
            "[  256/  272 ( 67%)]  Loss: 1.5510\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.3753  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 124\n",
            "[    0/   16 (  0%)]  Loss: 1.1275\n",
            "[  256/  272 ( 67%)]  Loss: 0.9340\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.5621  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 125\n",
            "[    0/   16 (  0%)]  Loss: 0.5233\n",
            "[  256/  272 ( 67%)]  Loss: 1.8247\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5027  Accuracy:   48/   95 (50.53%)\n",
            "\n",
            "Epoch: 126\n",
            "[    0/   16 (  0%)]  Loss: 0.9021\n",
            "[  256/  272 ( 67%)]  Loss: 0.8862\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4031  Accuracy:   49/   95 (51.58%)\n",
            "\n",
            "Epoch: 127\n",
            "[    0/   16 (  0%)]  Loss: 0.7549\n",
            "[  256/  272 ( 67%)]  Loss: 0.8884\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4974  Accuracy:   45/   95 (47.37%)\n",
            "\n",
            "Epoch: 128\n",
            "[    0/   16 (  0%)]  Loss: 1.1367\n",
            "[  256/  272 ( 67%)]  Loss: 0.4002\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.6900  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 129\n",
            "[    0/   16 (  0%)]  Loss: 0.5096\n",
            "[  256/  272 ( 67%)]  Loss: 0.7361\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4583  Accuracy:   45/   95 (47.37%)\n",
            "\n",
            "Epoch: 130\n",
            "[    0/   16 (  0%)]  Loss: 1.4509\n",
            "[  256/  272 ( 67%)]  Loss: 1.0417\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 2.6564  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 131\n",
            "[    0/   16 (  0%)]  Loss: 1.5800\n",
            "[  256/  272 ( 67%)]  Loss: 0.7430\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 2.7892  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 132\n",
            "[    0/   16 (  0%)]  Loss: 0.8433\n",
            "[  256/  272 ( 67%)]  Loss: 1.2586\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.7278  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 133\n",
            "[    0/   16 (  0%)]  Loss: 1.1978\n",
            "[  256/  272 ( 67%)]  Loss: 1.3469\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.9034  Accuracy:   39/   95 (41.05%)\n",
            "\n",
            "Epoch: 134\n",
            "[    0/   16 (  0%)]  Loss: 0.3969\n",
            "[  256/  272 ( 67%)]  Loss: 0.8756\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5903  Accuracy:   45/   95 (47.37%)\n",
            "\n",
            "Epoch: 135\n",
            "[    0/   16 (  0%)]  Loss: 1.1765\n",
            "[  256/  272 ( 67%)]  Loss: 0.8470\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.7088  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 136\n",
            "[    0/   16 (  0%)]  Loss: 0.4294\n",
            "[  256/  272 ( 67%)]  Loss: 0.3521\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.7755  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 137\n",
            "[    0/   16 (  0%)]  Loss: 1.2227\n",
            "[  256/  272 ( 67%)]  Loss: 0.5656\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4140  Accuracy:   43/   95 (45.26%)\n",
            "\n",
            "Epoch: 138\n",
            "[    0/   16 (  0%)]  Loss: 1.2224\n",
            "[  256/  272 ( 67%)]  Loss: 0.7979\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.8325  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 139\n",
            "[    0/   16 (  0%)]  Loss: 0.5341\n",
            "[  256/  272 ( 67%)]  Loss: 0.6623\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 2.5728  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 140\n",
            "[    0/   16 (  0%)]  Loss: 0.5675\n",
            "[  256/  272 ( 67%)]  Loss: 0.7181\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.6412  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 141\n",
            "[    0/   16 (  0%)]  Loss: 0.6234\n",
            "[  256/  272 ( 67%)]  Loss: 0.9561\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.7567  Accuracy:   40/   95 (42.11%)\n",
            "\n",
            "Epoch: 142\n",
            "[    0/   16 (  0%)]  Loss: 1.0933\n",
            "[  256/  272 ( 67%)]  Loss: 0.5745\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.4677  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 143\n",
            "[    0/   16 (  0%)]  Loss: 0.8978\n",
            "[  256/  272 ( 67%)]  Loss: 0.4908\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.7191  Accuracy:   38/   95 (40.00%)\n",
            "\n",
            "Epoch: 144\n",
            "[    0/   16 (  0%)]  Loss: 0.5256\n",
            "[  256/  272 ( 67%)]  Loss: 0.3323\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.5112  Accuracy:   41/   95 (43.16%)\n",
            "\n",
            "Epoch: 145\n",
            "[    0/   16 (  0%)]  Loss: 0.6503\n",
            "[  256/  272 ( 67%)]  Loss: 0.4038\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 2.5315  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 146\n",
            "[    0/   16 (  0%)]  Loss: 0.4900\n",
            "[  256/  272 ( 67%)]  Loss: 0.8445\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 2.5117  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 147\n",
            "[    0/   16 (  0%)]  Loss: 0.8023\n",
            "[  256/  272 ( 67%)]  Loss: 1.0324\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 2.4615  Accuracy:   49/   95 (51.58%)\n",
            "\n",
            "Epoch: 148\n",
            "[    0/   16 (  0%)]  Loss: 1.0785\n",
            "[  256/  272 ( 67%)]  Loss: 1.3288\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.6264  Accuracy:   37/   95 (38.95%)\n",
            "\n",
            "Epoch: 149\n",
            "[    0/   16 (  0%)]  Loss: 0.1833\n",
            "[  256/  272 ( 67%)]  Loss: 1.0994\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 2.4783  Accuracy:   42/   95 (44.21%)\n",
            "\n",
            "Epoch: 150\n",
            "[    0/   16 (  0%)]  Loss: 0.4696\n",
            "[  256/  272 ( 67%)]  Loss: 1.2495\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 2.5110  Accuracy:   44/   95 (46.32%)\n",
            "\n",
            "Execution time 316.00648736953735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRLMJHaClbpP"
      },
      "source": [
        "# VGG19 Trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoNve3Q0lXKa"
      },
      "source": [
        "N_EPOCHS = 150\r\n",
        "\r\n",
        "model = models.vgg19_bn(pretrained = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZDPCalkkk32"
      },
      "source": [
        "for param in model.features:\r\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JncB479ziPYc"
      },
      "source": [
        "model.classifier[-1].out_features = 11\r\n",
        "model.cuda()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b5aC82aDln81",
        "outputId": "f18a13ec-aa36-42f0-c07c-6c5e0735156c"
      },
      "source": [
        "train_loss_history, test_loss_history = [], []\r\n",
        "\r\n",
        "e_start = time.time()\r\n",
        "for epoch in range(1, N_EPOCHS + 1):\r\n",
        "    print('Epoch:', epoch)\r\n",
        "    start_time = time.time()\r\n",
        "    train(model, optimizer, train_loader, train_loss_history)\r\n",
        "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\r\n",
        "    evaluate(model, validation_loader, test_loss_history)\r\n",
        "\r\n",
        "print(f'Execution time {time.time()-e_start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[    0/  381 (  0%)]  Loss: 6.9087\n",
            "Execution time:  3.99 seconds\n",
            "\n",
            "Average test loss: 6.7116  Accuracy:   19/   96 (19.79%)\n",
            "\n",
            "Epoch: 2\n",
            "[    0/  381 (  0%)]  Loss: 6.7992\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.5987  Accuracy:   30/   96 (31.25%)\n",
            "\n",
            "Epoch: 3\n",
            "[    0/  381 (  0%)]  Loss: 6.5814\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.5866  Accuracy:   31/   96 (32.29%)\n",
            "\n",
            "Epoch: 4\n",
            "[    0/  381 (  0%)]  Loss: 6.5031\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.5971  Accuracy:   30/   96 (31.25%)\n",
            "\n",
            "Epoch: 5\n",
            "[    0/  381 (  0%)]  Loss: 6.5694\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7006  Accuracy:   20/   96 (20.83%)\n",
            "\n",
            "Epoch: 6\n",
            "[    0/  381 (  0%)]  Loss: 6.5659\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7532  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 7\n",
            "[    0/  381 (  0%)]  Loss: 6.5971\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7532  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 8\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7532  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 9\n",
            "[    0/  381 (  0%)]  Loss: 6.5970\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7220  Accuracy:   18/   96 (18.75%)\n",
            "\n",
            "Epoch: 10\n",
            "[    0/  381 (  0%)]  Loss: 6.6595\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7220  Accuracy:   18/   96 (18.75%)\n",
            "\n",
            "Epoch: 11\n",
            "[    0/  381 (  0%)]  Loss: 6.5641\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6907  Accuracy:   21/   96 (21.88%)\n",
            "\n",
            "Epoch: 12\n",
            "[    0/  381 (  0%)]  Loss: 6.7217\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7116  Accuracy:   19/   96 (19.79%)\n",
            "\n",
            "Epoch: 13\n",
            "[    0/  381 (  0%)]  Loss: 6.7220\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7324  Accuracy:   17/   96 (17.71%)\n",
            "\n",
            "Epoch: 14\n",
            "[    0/  381 (  0%)]  Loss: 6.7532\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7532  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 15\n",
            "[    0/  381 (  0%)]  Loss: 6.7532\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7150  Accuracy:   19/   96 (19.79%)\n",
            "\n",
            "Epoch: 16\n",
            "[    0/  381 (  0%)]  Loss: 6.7220\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7025  Accuracy:   20/   96 (20.83%)\n",
            "\n",
            "Epoch: 17\n",
            "[    0/  381 (  0%)]  Loss: 6.7532\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7040  Accuracy:   20/   96 (20.83%)\n",
            "\n",
            "Epoch: 18\n",
            "[    0/  381 (  0%)]  Loss: 6.7199\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7636  Accuracy:   14/   96 (14.58%)\n",
            "\n",
            "Epoch: 19\n",
            "[    0/  381 (  0%)]  Loss: 6.7532\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7324  Accuracy:   17/   96 (17.71%)\n",
            "\n",
            "Epoch: 20\n",
            "[    0/  381 (  0%)]  Loss: 6.7220\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7532  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 21\n",
            "[    0/  381 (  0%)]  Loss: 6.7218\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.7530  Accuracy:   15/   96 (15.62%)\n",
            "\n",
            "Epoch: 22\n",
            "[    0/  381 (  0%)]  Loss: 6.6910\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 23\n",
            "[    0/  381 (  0%)]  Loss: 6.6280\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 24\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 25\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 26\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 27\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 28\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 29\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 30\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 31\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 32\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 33\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 34\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 35\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 36\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 37\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 38\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 39\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 40\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 41\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 42\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 43\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 44\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 45\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 46\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 47\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 48\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 49\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 50\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 51\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 52\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 53\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 54\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 55\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 56\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 57\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 58\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 59\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 60\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 61\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 62\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 63\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 64\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 65\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 66\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 67\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 68\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 69\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 70\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 71\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 72\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 73\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.98 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 74\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 75\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 76\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 77\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 78\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 79\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n",
            "\n",
            "Average test loss: 6.6074  Accuracy:   29/   96 (30.21%)\n",
            "\n",
            "Epoch: 80\n",
            "[    0/  381 (  0%)]  Loss: 6.6282\n",
            "Execution time:  3.97 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-326b787e0f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Execution time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{:5.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Execution time {time.time()-e_start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-b138f5a2ac08>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, loss_history)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-386b62c2045c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1856\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1858\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA8lYHV5L42G"
      },
      "source": [
        "# ResNET-Untrained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl5iM9eEL42J"
      },
      "source": [
        "N_EPOCHS = 150\r\n",
        "\r\n",
        "model = models.resnet50(num_classes = 27)\r\n",
        "model.cuda()\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rUBBZgVL42J",
        "outputId": "abbdfcdd-9540-40cd-804b-291ef272d254"
      },
      "source": [
        "train_loss_history, test_loss_history = [], []\r\n",
        "\r\n",
        "e_start = time.time()\r\n",
        "for epoch in range(1, N_EPOCHS + 1):\r\n",
        "    print('Epoch:', epoch)\r\n",
        "    start_time = time.time()\r\n",
        "    train(model, optimizer, train_loader, train_loss_history)\r\n",
        "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\r\n",
        "    evaluate(model, validation_loader, test_loss_history)\r\n",
        "\r\n",
        "print(f'Execution time {time.time()-e_start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[    0/   16 (  0%)]  Loss: 3.3534\n",
            "[  256/  272 ( 67%)]  Loss: 3.4302\n",
            "Execution time:  2.54 seconds\n",
            "\n",
            "Average test loss: 3.3178  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 2\n",
            "[    0/   16 (  0%)]  Loss: 3.4780\n",
            "[  256/  272 ( 67%)]  Loss: 3.2394\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.3138  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 3\n",
            "[    0/   16 (  0%)]  Loss: 2.7562\n",
            "[  256/  272 ( 67%)]  Loss: 3.4436\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.4042  Accuracy:    2/   95 (2.11%)\n",
            "\n",
            "Epoch: 4\n",
            "[    0/   16 (  0%)]  Loss: 3.3589\n",
            "[  256/  272 ( 67%)]  Loss: 3.0570\n",
            "Execution time:  2.54 seconds\n",
            "\n",
            "Average test loss: 3.4150  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 5\n",
            "[    0/   16 (  0%)]  Loss: 2.8129\n",
            "[  256/  272 ( 67%)]  Loss: 2.8335\n",
            "Execution time:  2.56 seconds\n",
            "\n",
            "Average test loss: 3.3664  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 6\n",
            "[    0/   16 (  0%)]  Loss: 2.9513\n",
            "[  256/  272 ( 67%)]  Loss: 3.5507\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.3731  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 7\n",
            "[    0/   16 (  0%)]  Loss: 3.0833\n",
            "[  256/  272 ( 67%)]  Loss: 3.5822\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.3125  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 8\n",
            "[    0/   16 (  0%)]  Loss: 3.4335\n",
            "[  256/  272 ( 67%)]  Loss: 3.1145\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.2913  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 9\n",
            "[    0/   16 (  0%)]  Loss: 3.2356\n",
            "[  256/  272 ( 67%)]  Loss: 2.9242\n",
            "Execution time:  2.54 seconds\n",
            "\n",
            "Average test loss: 3.3344  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 10\n",
            "[    0/   16 (  0%)]  Loss: 3.3177\n",
            "[  256/  272 ( 67%)]  Loss: 3.1249\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.3637  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 11\n",
            "[    0/   16 (  0%)]  Loss: 3.3705\n",
            "[  256/  272 ( 67%)]  Loss: 3.5380\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.4317  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 12\n",
            "[    0/   16 (  0%)]  Loss: 3.2166\n",
            "[  256/  272 ( 67%)]  Loss: 3.1501\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.2973  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 13\n",
            "[    0/   16 (  0%)]  Loss: 3.4155\n",
            "[  256/  272 ( 67%)]  Loss: 2.8377\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.3081  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 14\n",
            "[    0/   16 (  0%)]  Loss: 3.3157\n",
            "[  256/  272 ( 67%)]  Loss: 2.6574\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.3327  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 15\n",
            "[    0/   16 (  0%)]  Loss: 3.2141\n",
            "[  256/  272 ( 67%)]  Loss: 3.3160\n",
            "Execution time:  2.56 seconds\n",
            "\n",
            "Average test loss: 3.3793  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 16\n",
            "[    0/   16 (  0%)]  Loss: 3.1831\n",
            "[  256/  272 ( 67%)]  Loss: 2.8212\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.2418  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 17\n",
            "[    0/   16 (  0%)]  Loss: 3.3729\n",
            "[  256/  272 ( 67%)]  Loss: 3.0053\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.2613  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 18\n",
            "[    0/   16 (  0%)]  Loss: 3.0320\n",
            "[  256/  272 ( 67%)]  Loss: 3.4560\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.2595  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 19\n",
            "[    0/   16 (  0%)]  Loss: 3.3483\n",
            "[  256/  272 ( 67%)]  Loss: 3.3885\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.2691  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 20\n",
            "[    0/   16 (  0%)]  Loss: 3.1432\n",
            "[  256/  272 ( 67%)]  Loss: 3.6504\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.4273  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 21\n",
            "[    0/   16 (  0%)]  Loss: 3.2057\n",
            "[  256/  272 ( 67%)]  Loss: 3.1401\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.3729  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 22\n",
            "[    0/   16 (  0%)]  Loss: 2.9997\n",
            "[  256/  272 ( 67%)]  Loss: 3.3035\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.2870  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 23\n",
            "[    0/   16 (  0%)]  Loss: 2.9405\n",
            "[  256/  272 ( 67%)]  Loss: 3.2255\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.3188  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 24\n",
            "[    0/   16 (  0%)]  Loss: 2.8196\n",
            "[  256/  272 ( 67%)]  Loss: 3.3914\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.3192  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 25\n",
            "[    0/   16 (  0%)]  Loss: 3.3069\n",
            "[  256/  272 ( 67%)]  Loss: 2.9548\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.2457  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 26\n",
            "[    0/   16 (  0%)]  Loss: 3.3780\n",
            "[  256/  272 ( 67%)]  Loss: 2.9190\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.2664  Accuracy:    4/   95 (4.21%)\n",
            "\n",
            "Epoch: 27\n",
            "[    0/   16 (  0%)]  Loss: 3.0657\n",
            "[  256/  272 ( 67%)]  Loss: 3.5289\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.3569  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 28\n",
            "[    0/   16 (  0%)]  Loss: 3.2488\n",
            "[  256/  272 ( 67%)]  Loss: 3.0049\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.3546  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 29\n",
            "[    0/   16 (  0%)]  Loss: 3.3026\n",
            "[  256/  272 ( 67%)]  Loss: 2.8919\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.2632  Accuracy:    4/   95 (4.21%)\n",
            "\n",
            "Epoch: 30\n",
            "[    0/   16 (  0%)]  Loss: 2.8245\n",
            "[  256/  272 ( 67%)]  Loss: 3.3375\n",
            "Execution time:  2.58 seconds\n",
            "\n",
            "Average test loss: 3.2536  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 31\n",
            "[    0/   16 (  0%)]  Loss: 3.1321\n",
            "[  256/  272 ( 67%)]  Loss: 3.1289\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.3476  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 32\n",
            "[    0/   16 (  0%)]  Loss: 2.8694\n",
            "[  256/  272 ( 67%)]  Loss: 3.3221\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.2411  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 33\n",
            "[    0/   16 (  0%)]  Loss: 2.7824\n",
            "[  256/  272 ( 67%)]  Loss: 3.1538\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.3005  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 34\n",
            "[    0/   16 (  0%)]  Loss: 2.7084\n",
            "[  256/  272 ( 67%)]  Loss: 2.8721\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.2626  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 35\n",
            "[    0/   16 (  0%)]  Loss: 2.8035\n",
            "[  256/  272 ( 67%)]  Loss: 2.9176\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.2501  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 36\n",
            "[    0/   16 (  0%)]  Loss: 2.8965\n",
            "[  256/  272 ( 67%)]  Loss: 2.5005\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.2060  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 37\n",
            "[    0/   16 (  0%)]  Loss: 2.9243\n",
            "[  256/  272 ( 67%)]  Loss: 3.0364\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.2218  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 38\n",
            "[    0/   16 (  0%)]  Loss: 3.1012\n",
            "[  256/  272 ( 67%)]  Loss: 2.7826\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.2418  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 39\n",
            "[    0/   16 (  0%)]  Loss: 3.0292\n",
            "[  256/  272 ( 67%)]  Loss: 3.0796\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 3.1368  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 40\n",
            "[    0/   16 (  0%)]  Loss: 2.7330\n",
            "[  256/  272 ( 67%)]  Loss: 3.4832\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.2149  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 41\n",
            "[    0/   16 (  0%)]  Loss: 2.7084\n",
            "[  256/  272 ( 67%)]  Loss: 3.0445\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.2164  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 42\n",
            "[    0/   16 (  0%)]  Loss: 3.0389\n",
            "[  256/  272 ( 67%)]  Loss: 2.7120\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.2671  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 43\n",
            "[    0/   16 (  0%)]  Loss: 2.8313\n",
            "[  256/  272 ( 67%)]  Loss: 2.7632\n",
            "Execution time:  2.54 seconds\n",
            "\n",
            "Average test loss: 3.1422  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 44\n",
            "[    0/   16 (  0%)]  Loss: 2.9405\n",
            "[  256/  272 ( 67%)]  Loss: 3.0445\n",
            "Execution time:  2.56 seconds\n",
            "\n",
            "Average test loss: 3.1814  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 45\n",
            "[    0/   16 (  0%)]  Loss: 3.1441\n",
            "[  256/  272 ( 67%)]  Loss: 3.1621\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.2208  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 46\n",
            "[    0/   16 (  0%)]  Loss: 2.7662\n",
            "[  256/  272 ( 67%)]  Loss: 2.8937\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.1271  Accuracy:   10/   95 (10.53%)\n",
            "\n",
            "Epoch: 47\n",
            "[    0/   16 (  0%)]  Loss: 3.3746\n",
            "[  256/  272 ( 67%)]  Loss: 3.3981\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 3.0537  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 48\n",
            "[    0/   16 (  0%)]  Loss: 2.6643\n",
            "[  256/  272 ( 67%)]  Loss: 3.1193\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.2620  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 49\n",
            "[    0/   16 (  0%)]  Loss: 3.2074\n",
            "[  256/  272 ( 67%)]  Loss: 3.2586\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.1200  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 50\n",
            "[    0/   16 (  0%)]  Loss: 2.9300\n",
            "[  256/  272 ( 67%)]  Loss: 3.1183\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 3.1186  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 51\n",
            "[    0/   16 (  0%)]  Loss: 3.1249\n",
            "[  256/  272 ( 67%)]  Loss: 3.2800\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.1385  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 52\n",
            "[    0/   16 (  0%)]  Loss: 3.0989\n",
            "[  256/  272 ( 67%)]  Loss: 3.2378\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.1070  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 53\n",
            "[    0/   16 (  0%)]  Loss: 2.6385\n",
            "[  256/  272 ( 67%)]  Loss: 2.8270\n",
            "Execution time:  2.55 seconds\n",
            "\n",
            "Average test loss: 3.2295  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 54\n",
            "[    0/   16 (  0%)]  Loss: 2.8744\n",
            "[  256/  272 ( 67%)]  Loss: 3.0519\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.2332  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 55\n",
            "[    0/   16 (  0%)]  Loss: 2.9159\n",
            "[  256/  272 ( 67%)]  Loss: 3.2288\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.1472  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 56\n",
            "[    0/   16 (  0%)]  Loss: 2.8412\n",
            "[  256/  272 ( 67%)]  Loss: 2.6793\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.1831  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 57\n",
            "[    0/   16 (  0%)]  Loss: 2.6087\n",
            "[  256/  272 ( 67%)]  Loss: 2.8684\n",
            "Execution time:  2.56 seconds\n",
            "\n",
            "Average test loss: 3.0809  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 58\n",
            "[    0/   16 (  0%)]  Loss: 2.7871\n",
            "[  256/  272 ( 67%)]  Loss: 2.8837\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0585  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 59\n",
            "[    0/   16 (  0%)]  Loss: 3.1542\n",
            "[  256/  272 ( 67%)]  Loss: 2.7313\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 2.9790  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 60\n",
            "[    0/   16 (  0%)]  Loss: 3.2293\n",
            "[  256/  272 ( 67%)]  Loss: 3.3771\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0419  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 61\n",
            "[    0/   16 (  0%)]  Loss: 3.1259\n",
            "[  256/  272 ( 67%)]  Loss: 3.1517\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 3.0515  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 62\n",
            "[    0/   16 (  0%)]  Loss: 2.9638\n",
            "[  256/  272 ( 67%)]  Loss: 3.0068\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0840  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 63\n",
            "[    0/   16 (  0%)]  Loss: 2.7932\n",
            "[  256/  272 ( 67%)]  Loss: 2.6591\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9463  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 64\n",
            "[    0/   16 (  0%)]  Loss: 2.9105\n",
            "[  256/  272 ( 67%)]  Loss: 2.9244\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0080  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 65\n",
            "[    0/   16 (  0%)]  Loss: 2.9187\n",
            "[  256/  272 ( 67%)]  Loss: 3.0244\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 3.0143  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 66\n",
            "[    0/   16 (  0%)]  Loss: 3.3010\n",
            "[  256/  272 ( 67%)]  Loss: 2.7760\n",
            "Execution time:  2.55 seconds\n",
            "\n",
            "Average test loss: 3.0300  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 67\n",
            "[    0/   16 (  0%)]  Loss: 3.0608\n",
            "[  256/  272 ( 67%)]  Loss: 2.9258\n",
            "Execution time:  2.54 seconds\n",
            "\n",
            "Average test loss: 3.0929  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 68\n",
            "[    0/   16 (  0%)]  Loss: 2.9458\n",
            "[  256/  272 ( 67%)]  Loss: 2.9281\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 3.0975  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 69\n",
            "[    0/   16 (  0%)]  Loss: 3.0993\n",
            "[  256/  272 ( 67%)]  Loss: 3.1750\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0075  Accuracy:    6/   95 (6.32%)\n",
            "\n",
            "Epoch: 70\n",
            "[    0/   16 (  0%)]  Loss: 2.8936\n",
            "[  256/  272 ( 67%)]  Loss: 3.2644\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.1638  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 71\n",
            "[    0/   16 (  0%)]  Loss: 3.5704\n",
            "[  256/  272 ( 67%)]  Loss: 2.5601\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 3.0440  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 72\n",
            "[    0/   16 (  0%)]  Loss: 3.1318\n",
            "[  256/  272 ( 67%)]  Loss: 2.9412\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0729  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 73\n",
            "[    0/   16 (  0%)]  Loss: 2.8561\n",
            "[  256/  272 ( 67%)]  Loss: 2.8142\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0118  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 74\n",
            "[    0/   16 (  0%)]  Loss: 2.9149\n",
            "[  256/  272 ( 67%)]  Loss: 2.8777\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0439  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 75\n",
            "[    0/   16 (  0%)]  Loss: 2.7338\n",
            "[  256/  272 ( 67%)]  Loss: 2.9192\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0433  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 76\n",
            "[    0/   16 (  0%)]  Loss: 3.0434\n",
            "[  256/  272 ( 67%)]  Loss: 3.0186\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 3.0220  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 77\n",
            "[    0/   16 (  0%)]  Loss: 2.9256\n",
            "[  256/  272 ( 67%)]  Loss: 2.9046\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.0644  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 78\n",
            "[    0/   16 (  0%)]  Loss: 2.5810\n",
            "[  256/  272 ( 67%)]  Loss: 2.8170\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 3.0237  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 79\n",
            "[    0/   16 (  0%)]  Loss: 2.7589\n",
            "[  256/  272 ( 67%)]  Loss: 2.5063\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 2.9822  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 80\n",
            "[    0/   16 (  0%)]  Loss: 2.4830\n",
            "[  256/  272 ( 67%)]  Loss: 3.2607\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.9813  Accuracy:    8/   95 (8.42%)\n",
            "\n",
            "Epoch: 81\n",
            "[    0/   16 (  0%)]  Loss: 2.6837\n",
            "[  256/  272 ( 67%)]  Loss: 2.7127\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9912  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 82\n",
            "[    0/   16 (  0%)]  Loss: 2.5134\n",
            "[  256/  272 ( 67%)]  Loss: 2.8882\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 3.0024  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 83\n",
            "[    0/   16 (  0%)]  Loss: 2.6449\n",
            "[  256/  272 ( 67%)]  Loss: 2.5502\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9432  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 84\n",
            "[    0/   16 (  0%)]  Loss: 2.6362\n",
            "[  256/  272 ( 67%)]  Loss: 3.2725\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9803  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 85\n",
            "[    0/   16 (  0%)]  Loss: 3.0536\n",
            "[  256/  272 ( 67%)]  Loss: 2.9871\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 2.9807  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 86\n",
            "[    0/   16 (  0%)]  Loss: 3.0473\n",
            "[  256/  272 ( 67%)]  Loss: 2.5979\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 3.0663  Accuracy:    7/   95 (7.37%)\n",
            "\n",
            "Epoch: 87\n",
            "[    0/   16 (  0%)]  Loss: 2.6723\n",
            "[  256/  272 ( 67%)]  Loss: 2.8341\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 2.9605  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 88\n",
            "[    0/   16 (  0%)]  Loss: 2.7371\n",
            "[  256/  272 ( 67%)]  Loss: 3.0594\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.8614  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 89\n",
            "[    0/   16 (  0%)]  Loss: 3.4951\n",
            "[  256/  272 ( 67%)]  Loss: 3.3725\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0142  Accuracy:    5/   95 (5.26%)\n",
            "\n",
            "Epoch: 90\n",
            "[    0/   16 (  0%)]  Loss: 2.9238\n",
            "[  256/  272 ( 67%)]  Loss: 2.7861\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9023  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 91\n",
            "[    0/   16 (  0%)]  Loss: 3.0119\n",
            "[  256/  272 ( 67%)]  Loss: 2.7657\n",
            "Execution time:  2.51 seconds\n",
            "\n",
            "Average test loss: 3.0356  Accuracy:   10/   95 (10.53%)\n",
            "\n",
            "Epoch: 92\n",
            "[    0/   16 (  0%)]  Loss: 2.5323\n",
            "[  256/  272 ( 67%)]  Loss: 3.2543\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 2.9952  Accuracy:   10/   95 (10.53%)\n",
            "\n",
            "Epoch: 93\n",
            "[    0/   16 (  0%)]  Loss: 2.7521\n",
            "[  256/  272 ( 67%)]  Loss: 3.4517\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 3.0081  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 94\n",
            "[    0/   16 (  0%)]  Loss: 3.0623\n",
            "[  256/  272 ( 67%)]  Loss: 2.8978\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9482  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 95\n",
            "[    0/   16 (  0%)]  Loss: 2.8721\n",
            "[  256/  272 ( 67%)]  Loss: 3.1449\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.9838  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 96\n",
            "[    0/   16 (  0%)]  Loss: 2.8065\n",
            "[  256/  272 ( 67%)]  Loss: 2.2673\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 3.0589  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 97\n",
            "[    0/   16 (  0%)]  Loss: 2.5194\n",
            "[  256/  272 ( 67%)]  Loss: 3.0823\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 2.8899  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 98\n",
            "[    0/   16 (  0%)]  Loss: 2.8643\n",
            "[  256/  272 ( 67%)]  Loss: 2.7975\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0095  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 99\n",
            "[    0/   16 (  0%)]  Loss: 2.8917\n",
            "[  256/  272 ( 67%)]  Loss: 2.8029\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9289  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 100\n",
            "[    0/   16 (  0%)]  Loss: 2.3370\n",
            "[  256/  272 ( 67%)]  Loss: 2.8321\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 3.0237  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 101\n",
            "[    0/   16 (  0%)]  Loss: 2.8084\n",
            "[  256/  272 ( 67%)]  Loss: 2.7765\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.9854  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 102\n",
            "[    0/   16 (  0%)]  Loss: 2.9035\n",
            "[  256/  272 ( 67%)]  Loss: 2.9725\n",
            "Execution time:  2.43 seconds\n",
            "\n",
            "Average test loss: 3.0113  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 103\n",
            "[    0/   16 (  0%)]  Loss: 3.4066\n",
            "[  256/  272 ( 67%)]  Loss: 2.3352\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 2.8341  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 104\n",
            "[    0/   16 (  0%)]  Loss: 2.8125\n",
            "[  256/  272 ( 67%)]  Loss: 2.7879\n",
            "Execution time:  2.53 seconds\n",
            "\n",
            "Average test loss: 2.9746  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 105\n",
            "[    0/   16 (  0%)]  Loss: 3.0366\n",
            "[  256/  272 ( 67%)]  Loss: 3.4324\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 2.8366  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 106\n",
            "[    0/   16 (  0%)]  Loss: 2.5083\n",
            "[  256/  272 ( 67%)]  Loss: 2.7009\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9263  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 107\n",
            "[    0/   16 (  0%)]  Loss: 2.5692\n",
            "[  256/  272 ( 67%)]  Loss: 3.1243\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 3.0262  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 108\n",
            "[    0/   16 (  0%)]  Loss: 3.0658\n",
            "[  256/  272 ( 67%)]  Loss: 3.0821\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 3.0098  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 109\n",
            "[    0/   16 (  0%)]  Loss: 3.8286\n",
            "[  256/  272 ( 67%)]  Loss: 2.8750\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9320  Accuracy:   10/   95 (10.53%)\n",
            "\n",
            "Epoch: 110\n",
            "[    0/   16 (  0%)]  Loss: 2.6689\n",
            "[  256/  272 ( 67%)]  Loss: 2.4774\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9021  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 111\n",
            "[    0/   16 (  0%)]  Loss: 3.0342\n",
            "[  256/  272 ( 67%)]  Loss: 2.3843\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9714  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 112\n",
            "[    0/   16 (  0%)]  Loss: 2.6715\n",
            "[  256/  272 ( 67%)]  Loss: 3.0174\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9170  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 113\n",
            "[    0/   16 (  0%)]  Loss: 2.9226\n",
            "[  256/  272 ( 67%)]  Loss: 2.6582\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 2.8996  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 114\n",
            "[    0/   16 (  0%)]  Loss: 2.5095\n",
            "[  256/  272 ( 67%)]  Loss: 2.8012\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9292  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 115\n",
            "[    0/   16 (  0%)]  Loss: 2.9454\n",
            "[  256/  272 ( 67%)]  Loss: 2.6789\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.8825  Accuracy:   21/   95 (22.11%)\n",
            "\n",
            "Epoch: 116\n",
            "[    0/   16 (  0%)]  Loss: 3.0538\n",
            "[  256/  272 ( 67%)]  Loss: 2.4407\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.9092  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 117\n",
            "[    0/   16 (  0%)]  Loss: 2.4362\n",
            "[  256/  272 ( 67%)]  Loss: 3.0351\n",
            "Execution time:  2.56 seconds\n",
            "\n",
            "Average test loss: 2.9599  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 118\n",
            "[    0/   16 (  0%)]  Loss: 2.7527\n",
            "[  256/  272 ( 67%)]  Loss: 2.5822\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 2.8755  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 119\n",
            "[    0/   16 (  0%)]  Loss: 2.5804\n",
            "[  256/  272 ( 67%)]  Loss: 2.6513\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.8721  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 120\n",
            "[    0/   16 (  0%)]  Loss: 3.1227\n",
            "[  256/  272 ( 67%)]  Loss: 2.7031\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.9775  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 121\n",
            "[    0/   16 (  0%)]  Loss: 2.4942\n",
            "[  256/  272 ( 67%)]  Loss: 2.5115\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.8305  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 122\n",
            "[    0/   16 (  0%)]  Loss: 2.6717\n",
            "[  256/  272 ( 67%)]  Loss: 3.1031\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.7022  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 123\n",
            "[    0/   16 (  0%)]  Loss: 2.4849\n",
            "[  256/  272 ( 67%)]  Loss: 3.2830\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.7939  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 124\n",
            "[    0/   16 (  0%)]  Loss: 2.5250\n",
            "[  256/  272 ( 67%)]  Loss: 2.4960\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.8424  Accuracy:   24/   95 (25.26%)\n",
            "\n",
            "Epoch: 125\n",
            "[    0/   16 (  0%)]  Loss: 2.7774\n",
            "[  256/  272 ( 67%)]  Loss: 2.2331\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9321  Accuracy:   20/   95 (21.05%)\n",
            "\n",
            "Epoch: 126\n",
            "[    0/   16 (  0%)]  Loss: 2.4868\n",
            "[  256/  272 ( 67%)]  Loss: 2.8116\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9760  Accuracy:   15/   95 (15.79%)\n",
            "\n",
            "Epoch: 127\n",
            "[    0/   16 (  0%)]  Loss: 2.1820\n",
            "[  256/  272 ( 67%)]  Loss: 2.5600\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.8681  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 128\n",
            "[    0/   16 (  0%)]  Loss: 2.5630\n",
            "[  256/  272 ( 67%)]  Loss: 2.9214\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.9570  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 129\n",
            "[    0/   16 (  0%)]  Loss: 2.4898\n",
            "[  256/  272 ( 67%)]  Loss: 2.7750\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 2.8872  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 130\n",
            "[    0/   16 (  0%)]  Loss: 2.2057\n",
            "[  256/  272 ( 67%)]  Loss: 3.0685\n",
            "Execution time:  2.52 seconds\n",
            "\n",
            "Average test loss: 2.8504  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 131\n",
            "[    0/   16 (  0%)]  Loss: 2.7887\n",
            "[  256/  272 ( 67%)]  Loss: 2.8257\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 2.8750  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 132\n",
            "[    0/   16 (  0%)]  Loss: 2.5169\n",
            "[  256/  272 ( 67%)]  Loss: 2.3073\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.8579  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 133\n",
            "[    0/   16 (  0%)]  Loss: 2.7572\n",
            "[  256/  272 ( 67%)]  Loss: 2.3603\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.7901  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 134\n",
            "[    0/   16 (  0%)]  Loss: 2.3031\n",
            "[  256/  272 ( 67%)]  Loss: 2.6182\n",
            "Execution time:  2.43 seconds\n",
            "\n",
            "Average test loss: 2.8308  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 135\n",
            "[    0/   16 (  0%)]  Loss: 2.5678\n",
            "[  256/  272 ( 67%)]  Loss: 2.7792\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.7851  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 136\n",
            "[    0/   16 (  0%)]  Loss: 2.9677\n",
            "[  256/  272 ( 67%)]  Loss: 2.7241\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 2.7941  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 137\n",
            "[    0/   16 (  0%)]  Loss: 2.6781\n",
            "[  256/  272 ( 67%)]  Loss: 2.9079\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.8342  Accuracy:   12/   95 (12.63%)\n",
            "\n",
            "Epoch: 138\n",
            "[    0/   16 (  0%)]  Loss: 2.6238\n",
            "[  256/  272 ( 67%)]  Loss: 2.6503\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.7964  Accuracy:   19/   95 (20.00%)\n",
            "\n",
            "Epoch: 139\n",
            "[    0/   16 (  0%)]  Loss: 2.1344\n",
            "[  256/  272 ( 67%)]  Loss: 3.1314\n",
            "Execution time:  2.47 seconds\n",
            "\n",
            "Average test loss: 2.9468  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 140\n",
            "[    0/   16 (  0%)]  Loss: 2.5058\n",
            "[  256/  272 ( 67%)]  Loss: 3.0239\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9176  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 141\n",
            "[    0/   16 (  0%)]  Loss: 2.6579\n",
            "[  256/  272 ( 67%)]  Loss: 2.4733\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.8190  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 142\n",
            "[    0/   16 (  0%)]  Loss: 2.6656\n",
            "[  256/  272 ( 67%)]  Loss: 2.7362\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 2.7714  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 143\n",
            "[    0/   16 (  0%)]  Loss: 2.6379\n",
            "[  256/  272 ( 67%)]  Loss: 2.8007\n",
            "Execution time:  2.49 seconds\n",
            "\n",
            "Average test loss: 2.9420  Accuracy:   13/   95 (13.68%)\n",
            "\n",
            "Epoch: 144\n",
            "[    0/   16 (  0%)]  Loss: 2.6073\n",
            "[  256/  272 ( 67%)]  Loss: 2.8797\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.8315  Accuracy:   11/   95 (11.58%)\n",
            "\n",
            "Epoch: 145\n",
            "[    0/   16 (  0%)]  Loss: 2.9401\n",
            "[  256/  272 ( 67%)]  Loss: 2.3157\n",
            "Execution time:  2.44 seconds\n",
            "\n",
            "Average test loss: 2.8619  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Epoch: 146\n",
            "[    0/   16 (  0%)]  Loss: 2.9290\n",
            "[  256/  272 ( 67%)]  Loss: 1.8974\n",
            "Execution time:  2.46 seconds\n",
            "\n",
            "Average test loss: 2.9005  Accuracy:    9/   95 (9.47%)\n",
            "\n",
            "Epoch: 147\n",
            "[    0/   16 (  0%)]  Loss: 2.4049\n",
            "[  256/  272 ( 67%)]  Loss: 2.4047\n",
            "Execution time:  2.50 seconds\n",
            "\n",
            "Average test loss: 2.8188  Accuracy:   14/   95 (14.74%)\n",
            "\n",
            "Epoch: 148\n",
            "[    0/   16 (  0%)]  Loss: 2.4807\n",
            "[  256/  272 ( 67%)]  Loss: 2.7344\n",
            "Execution time:  2.48 seconds\n",
            "\n",
            "Average test loss: 2.8420  Accuracy:   18/   95 (18.95%)\n",
            "\n",
            "Epoch: 149\n",
            "[    0/   16 (  0%)]  Loss: 2.4003\n",
            "[  256/  272 ( 67%)]  Loss: 2.8461\n",
            "Execution time:  2.45 seconds\n",
            "\n",
            "Average test loss: 2.8208  Accuracy:   16/   95 (16.84%)\n",
            "\n",
            "Epoch: 150\n",
            "[    0/   16 (  0%)]  Loss: 2.4939\n",
            "[  256/  272 ( 67%)]  Loss: 2.9173\n",
            "Execution time:  2.43 seconds\n",
            "\n",
            "Average test loss: 2.7310  Accuracy:   17/   95 (17.89%)\n",
            "\n",
            "Execution time 425.23316621780396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttfBqrQqmvyF"
      },
      "source": [
        "# Resnet 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9TFfwU2mvyI"
      },
      "source": [
        "N_EPOCHS = 150\r\n",
        "\r\n",
        "model = models.resnet50(pretrained = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUXGwVl0nAdn"
      },
      "source": [
        "model.requires_grad_(requires_grad=False)\r\n",
        "model.fc = nn.Sequential(nn.Linear(2048,512,bias = True),\r\n",
        "                         nn.Linear(512,11,bias=True))\r\n",
        "model.fc.requires_grad_(requires_grad=True)\r\n",
        "\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udU6-wAfmvyJ",
        "outputId": "1982521b-115d-4a71-847e-0ae824b3d14d"
      },
      "source": [
        "train_loss_history, test_loss_history, test_acc_history = [], [], []\r\n",
        "\r\n",
        "e_start = time.time()\r\n",
        "for epoch in range(1, N_EPOCHS + 1):\r\n",
        "    print('Epoch:', epoch)\r\n",
        "    start_time = time.time()\r\n",
        "    train(model, optimizer, train_loader, train_loss_history)\r\n",
        "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\r\n",
        "    evaluate(model, validation_loader, test_loss_history,test_acc_history)\r\n",
        "\r\n",
        "print(f'Execution time {time.time()-e_start}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[    0/  381 (  0%)]  Loss: 1.9461\n",
            "[   96/  381 ( 25%)]  Loss: 2.0144\n",
            "[  192/  381 ( 50%)]  Loss: 1.9287\n",
            "[  288/  381 ( 75%)]  Loss: 2.0195\n",
            "Execution time:  1.84 seconds\n",
            "\n",
            "Average test loss: 1.9584  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 2\n",
            "[    0/  381 (  0%)]  Loss: 1.9255\n",
            "[   96/  381 ( 25%)]  Loss: 1.9942\n",
            "[  192/  381 ( 50%)]  Loss: 1.9080\n",
            "[  288/  381 ( 75%)]  Loss: 2.0254\n",
            "Execution time:  1.84 seconds\n",
            "\n",
            "Average test loss: 1.9581  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 3\n",
            "[    0/  381 (  0%)]  Loss: 1.9313\n",
            "[   96/  381 ( 25%)]  Loss: 1.9996\n",
            "[  192/  381 ( 50%)]  Loss: 1.9277\n",
            "[  288/  381 ( 75%)]  Loss: 2.0302\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9577  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 4\n",
            "[    0/  381 (  0%)]  Loss: 1.9296\n",
            "[   96/  381 ( 25%)]  Loss: 2.0248\n",
            "[  192/  381 ( 50%)]  Loss: 1.8954\n",
            "[  288/  381 ( 75%)]  Loss: 2.0215\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9582  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 5\n",
            "[    0/  381 (  0%)]  Loss: 1.9411\n",
            "[   96/  381 ( 25%)]  Loss: 2.0088\n",
            "[  192/  381 ( 50%)]  Loss: 1.9289\n",
            "[  288/  381 ( 75%)]  Loss: 2.0226\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9571  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 6\n",
            "[    0/  381 (  0%)]  Loss: 1.9289\n",
            "[   96/  381 ( 25%)]  Loss: 1.9883\n",
            "[  192/  381 ( 50%)]  Loss: 1.8949\n",
            "[  288/  381 ( 75%)]  Loss: 2.0267\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9569  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 7\n",
            "[    0/  381 (  0%)]  Loss: 1.9584\n",
            "[   96/  381 ( 25%)]  Loss: 2.0121\n",
            "[  192/  381 ( 50%)]  Loss: 1.9046\n",
            "[  288/  381 ( 75%)]  Loss: 2.0406\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9566  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 8\n",
            "[    0/  381 (  0%)]  Loss: 1.9349\n",
            "[   96/  381 ( 25%)]  Loss: 2.0135\n",
            "[  192/  381 ( 50%)]  Loss: 1.9249\n",
            "[  288/  381 ( 75%)]  Loss: 2.0390\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9573  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 9\n",
            "[    0/  381 (  0%)]  Loss: 1.9444\n",
            "[   96/  381 ( 25%)]  Loss: 2.0230\n",
            "[  192/  381 ( 50%)]  Loss: 1.9084\n",
            "[  288/  381 ( 75%)]  Loss: 2.0242\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9576  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 10\n",
            "[    0/  381 (  0%)]  Loss: 1.9594\n",
            "[   96/  381 ( 25%)]  Loss: 2.0174\n",
            "[  192/  381 ( 50%)]  Loss: 1.9085\n",
            "[  288/  381 ( 75%)]  Loss: 2.0388\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9582  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 11\n",
            "[    0/  381 (  0%)]  Loss: 1.9506\n",
            "[   96/  381 ( 25%)]  Loss: 2.0138\n",
            "[  192/  381 ( 50%)]  Loss: 1.9006\n",
            "[  288/  381 ( 75%)]  Loss: 2.0370\n",
            "Execution time:  1.84 seconds\n",
            "\n",
            "Average test loss: 1.9582  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 12\n",
            "[    0/  381 (  0%)]  Loss: 1.9323\n",
            "[   96/  381 ( 25%)]  Loss: 2.0161\n",
            "[  192/  381 ( 50%)]  Loss: 1.9055\n",
            "[  288/  381 ( 75%)]  Loss: 2.0157\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9578  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 13\n",
            "[    0/  381 (  0%)]  Loss: 1.9291\n",
            "[   96/  381 ( 25%)]  Loss: 1.9924\n",
            "[  192/  381 ( 50%)]  Loss: 1.9134\n",
            "[  288/  381 ( 75%)]  Loss: 2.0215\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9568  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 14\n",
            "[    0/  381 (  0%)]  Loss: 1.9385\n",
            "[   96/  381 ( 25%)]  Loss: 1.9923\n",
            "[  192/  381 ( 50%)]  Loss: 1.9060\n",
            "[  288/  381 ( 75%)]  Loss: 2.0251\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9563  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 15\n",
            "[    0/  381 (  0%)]  Loss: 1.9322\n",
            "[   96/  381 ( 25%)]  Loss: 2.0045\n",
            "[  192/  381 ( 50%)]  Loss: 1.8937\n",
            "[  288/  381 ( 75%)]  Loss: 2.0242\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9575  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 16\n",
            "[    0/  381 (  0%)]  Loss: 1.9429\n",
            "[   96/  381 ( 25%)]  Loss: 1.9871\n",
            "[  192/  381 ( 50%)]  Loss: 1.9138\n",
            "[  288/  381 ( 75%)]  Loss: 2.0181\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9575  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 17\n",
            "[    0/  381 (  0%)]  Loss: 1.9337\n",
            "[   96/  381 ( 25%)]  Loss: 2.0006\n",
            "[  192/  381 ( 50%)]  Loss: 1.8989\n",
            "[  288/  381 ( 75%)]  Loss: 2.0275\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9567  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 18\n",
            "[    0/  381 (  0%)]  Loss: 1.9297\n",
            "[   96/  381 ( 25%)]  Loss: 1.9803\n",
            "[  192/  381 ( 50%)]  Loss: 1.9014\n",
            "[  288/  381 ( 75%)]  Loss: 2.0231\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9564  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 19\n",
            "[    0/  381 (  0%)]  Loss: 1.9296\n",
            "[   96/  381 ( 25%)]  Loss: 2.0009\n",
            "[  192/  381 ( 50%)]  Loss: 1.9092\n",
            "[  288/  381 ( 75%)]  Loss: 2.0264\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9577  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 20\n",
            "[    0/  381 (  0%)]  Loss: 1.9439\n",
            "[   96/  381 ( 25%)]  Loss: 1.9949\n",
            "[  192/  381 ( 50%)]  Loss: 1.9082\n",
            "[  288/  381 ( 75%)]  Loss: 2.0323\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9578  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 21\n",
            "[    0/  381 (  0%)]  Loss: 1.9415\n",
            "[   96/  381 ( 25%)]  Loss: 2.0010\n",
            "[  192/  381 ( 50%)]  Loss: 1.9142\n",
            "[  288/  381 ( 75%)]  Loss: 2.0346\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9573  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 22\n",
            "[    0/  381 (  0%)]  Loss: 1.9375\n",
            "[   96/  381 ( 25%)]  Loss: 2.0078\n",
            "[  192/  381 ( 50%)]  Loss: 1.8987\n",
            "[  288/  381 ( 75%)]  Loss: 2.0360\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 1.9573  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 23\n",
            "[    0/  381 (  0%)]  Loss: 1.9253\n",
            "[   96/  381 ( 25%)]  Loss: 2.0025\n",
            "[  192/  381 ( 50%)]  Loss: 1.9010\n",
            "[  288/  381 ( 75%)]  Loss: 2.0608\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9552  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 24\n",
            "[    0/  381 (  0%)]  Loss: 1.9261\n",
            "[   96/  381 ( 25%)]  Loss: 1.9914\n",
            "[  192/  381 ( 50%)]  Loss: 1.9124\n",
            "[  288/  381 ( 75%)]  Loss: 2.0104\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9560  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 25\n",
            "[    0/  381 (  0%)]  Loss: 1.9380\n",
            "[   96/  381 ( 25%)]  Loss: 2.0106\n",
            "[  192/  381 ( 50%)]  Loss: 1.9068\n",
            "[  288/  381 ( 75%)]  Loss: 2.0320\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9557  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 26\n",
            "[    0/  381 (  0%)]  Loss: 1.9238\n",
            "[   96/  381 ( 25%)]  Loss: 2.0055\n",
            "[  192/  381 ( 50%)]  Loss: 1.9087\n",
            "[  288/  381 ( 75%)]  Loss: 2.0426\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9560  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 27\n",
            "[    0/  381 (  0%)]  Loss: 1.9452\n",
            "[   96/  381 ( 25%)]  Loss: 1.9994\n",
            "[  192/  381 ( 50%)]  Loss: 1.8975\n",
            "[  288/  381 ( 75%)]  Loss: 2.0152\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9546  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 28\n",
            "[    0/  381 (  0%)]  Loss: 1.9286\n",
            "[   96/  381 ( 25%)]  Loss: 2.0036\n",
            "[  192/  381 ( 50%)]  Loss: 1.9029\n",
            "[  288/  381 ( 75%)]  Loss: 2.0175\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9555  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 29\n",
            "[    0/  381 (  0%)]  Loss: 1.9399\n",
            "[   96/  381 ( 25%)]  Loss: 2.0177\n",
            "[  192/  381 ( 50%)]  Loss: 1.9095\n",
            "[  288/  381 ( 75%)]  Loss: 2.0140\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9562  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 30\n",
            "[    0/  381 (  0%)]  Loss: 1.9271\n",
            "[   96/  381 ( 25%)]  Loss: 1.9988\n",
            "[  192/  381 ( 50%)]  Loss: 1.9386\n",
            "[  288/  381 ( 75%)]  Loss: 2.0199\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9557  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 31\n",
            "[    0/  381 (  0%)]  Loss: 1.9523\n",
            "[   96/  381 ( 25%)]  Loss: 2.0118\n",
            "[  192/  381 ( 50%)]  Loss: 1.9094\n",
            "[  288/  381 ( 75%)]  Loss: 2.0155\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9555  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 32\n",
            "[    0/  381 (  0%)]  Loss: 1.9377\n",
            "[   96/  381 ( 25%)]  Loss: 1.9842\n",
            "[  192/  381 ( 50%)]  Loss: 1.9144\n",
            "[  288/  381 ( 75%)]  Loss: 2.0211\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9565  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 33\n",
            "[    0/  381 (  0%)]  Loss: 1.9310\n",
            "[   96/  381 ( 25%)]  Loss: 2.0189\n",
            "[  192/  381 ( 50%)]  Loss: 1.9383\n",
            "[  288/  381 ( 75%)]  Loss: 2.0326\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9549  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 34\n",
            "[    0/  381 (  0%)]  Loss: 1.9484\n",
            "[   96/  381 ( 25%)]  Loss: 2.0113\n",
            "[  192/  381 ( 50%)]  Loss: 1.9027\n",
            "[  288/  381 ( 75%)]  Loss: 2.0217\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9550  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 35\n",
            "[    0/  381 (  0%)]  Loss: 1.9489\n",
            "[   96/  381 ( 25%)]  Loss: 2.0091\n",
            "[  192/  381 ( 50%)]  Loss: 1.8909\n",
            "[  288/  381 ( 75%)]  Loss: 2.0169\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9550  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 36\n",
            "[    0/  381 (  0%)]  Loss: 1.9408\n",
            "[   96/  381 ( 25%)]  Loss: 2.0041\n",
            "[  192/  381 ( 50%)]  Loss: 1.9034\n",
            "[  288/  381 ( 75%)]  Loss: 2.0346\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9541  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 37\n",
            "[    0/  381 (  0%)]  Loss: 1.9329\n",
            "[   96/  381 ( 25%)]  Loss: 1.9917\n",
            "[  192/  381 ( 50%)]  Loss: 1.8907\n",
            "[  288/  381 ( 75%)]  Loss: 2.0292\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 1.9542  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 38\n",
            "[    0/  381 (  0%)]  Loss: 1.9272\n",
            "[   96/  381 ( 25%)]  Loss: 1.9911\n",
            "[  192/  381 ( 50%)]  Loss: 1.9149\n",
            "[  288/  381 ( 75%)]  Loss: 2.0164\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9541  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 39\n",
            "[    0/  381 (  0%)]  Loss: 1.9390\n",
            "[   96/  381 ( 25%)]  Loss: 1.9996\n",
            "[  192/  381 ( 50%)]  Loss: 1.9128\n",
            "[  288/  381 ( 75%)]  Loss: 2.0274\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9539  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 40\n",
            "[    0/  381 (  0%)]  Loss: 1.9352\n",
            "[   96/  381 ( 25%)]  Loss: 2.0014\n",
            "[  192/  381 ( 50%)]  Loss: 1.8943\n",
            "[  288/  381 ( 75%)]  Loss: 2.0184\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9535  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 41\n",
            "[    0/  381 (  0%)]  Loss: 1.9276\n",
            "[   96/  381 ( 25%)]  Loss: 2.0231\n",
            "[  192/  381 ( 50%)]  Loss: 1.9216\n",
            "[  288/  381 ( 75%)]  Loss: 2.0149\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9530  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 42\n",
            "[    0/  381 (  0%)]  Loss: 1.9310\n",
            "[   96/  381 ( 25%)]  Loss: 1.9824\n",
            "[  192/  381 ( 50%)]  Loss: 1.8949\n",
            "[  288/  381 ( 75%)]  Loss: 2.0138\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9544  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 43\n",
            "[    0/  381 (  0%)]  Loss: 1.9386\n",
            "[   96/  381 ( 25%)]  Loss: 2.0023\n",
            "[  192/  381 ( 50%)]  Loss: 1.8917\n",
            "[  288/  381 ( 75%)]  Loss: 2.0361\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9538  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 44\n",
            "[    0/  381 (  0%)]  Loss: 1.9213\n",
            "[   96/  381 ( 25%)]  Loss: 2.0149\n",
            "[  192/  381 ( 50%)]  Loss: 1.9085\n",
            "[  288/  381 ( 75%)]  Loss: 2.0110\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9543  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 45\n",
            "[    0/  381 (  0%)]  Loss: 1.9152\n",
            "[   96/  381 ( 25%)]  Loss: 2.0060\n",
            "[  192/  381 ( 50%)]  Loss: 1.9275\n",
            "[  288/  381 ( 75%)]  Loss: 2.0287\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9560  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 46\n",
            "[    0/  381 (  0%)]  Loss: 1.9426\n",
            "[   96/  381 ( 25%)]  Loss: 2.0064\n",
            "[  192/  381 ( 50%)]  Loss: 1.9112\n",
            "[  288/  381 ( 75%)]  Loss: 2.0332\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9545  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 47\n",
            "[    0/  381 (  0%)]  Loss: 1.9208\n",
            "[   96/  381 ( 25%)]  Loss: 2.0007\n",
            "[  192/  381 ( 50%)]  Loss: 1.9194\n",
            "[  288/  381 ( 75%)]  Loss: 2.0159\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9538  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 48\n",
            "[    0/  381 (  0%)]  Loss: 1.9343\n",
            "[   96/  381 ( 25%)]  Loss: 1.9943\n",
            "[  192/  381 ( 50%)]  Loss: 1.9339\n",
            "[  288/  381 ( 75%)]  Loss: 2.0148\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9542  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 49\n",
            "[    0/  381 (  0%)]  Loss: 1.9493\n",
            "[   96/  381 ( 25%)]  Loss: 2.0048\n",
            "[  192/  381 ( 50%)]  Loss: 1.8962\n",
            "[  288/  381 ( 75%)]  Loss: 2.0316\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9547  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 50\n",
            "[    0/  381 (  0%)]  Loss: 1.9295\n",
            "[   96/  381 ( 25%)]  Loss: 1.9920\n",
            "[  192/  381 ( 50%)]  Loss: 1.9212\n",
            "[  288/  381 ( 75%)]  Loss: 2.0248\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9530  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 51\n",
            "[    0/  381 (  0%)]  Loss: 1.9397\n",
            "[   96/  381 ( 25%)]  Loss: 2.0181\n",
            "[  192/  381 ( 50%)]  Loss: 1.8947\n",
            "[  288/  381 ( 75%)]  Loss: 2.0211\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9545  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 52\n",
            "[    0/  381 (  0%)]  Loss: 1.9432\n",
            "[   96/  381 ( 25%)]  Loss: 2.0293\n",
            "[  192/  381 ( 50%)]  Loss: 1.8988\n",
            "[  288/  381 ( 75%)]  Loss: 2.0138\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9534  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 53\n",
            "[    0/  381 (  0%)]  Loss: 1.9472\n",
            "[   96/  381 ( 25%)]  Loss: 1.9992\n",
            "[  192/  381 ( 50%)]  Loss: 1.9015\n",
            "[  288/  381 ( 75%)]  Loss: 2.0207\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9531  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 54\n",
            "[    0/  381 (  0%)]  Loss: 1.9236\n",
            "[   96/  381 ( 25%)]  Loss: 1.9887\n",
            "[  192/  381 ( 50%)]  Loss: 1.8892\n",
            "[  288/  381 ( 75%)]  Loss: 2.0210\n",
            "Execution time:  1.85 seconds\n",
            "\n",
            "Average test loss: 1.9531  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 55\n",
            "[    0/  381 (  0%)]  Loss: 1.9403\n",
            "[   96/  381 ( 25%)]  Loss: 1.9959\n",
            "[  192/  381 ( 50%)]  Loss: 1.9003\n",
            "[  288/  381 ( 75%)]  Loss: 2.0103\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 1.9531  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 56\n",
            "[    0/  381 (  0%)]  Loss: 1.9254\n",
            "[   96/  381 ( 25%)]  Loss: 1.9860\n",
            "[  192/  381 ( 50%)]  Loss: 1.9081\n",
            "[  288/  381 ( 75%)]  Loss: 2.0222\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9525  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 57\n",
            "[    0/  381 (  0%)]  Loss: 1.9286\n",
            "[   96/  381 ( 25%)]  Loss: 1.9921\n",
            "[  192/  381 ( 50%)]  Loss: 1.9067\n",
            "[  288/  381 ( 75%)]  Loss: 2.0332\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9536  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 58\n",
            "[    0/  381 (  0%)]  Loss: 1.9429\n",
            "[   96/  381 ( 25%)]  Loss: 1.9833\n",
            "[  192/  381 ( 50%)]  Loss: 1.8986\n",
            "[  288/  381 ( 75%)]  Loss: 2.0322\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9514  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 59\n",
            "[    0/  381 (  0%)]  Loss: 1.9354\n",
            "[   96/  381 ( 25%)]  Loss: 1.9965\n",
            "[  192/  381 ( 50%)]  Loss: 1.8976\n",
            "[  288/  381 ( 75%)]  Loss: 2.0102\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9530  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 60\n",
            "[    0/  381 (  0%)]  Loss: 1.9274\n",
            "[   96/  381 ( 25%)]  Loss: 1.9880\n",
            "[  192/  381 ( 50%)]  Loss: 1.9061\n",
            "[  288/  381 ( 75%)]  Loss: 2.0136\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9523  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 61\n",
            "[    0/  381 (  0%)]  Loss: 1.9309\n",
            "[   96/  381 ( 25%)]  Loss: 1.9898\n",
            "[  192/  381 ( 50%)]  Loss: 1.8954\n",
            "[  288/  381 ( 75%)]  Loss: 2.0082\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 62\n",
            "[    0/  381 (  0%)]  Loss: 1.9360\n",
            "[   96/  381 ( 25%)]  Loss: 1.9880\n",
            "[  192/  381 ( 50%)]  Loss: 1.9144\n",
            "[  288/  381 ( 75%)]  Loss: 2.0139\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9524  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 63\n",
            "[    0/  381 (  0%)]  Loss: 1.9294\n",
            "[   96/  381 ( 25%)]  Loss: 1.9835\n",
            "[  192/  381 ( 50%)]  Loss: 1.8979\n",
            "[  288/  381 ( 75%)]  Loss: 2.0245\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9545  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 64\n",
            "[    0/  381 (  0%)]  Loss: 1.9291\n",
            "[   96/  381 ( 25%)]  Loss: 1.9880\n",
            "[  192/  381 ( 50%)]  Loss: 1.8917\n",
            "[  288/  381 ( 75%)]  Loss: 2.0147\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9526  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 65\n",
            "[    0/  381 (  0%)]  Loss: 1.9343\n",
            "[   96/  381 ( 25%)]  Loss: 1.9917\n",
            "[  192/  381 ( 50%)]  Loss: 1.8939\n",
            "[  288/  381 ( 75%)]  Loss: 2.0155\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9518  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 66\n",
            "[    0/  381 (  0%)]  Loss: 1.9210\n",
            "[   96/  381 ( 25%)]  Loss: 1.9829\n",
            "[  192/  381 ( 50%)]  Loss: 1.9138\n",
            "[  288/  381 ( 75%)]  Loss: 2.0113\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 1.9517  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 67\n",
            "[    0/  381 (  0%)]  Loss: 1.9307\n",
            "[   96/  381 ( 25%)]  Loss: 1.9971\n",
            "[  192/  381 ( 50%)]  Loss: 1.9001\n",
            "[  288/  381 ( 75%)]  Loss: 2.0115\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9516  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 68\n",
            "[    0/  381 (  0%)]  Loss: 1.9456\n",
            "[   96/  381 ( 25%)]  Loss: 1.9809\n",
            "[  192/  381 ( 50%)]  Loss: 1.8918\n",
            "[  288/  381 ( 75%)]  Loss: 2.0152\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9512  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 69\n",
            "[    0/  381 (  0%)]  Loss: 1.9370\n",
            "[   96/  381 ( 25%)]  Loss: 1.9963\n",
            "[  192/  381 ( 50%)]  Loss: 1.9017\n",
            "[  288/  381 ( 75%)]  Loss: 2.0236\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9528  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 70\n",
            "[    0/  381 (  0%)]  Loss: 1.9235\n",
            "[   96/  381 ( 25%)]  Loss: 1.9904\n",
            "[  192/  381 ( 50%)]  Loss: 1.9005\n",
            "[  288/  381 ( 75%)]  Loss: 2.0121\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9531  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 71\n",
            "[    0/  381 (  0%)]  Loss: 1.9199\n",
            "[   96/  381 ( 25%)]  Loss: 1.9783\n",
            "[  192/  381 ( 50%)]  Loss: 1.9080\n",
            "[  288/  381 ( 75%)]  Loss: 2.0272\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 72\n",
            "[    0/  381 (  0%)]  Loss: 1.9236\n",
            "[   96/  381 ( 25%)]  Loss: 1.9892\n",
            "[  192/  381 ( 50%)]  Loss: 1.9130\n",
            "[  288/  381 ( 75%)]  Loss: 2.0102\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9521  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 73\n",
            "[    0/  381 (  0%)]  Loss: 1.9187\n",
            "[   96/  381 ( 25%)]  Loss: 1.9856\n",
            "[  192/  381 ( 50%)]  Loss: 1.8927\n",
            "[  288/  381 ( 75%)]  Loss: 2.0147\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9525  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 74\n",
            "[    0/  381 (  0%)]  Loss: 1.9401\n",
            "[   96/  381 ( 25%)]  Loss: 1.9889\n",
            "[  192/  381 ( 50%)]  Loss: 1.8954\n",
            "[  288/  381 ( 75%)]  Loss: 2.0133\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9531  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 75\n",
            "[    0/  381 (  0%)]  Loss: 1.9544\n",
            "[   96/  381 ( 25%)]  Loss: 2.0043\n",
            "[  192/  381 ( 50%)]  Loss: 1.9076\n",
            "[  288/  381 ( 75%)]  Loss: 2.0150\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9517  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 76\n",
            "[    0/  381 (  0%)]  Loss: 1.9256\n",
            "[   96/  381 ( 25%)]  Loss: 1.9903\n",
            "[  192/  381 ( 50%)]  Loss: 1.8877\n",
            "[  288/  381 ( 75%)]  Loss: 2.0177\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9521  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 77\n",
            "[    0/  381 (  0%)]  Loss: 1.9410\n",
            "[   96/  381 ( 25%)]  Loss: 1.9831\n",
            "[  192/  381 ( 50%)]  Loss: 1.9014\n",
            "[  288/  381 ( 75%)]  Loss: 2.0173\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9522  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 78\n",
            "[    0/  381 (  0%)]  Loss: 1.9246\n",
            "[   96/  381 ( 25%)]  Loss: 1.9805\n",
            "[  192/  381 ( 50%)]  Loss: 1.9186\n",
            "[  288/  381 ( 75%)]  Loss: 2.0122\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 1.9518  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 79\n",
            "[    0/  381 (  0%)]  Loss: 1.9398\n",
            "[   96/  381 ( 25%)]  Loss: 1.9832\n",
            "[  192/  381 ( 50%)]  Loss: 1.9145\n",
            "[  288/  381 ( 75%)]  Loss: 2.0120\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9521  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 80\n",
            "[    0/  381 (  0%)]  Loss: 1.9217\n",
            "[   96/  381 ( 25%)]  Loss: 1.9865\n",
            "[  192/  381 ( 50%)]  Loss: 1.9018\n",
            "[  288/  381 ( 75%)]  Loss: 2.0115\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 81\n",
            "[    0/  381 (  0%)]  Loss: 1.9269\n",
            "[   96/  381 ( 25%)]  Loss: 2.0000\n",
            "[  192/  381 ( 50%)]  Loss: 1.8877\n",
            "[  288/  381 ( 75%)]  Loss: 2.0239\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 82\n",
            "[    0/  381 (  0%)]  Loss: 1.9333\n",
            "[   96/  381 ( 25%)]  Loss: 1.9795\n",
            "[  192/  381 ( 50%)]  Loss: 1.9023\n",
            "[  288/  381 ( 75%)]  Loss: 2.0228\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9507  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 83\n",
            "[    0/  381 (  0%)]  Loss: 1.9160\n",
            "[   96/  381 ( 25%)]  Loss: 1.9818\n",
            "[  192/  381 ( 50%)]  Loss: 1.9138\n",
            "[  288/  381 ( 75%)]  Loss: 2.0140\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9505  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 84\n",
            "[    0/  381 (  0%)]  Loss: 1.9253\n",
            "[   96/  381 ( 25%)]  Loss: 1.9784\n",
            "[  192/  381 ( 50%)]  Loss: 1.8982\n",
            "[  288/  381 ( 75%)]  Loss: 2.0101\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9504  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 85\n",
            "[    0/  381 (  0%)]  Loss: 1.9293\n",
            "[   96/  381 ( 25%)]  Loss: 1.9831\n",
            "[  192/  381 ( 50%)]  Loss: 1.9041\n",
            "[  288/  381 ( 75%)]  Loss: 2.0109\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9507  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 86\n",
            "[    0/  381 (  0%)]  Loss: 1.9292\n",
            "[   96/  381 ( 25%)]  Loss: 1.9911\n",
            "[  192/  381 ( 50%)]  Loss: 1.8904\n",
            "[  288/  381 ( 75%)]  Loss: 2.0096\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9521  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 87\n",
            "[    0/  381 (  0%)]  Loss: 1.9262\n",
            "[   96/  381 ( 25%)]  Loss: 1.9812\n",
            "[  192/  381 ( 50%)]  Loss: 1.8997\n",
            "[  288/  381 ( 75%)]  Loss: 2.0220\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 1.9518  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 88\n",
            "[    0/  381 (  0%)]  Loss: 1.9381\n",
            "[   96/  381 ( 25%)]  Loss: 1.9842\n",
            "[  192/  381 ( 50%)]  Loss: 1.9072\n",
            "[  288/  381 ( 75%)]  Loss: 2.0134\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9525  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 89\n",
            "[    0/  381 (  0%)]  Loss: 1.9401\n",
            "[   96/  381 ( 25%)]  Loss: 1.9786\n",
            "[  192/  381 ( 50%)]  Loss: 1.9060\n",
            "[  288/  381 ( 75%)]  Loss: 2.0143\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9506  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 90\n",
            "[    0/  381 (  0%)]  Loss: 1.9301\n",
            "[   96/  381 ( 25%)]  Loss: 1.9883\n",
            "[  192/  381 ( 50%)]  Loss: 1.9010\n",
            "[  288/  381 ( 75%)]  Loss: 2.0116\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9508  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 91\n",
            "[    0/  381 (  0%)]  Loss: 1.9484\n",
            "[   96/  381 ( 25%)]  Loss: 1.9920\n",
            "[  192/  381 ( 50%)]  Loss: 1.9073\n",
            "[  288/  381 ( 75%)]  Loss: 2.0133\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9517  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 92\n",
            "[    0/  381 (  0%)]  Loss: 1.9318\n",
            "[   96/  381 ( 25%)]  Loss: 1.9903\n",
            "[  192/  381 ( 50%)]  Loss: 1.8980\n",
            "[  288/  381 ( 75%)]  Loss: 2.0136\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 93\n",
            "[    0/  381 (  0%)]  Loss: 1.9377\n",
            "[   96/  381 ( 25%)]  Loss: 1.9786\n",
            "[  192/  381 ( 50%)]  Loss: 1.8872\n",
            "[  288/  381 ( 75%)]  Loss: 2.0269\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9511  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 94\n",
            "[    0/  381 (  0%)]  Loss: 1.9372\n",
            "[   96/  381 ( 25%)]  Loss: 1.9908\n",
            "[  192/  381 ( 50%)]  Loss: 1.8938\n",
            "[  288/  381 ( 75%)]  Loss: 2.0129\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 95\n",
            "[    0/  381 (  0%)]  Loss: 1.9411\n",
            "[   96/  381 ( 25%)]  Loss: 1.9886\n",
            "[  192/  381 ( 50%)]  Loss: 1.8973\n",
            "[  288/  381 ( 75%)]  Loss: 2.0160\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9513  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 96\n",
            "[    0/  381 (  0%)]  Loss: 1.9376\n",
            "[   96/  381 ( 25%)]  Loss: 1.9799\n",
            "[  192/  381 ( 50%)]  Loss: 1.8968\n",
            "[  288/  381 ( 75%)]  Loss: 2.0129\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9508  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 97\n",
            "[    0/  381 (  0%)]  Loss: 1.9166\n",
            "[   96/  381 ( 25%)]  Loss: 1.9786\n",
            "[  192/  381 ( 50%)]  Loss: 1.9041\n",
            "[  288/  381 ( 75%)]  Loss: 2.0079\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9493  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 98\n",
            "[    0/  381 (  0%)]  Loss: 1.9180\n",
            "[   96/  381 ( 25%)]  Loss: 1.9920\n",
            "[  192/  381 ( 50%)]  Loss: 1.8920\n",
            "[  288/  381 ( 75%)]  Loss: 2.0089\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9507  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 99\n",
            "[    0/  381 (  0%)]  Loss: 1.9181\n",
            "[   96/  381 ( 25%)]  Loss: 1.9816\n",
            "[  192/  381 ( 50%)]  Loss: 1.8962\n",
            "[  288/  381 ( 75%)]  Loss: 2.0158\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9510  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 100\n",
            "[    0/  381 (  0%)]  Loss: 1.9169\n",
            "[   96/  381 ( 25%)]  Loss: 1.9861\n",
            "[  192/  381 ( 50%)]  Loss: 1.8922\n",
            "[  288/  381 ( 75%)]  Loss: 2.0105\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 101\n",
            "[    0/  381 (  0%)]  Loss: 1.9387\n",
            "[   96/  381 ( 25%)]  Loss: 1.9778\n",
            "[  192/  381 ( 50%)]  Loss: 1.9138\n",
            "[  288/  381 ( 75%)]  Loss: 2.0092\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9500  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 102\n",
            "[    0/  381 (  0%)]  Loss: 1.9239\n",
            "[   96/  381 ( 25%)]  Loss: 2.0070\n",
            "[  192/  381 ( 50%)]  Loss: 1.8921\n",
            "[  288/  381 ( 75%)]  Loss: 2.0084\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9494  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 103\n",
            "[    0/  381 (  0%)]  Loss: 1.9264\n",
            "[   96/  381 ( 25%)]  Loss: 1.9814\n",
            "[  192/  381 ( 50%)]  Loss: 1.9085\n",
            "[  288/  381 ( 75%)]  Loss: 2.0148\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9504  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 104\n",
            "[    0/  381 (  0%)]  Loss: 1.9350\n",
            "[   96/  381 ( 25%)]  Loss: 1.9790\n",
            "[  192/  381 ( 50%)]  Loss: 1.8973\n",
            "[  288/  381 ( 75%)]  Loss: 2.0192\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 105\n",
            "[    0/  381 (  0%)]  Loss: 1.9219\n",
            "[   96/  381 ( 25%)]  Loss: 1.9824\n",
            "[  192/  381 ( 50%)]  Loss: 1.8916\n",
            "[  288/  381 ( 75%)]  Loss: 2.0146\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9514  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 106\n",
            "[    0/  381 (  0%)]  Loss: 1.9280\n",
            "[   96/  381 ( 25%)]  Loss: 1.9851\n",
            "[  192/  381 ( 50%)]  Loss: 1.8917\n",
            "[  288/  381 ( 75%)]  Loss: 2.0081\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9502  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 107\n",
            "[    0/  381 (  0%)]  Loss: 1.9239\n",
            "[   96/  381 ( 25%)]  Loss: 1.9828\n",
            "[  192/  381 ( 50%)]  Loss: 1.8993\n",
            "[  288/  381 ( 75%)]  Loss: 2.0177\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9520  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 108\n",
            "[    0/  381 (  0%)]  Loss: 1.9200\n",
            "[   96/  381 ( 25%)]  Loss: 1.9905\n",
            "[  192/  381 ( 50%)]  Loss: 1.9075\n",
            "[  288/  381 ( 75%)]  Loss: 2.0130\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9515  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 109\n",
            "[    0/  381 (  0%)]  Loss: 1.9480\n",
            "[   96/  381 ( 25%)]  Loss: 1.9860\n",
            "[  192/  381 ( 50%)]  Loss: 1.8944\n",
            "[  288/  381 ( 75%)]  Loss: 2.0101\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9507  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 110\n",
            "[    0/  381 (  0%)]  Loss: 1.9458\n",
            "[   96/  381 ( 25%)]  Loss: 1.9839\n",
            "[  192/  381 ( 50%)]  Loss: 1.9023\n",
            "[  288/  381 ( 75%)]  Loss: 2.0194\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9532  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 111\n",
            "[    0/  381 (  0%)]  Loss: 1.9231\n",
            "[   96/  381 ( 25%)]  Loss: 1.9798\n",
            "[  192/  381 ( 50%)]  Loss: 1.8990\n",
            "[  288/  381 ( 75%)]  Loss: 2.0259\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9503  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 112\n",
            "[    0/  381 (  0%)]  Loss: 1.9428\n",
            "[   96/  381 ( 25%)]  Loss: 1.9796\n",
            "[  192/  381 ( 50%)]  Loss: 1.9032\n",
            "[  288/  381 ( 75%)]  Loss: 2.0218\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 113\n",
            "[    0/  381 (  0%)]  Loss: 1.9341\n",
            "[   96/  381 ( 25%)]  Loss: 1.9906\n",
            "[  192/  381 ( 50%)]  Loss: 1.8897\n",
            "[  288/  381 ( 75%)]  Loss: 2.0131\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9510  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 114\n",
            "[    0/  381 (  0%)]  Loss: 1.9222\n",
            "[   96/  381 ( 25%)]  Loss: 1.9791\n",
            "[  192/  381 ( 50%)]  Loss: 1.9060\n",
            "[  288/  381 ( 75%)]  Loss: 2.0294\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9511  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 115\n",
            "[    0/  381 (  0%)]  Loss: 1.9281\n",
            "[   96/  381 ( 25%)]  Loss: 1.9891\n",
            "[  192/  381 ( 50%)]  Loss: 1.9039\n",
            "[  288/  381 ( 75%)]  Loss: 2.0119\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9494  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 116\n",
            "[    0/  381 (  0%)]  Loss: 1.9355\n",
            "[   96/  381 ( 25%)]  Loss: 1.9873\n",
            "[  192/  381 ( 50%)]  Loss: 1.8933\n",
            "[  288/  381 ( 75%)]  Loss: 2.0361\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9506  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 117\n",
            "[    0/  381 (  0%)]  Loss: 1.9127\n",
            "[   96/  381 ( 25%)]  Loss: 1.9879\n",
            "[  192/  381 ( 50%)]  Loss: 1.9080\n",
            "[  288/  381 ( 75%)]  Loss: 2.0102\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9526  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 118\n",
            "[    0/  381 (  0%)]  Loss: 1.9211\n",
            "[   96/  381 ( 25%)]  Loss: 1.9797\n",
            "[  192/  381 ( 50%)]  Loss: 1.8922\n",
            "[  288/  381 ( 75%)]  Loss: 2.0159\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9525  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 119\n",
            "[    0/  381 (  0%)]  Loss: 1.9329\n",
            "[   96/  381 ( 25%)]  Loss: 1.9865\n",
            "[  192/  381 ( 50%)]  Loss: 1.9015\n",
            "[  288/  381 ( 75%)]  Loss: 2.0124\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9517  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 120\n",
            "[    0/  381 (  0%)]  Loss: 1.9218\n",
            "[   96/  381 ( 25%)]  Loss: 1.9803\n",
            "[  192/  381 ( 50%)]  Loss: 1.9052\n",
            "[  288/  381 ( 75%)]  Loss: 2.0120\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9501  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 121\n",
            "[    0/  381 (  0%)]  Loss: 1.9288\n",
            "[   96/  381 ( 25%)]  Loss: 1.9748\n",
            "[  192/  381 ( 50%)]  Loss: 1.9085\n",
            "[  288/  381 ( 75%)]  Loss: 2.0105\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 122\n",
            "[    0/  381 (  0%)]  Loss: 1.9260\n",
            "[   96/  381 ( 25%)]  Loss: 1.9805\n",
            "[  192/  381 ( 50%)]  Loss: 1.8981\n",
            "[  288/  381 ( 75%)]  Loss: 2.0156\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9502  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 123\n",
            "[    0/  381 (  0%)]  Loss: 1.9423\n",
            "[   96/  381 ( 25%)]  Loss: 1.9918\n",
            "[  192/  381 ( 50%)]  Loss: 1.8876\n",
            "[  288/  381 ( 75%)]  Loss: 2.0146\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9503  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 124\n",
            "[    0/  381 (  0%)]  Loss: 1.9165\n",
            "[   96/  381 ( 25%)]  Loss: 1.9836\n",
            "[  192/  381 ( 50%)]  Loss: 1.9125\n",
            "[  288/  381 ( 75%)]  Loss: 2.0065\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9499  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 125\n",
            "[    0/  381 (  0%)]  Loss: 1.9253\n",
            "[   96/  381 ( 25%)]  Loss: 1.9897\n",
            "[  192/  381 ( 50%)]  Loss: 1.9004\n",
            "[  288/  381 ( 75%)]  Loss: 2.0126\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9498  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 126\n",
            "[    0/  381 (  0%)]  Loss: 1.9335\n",
            "[   96/  381 ( 25%)]  Loss: 1.9803\n",
            "[  192/  381 ( 50%)]  Loss: 1.9083\n",
            "[  288/  381 ( 75%)]  Loss: 2.0247\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9501  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 127\n",
            "[    0/  381 (  0%)]  Loss: 1.9271\n",
            "[   96/  381 ( 25%)]  Loss: 1.9834\n",
            "[  192/  381 ( 50%)]  Loss: 1.8937\n",
            "[  288/  381 ( 75%)]  Loss: 2.0167\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9502  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 128\n",
            "[    0/  381 (  0%)]  Loss: 1.9242\n",
            "[   96/  381 ( 25%)]  Loss: 1.9801\n",
            "[  192/  381 ( 50%)]  Loss: 1.8980\n",
            "[  288/  381 ( 75%)]  Loss: 2.0170\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9502  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 129\n",
            "[    0/  381 (  0%)]  Loss: 1.9319\n",
            "[   96/  381 ( 25%)]  Loss: 1.9867\n",
            "[  192/  381 ( 50%)]  Loss: 1.8924\n",
            "[  288/  381 ( 75%)]  Loss: 2.0144\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9480  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 130\n",
            "[    0/  381 (  0%)]  Loss: 1.9374\n",
            "[   96/  381 ( 25%)]  Loss: 1.9763\n",
            "[  192/  381 ( 50%)]  Loss: 1.8921\n",
            "[  288/  381 ( 75%)]  Loss: 2.0100\n",
            "Execution time:  1.76 seconds\n",
            "\n",
            "Average test loss: 1.9494  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 131\n",
            "[    0/  381 (  0%)]  Loss: 1.9364\n",
            "[   96/  381 ( 25%)]  Loss: 1.9775\n",
            "[  192/  381 ( 50%)]  Loss: 1.8851\n",
            "[  288/  381 ( 75%)]  Loss: 2.0130\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9487  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 132\n",
            "[    0/  381 (  0%)]  Loss: 1.9303\n",
            "[   96/  381 ( 25%)]  Loss: 1.9763\n",
            "[  192/  381 ( 50%)]  Loss: 1.8968\n",
            "[  288/  381 ( 75%)]  Loss: 2.0237\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 1.9513  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 133\n",
            "[    0/  381 (  0%)]  Loss: 1.9257\n",
            "[   96/  381 ( 25%)]  Loss: 1.9798\n",
            "[  192/  381 ( 50%)]  Loss: 1.9145\n",
            "[  288/  381 ( 75%)]  Loss: 2.0123\n",
            "Execution time:  1.75 seconds\n",
            "\n",
            "Average test loss: 1.9533  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 134\n",
            "[    0/  381 (  0%)]  Loss: 1.9448\n",
            "[   96/  381 ( 25%)]  Loss: 1.9882\n",
            "[  192/  381 ( 50%)]  Loss: 1.8999\n",
            "[  288/  381 ( 75%)]  Loss: 2.0178\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9521  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 135\n",
            "[    0/  381 (  0%)]  Loss: 1.9161\n",
            "[   96/  381 ( 25%)]  Loss: 1.9902\n",
            "[  192/  381 ( 50%)]  Loss: 1.9049\n",
            "[  288/  381 ( 75%)]  Loss: 2.0176\n",
            "Execution time:  1.81 seconds\n",
            "\n",
            "Average test loss: 1.9497  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 136\n",
            "[    0/  381 (  0%)]  Loss: 1.9214\n",
            "[   96/  381 ( 25%)]  Loss: 1.9795\n",
            "[  192/  381 ( 50%)]  Loss: 1.8959\n",
            "[  288/  381 ( 75%)]  Loss: 2.0083\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9491  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 137\n",
            "[    0/  381 (  0%)]  Loss: 1.9194\n",
            "[   96/  381 ( 25%)]  Loss: 1.9803\n",
            "[  192/  381 ( 50%)]  Loss: 1.8906\n",
            "[  288/  381 ( 75%)]  Loss: 2.0089\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9497  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 138\n",
            "[    0/  381 (  0%)]  Loss: 1.9274\n",
            "[   96/  381 ( 25%)]  Loss: 1.9800\n",
            "[  192/  381 ( 50%)]  Loss: 1.8952\n",
            "[  288/  381 ( 75%)]  Loss: 2.0107\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9491  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 139\n",
            "[    0/  381 (  0%)]  Loss: 1.9504\n",
            "[   96/  381 ( 25%)]  Loss: 1.9914\n",
            "[  192/  381 ( 50%)]  Loss: 1.8866\n",
            "[  288/  381 ( 75%)]  Loss: 2.0099\n",
            "Execution time:  1.82 seconds\n",
            "\n",
            "Average test loss: 1.9491  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 140\n",
            "[    0/  381 (  0%)]  Loss: 1.9466\n",
            "[   96/  381 ( 25%)]  Loss: 1.9838\n",
            "[  192/  381 ( 50%)]  Loss: 1.8920\n",
            "[  288/  381 ( 75%)]  Loss: 2.0182\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9497  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 141\n",
            "[    0/  381 (  0%)]  Loss: 1.9320\n",
            "[   96/  381 ( 25%)]  Loss: 1.9846\n",
            "[  192/  381 ( 50%)]  Loss: 1.8896\n",
            "[  288/  381 ( 75%)]  Loss: 2.0109\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9475  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 142\n",
            "[    0/  381 (  0%)]  Loss: 1.9405\n",
            "[   96/  381 ( 25%)]  Loss: 1.9775\n",
            "[  192/  381 ( 50%)]  Loss: 1.8959\n",
            "[  288/  381 ( 75%)]  Loss: 2.0152\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9478  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 143\n",
            "[    0/  381 (  0%)]  Loss: 1.9286\n",
            "[   96/  381 ( 25%)]  Loss: 1.9866\n",
            "[  192/  381 ( 50%)]  Loss: 1.8970\n",
            "[  288/  381 ( 75%)]  Loss: 2.0205\n",
            "Execution time:  1.80 seconds\n",
            "\n",
            "Average test loss: 1.9495  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 144\n",
            "[    0/  381 (  0%)]  Loss: 1.9300\n",
            "[   96/  381 ( 25%)]  Loss: 1.9756\n",
            "[  192/  381 ( 50%)]  Loss: 1.8846\n",
            "[  288/  381 ( 75%)]  Loss: 2.0132\n",
            "Execution time:  1.79 seconds\n",
            "\n",
            "Average test loss: 1.9494  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 145\n",
            "[    0/  381 (  0%)]  Loss: 1.9430\n",
            "[   96/  381 ( 25%)]  Loss: 1.9807\n",
            "[  192/  381 ( 50%)]  Loss: 1.9154\n",
            "[  288/  381 ( 75%)]  Loss: 2.0122\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9511  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 146\n",
            "[    0/  381 (  0%)]  Loss: 1.9355\n",
            "[   96/  381 ( 25%)]  Loss: 1.9798\n",
            "[  192/  381 ( 50%)]  Loss: 1.8857\n",
            "[  288/  381 ( 75%)]  Loss: 2.0143\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9482  Accuracy:   58/   96 (60.42%)\n",
            "\n",
            "Epoch: 147\n",
            "[    0/  381 (  0%)]  Loss: 1.9397\n",
            "[   96/  381 ( 25%)]  Loss: 1.9980\n",
            "[  192/  381 ( 50%)]  Loss: 1.8925\n",
            "[  288/  381 ( 75%)]  Loss: 2.0190\n",
            "Execution time:  1.77 seconds\n",
            "\n",
            "Average test loss: 1.9497  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Epoch: 148\n",
            "[    0/  381 (  0%)]  Loss: 1.9237\n",
            "[   96/  381 ( 25%)]  Loss: 1.9794\n",
            "[  192/  381 ( 50%)]  Loss: 1.8863\n",
            "[  288/  381 ( 75%)]  Loss: 2.0115\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9492  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 149\n",
            "[    0/  381 (  0%)]  Loss: 1.9256\n",
            "[   96/  381 ( 25%)]  Loss: 1.9805\n",
            "[  192/  381 ( 50%)]  Loss: 1.8885\n",
            "[  288/  381 ( 75%)]  Loss: 2.0144\n",
            "Execution time:  1.78 seconds\n",
            "\n",
            "Average test loss: 1.9492  Accuracy:   57/   96 (59.38%)\n",
            "\n",
            "Epoch: 150\n",
            "[    0/  381 (  0%)]  Loss: 1.9204\n",
            "[   96/  381 ( 25%)]  Loss: 1.9875\n",
            "[  192/  381 ( 50%)]  Loss: 1.8916\n",
            "[  288/  381 ( 75%)]  Loss: 2.0086\n",
            "Execution time:  1.83 seconds\n",
            "\n",
            "Average test loss: 1.9485  Accuracy:   56/   96 (58.33%)\n",
            "\n",
            "Execution time 341.50782918930054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QvIrAkACgST",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "496b6c85-30d2-4ab1-f05c-dd06f97401d5"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(list(range(len(train_loss_history))),train_loss_history)\r\n",
        "plt.plot(list(range(len(test_loss_history))),test_loss_history)\r\n",
        "plt.title(\"loss plot\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Avg Accuracy\")\r\n",
        "plt.legend([\"val\",\"train\"])\r\n",
        "m=min(test_loss_history)\r\n",
        "t=min(train_loss_history)\r\n",
        "# plt.annotate(f\"Max val acc: {m:0.2f}\\nMax train acc: {t:0.2f}\",(40,0.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Coqwf7C6lX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cd8e1032-80af-43c1-8b97-7bc311a02095"
      },
      "source": [
        "# plt.plot(list(range(len(train_acc_history))),train_loss_history)\r\n",
        "plt.plot(list(range(len(test_acc_history))),test_acc_history)\r\n",
        "plt.title(\"Acc plot\")\r\n",
        "plt.xlabel(\"Epoch\")\r\n",
        "plt.ylabel(\"Avg Accuracy\")\r\n",
        "# plt.legend([\"val\",\"train\"])\r\n",
        "m=max(test_loss_history)\r\n",
        "t=max(train_loss_history)\r\n",
        "# plt.annotate(f\"Max val acc: {m:0.2f}\\nMax train acc: {t:0.2f}\",(40,0.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiRyDP3LEz9C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}