{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmbiTyga/Bio-VI-BERT/blob/main/Image%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_baimJsBy1F",
        "outputId": "bf092063-aee3-459f-c7b2-9fe5ab6b9ba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!7z x /content/Dataset.7z"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1 file, 17231696 bytes (17 MiB)\n",
            "\n",
            "Extracting archive: /content/Dataset.7z\n",
            "--\n",
            "Path = /content/Dataset.7z\n",
            "Type = 7z\n",
            "Physical Size = 17231696\n",
            "Headers Size = 6422\n",
            "Method = LZMA2:24\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b 18% 23\b\b\b\b\b\b\b       \b\b\b\b\b\b\b 35% 143 - Dataset/Dibothriocephalus/Diphyllobothrium_tissue_WA_500x1.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 251 - Dataset/Giardia/Giardia_cyst_tric5.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 354 - Dataset/Plasmodium/Pm_gametocyte_thinA.jpg\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 460 - Dataset/Strongyloides/Strongy_C\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 23\n",
            "Files: 528\n",
            "Size:       21325876\n",
            "Compressed: 17231696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJZGjtWHewjj"
      },
      "source": [
        "# Installing and Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYyzxsYmKgAO"
      },
      "source": [
        "!pip install einops -q\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from PIL import Image\r\n",
        "import time\r\n",
        "import torch\r\n",
        "from torchvision import transforms\r\n",
        "import torch.nn.functional as F\r\n",
        "from einops import rearrange\r\n",
        "from torch import nn\r\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSfgsoF0fH-m"
      },
      "source": [
        "# Vision Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce_ZFu3cCmT6"
      },
      "source": [
        "class Residual(nn.Module):\r\n",
        "    def __init__(self, fn):\r\n",
        "        super().__init__()\r\n",
        "        self.fn = fn\r\n",
        "    def forward(self, x, **kwargs):\r\n",
        "        return self.fn(x, **kwargs) + x\r\n",
        "\r\n",
        "class LayerNormalize(nn.Module):\r\n",
        "    def __init__(self, dim, fn):\r\n",
        "        super().__init__()\r\n",
        "        self.norm = nn.LayerNorm(dim)\r\n",
        "        self.fn = fn\r\n",
        "    def forward(self, x, **kwargs):\r\n",
        "        return self.fn(self.norm(x), **kwargs)\r\n",
        "\r\n",
        "class MLP_Block(nn.Module):\r\n",
        "    def __init__(self, dim, hidden_dim, dropout = 0.1):\r\n",
        "        super().__init__()\r\n",
        "        self.nn1 = nn.Linear(dim, hidden_dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "        torch.nn.init.normal_(self.nn1.bias, std = 1e-6)\r\n",
        "        self.af1 = nn.GELU()\r\n",
        "        self.do1 = nn.Dropout(dropout)\r\n",
        "        self.nn2 = nn.Linear(hidden_dim, dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn2.weight)\r\n",
        "        torch.nn.init.normal_(self.nn2.bias, std = 1e-6)\r\n",
        "        self.do2 = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.nn1(x)\r\n",
        "        x = self.af1(x)\r\n",
        "        x = self.do1(x)\r\n",
        "        x = self.nn2(x)\r\n",
        "        x = self.do2(x)\r\n",
        "        \r\n",
        "        return x\r\n",
        "\r\n",
        "class Attention(nn.Module):\r\n",
        "    def __init__(self, dim, heads = 8, dropout = 0.1):\r\n",
        "        super().__init__()\r\n",
        "        self.heads = heads\r\n",
        "        self.scale = dim ** -0.5  # 1/sqrt(dim)\r\n",
        "\r\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias = True) # Wq,Wk,Wv for each vector, thats why *3\r\n",
        "        torch.nn.init.xavier_uniform_(self.to_qkv.weight)\r\n",
        "        torch.nn.init.zeros_(self.to_qkv.bias)\r\n",
        "        \r\n",
        "        self.nn1 = nn.Linear(dim, dim)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "        torch.nn.init.zeros_(self.nn1.bias)        \r\n",
        "        self.do1 = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x, mask = None):\r\n",
        "        b, n, _, h = *x.shape, self.heads\r\n",
        "        qkv = self.to_qkv(x) #gets q = Q = Wq matmul x1, k = Wk mm x2, v = Wv mm x3\r\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv = 3, h = h) # split into multi head attentions\r\n",
        "\r\n",
        "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\r\n",
        "\r\n",
        "        if mask is not None:\r\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\r\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\r\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\r\n",
        "            dots.masked_fill_(~mask, float('-inf'))\r\n",
        "            del mask\r\n",
        "\r\n",
        "        attn = dots.softmax(dim=-1) #follow the softmax,q,d,v equation in the paper\r\n",
        "\r\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v) #product of v times whatever inside softmax\r\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)') #concat heads into one matrix, ready for next encoder block\r\n",
        "        out =  self.nn1(out)\r\n",
        "        out = self.do1(out)\r\n",
        "        return out\r\n",
        "\r\n",
        "class Transformer(nn.Module):\r\n",
        "    def __init__(self, dim, depth, heads, mlp_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        self.layers = nn.ModuleList([])\r\n",
        "        for _ in range(depth):\r\n",
        "            self.layers.append(nn.ModuleList([\r\n",
        "                Residual(LayerNormalize(dim, Attention(dim, heads = heads, dropout = dropout))),\r\n",
        "                Residual(LayerNormalize(dim, MLP_Block(dim, mlp_dim, dropout = dropout)))\r\n",
        "            ]))\r\n",
        "    def forward(self, x, mask = None):\r\n",
        "        for attention, mlp in self.layers:\r\n",
        "            x = attention(x, mask = mask) # go to attention\r\n",
        "            x = mlp(x) #go to MLP_Block\r\n",
        "        return x\r\n",
        "\r\n",
        "class ImageTransformer(nn.Module):\r\n",
        "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels = 3, dropout = 0.1, emb_dropout = 0.1):\r\n",
        "        super().__init__()\r\n",
        "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\r\n",
        "        num_patches = (image_size // patch_size) ** 2  # e.g. (32/4)**2= 64\r\n",
        "        patch_dim = channels * patch_size ** 2  # e.g. 3*8**2 = 64*3\r\n",
        "\r\n",
        "        self.patch_size = patch_size\r\n",
        "        self.pos_embedding = nn.Parameter(torch.empty(1, (num_patches + 1), dim))\r\n",
        "        torch.nn.init.normal_(self.pos_embedding, std = .02) # initialized based on the paper\r\n",
        "        self.patch_conv= nn.Conv2d(3,dim, patch_size, stride = patch_size) #eqivalent to x matmul E, E= embedd matrix, this is the linear patch projection\r\n",
        "        \r\n",
        "        #self.E = nn.Parameter(nn.init.normal_(torch.empty(BATCH_SIZE_TRAIN,patch_dim,dim)),requires_grad = True)\r\n",
        "        \r\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim)) #initialized based on the paper\r\n",
        "        self.dropout = nn.Dropout(emb_dropout)\r\n",
        "\r\n",
        "        self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)\r\n",
        "\r\n",
        "        self.to_cls_token = nn.Identity()\r\n",
        "\r\n",
        "        self.nn1 = nn.Linear(dim, num_classes)  # if finetuning, just use a linear layer without further hidden layers (paper)\r\n",
        "        torch.nn.init.xavier_uniform_(self.nn1.weight)\r\n",
        "        torch.nn.init.normal_(self.nn1.bias, std = 1e-6)\r\n",
        "        # self.af1 = nn.GELU() # use additinal hidden layers only when training on large datasets\r\n",
        "        # self.do1 = nn.Dropout(dropout)\r\n",
        "        # self.nn2 = nn.Linear(mlp_dim, num_classes)\r\n",
        "        # torch.nn.init.xavier_uniform_(self.nn2.weight)\r\n",
        "        # torch.nn.init.normal_(self.nn2.bias)\r\n",
        "        # self.do2 = nn.Dropout(dropout)\r\n",
        "\r\n",
        "    def forward(self, img, mask = None):\r\n",
        "        p = self.patch_size\r\n",
        "\r\n",
        "        x = self.patch_conv(img) # each of 64 vecotrs is linearly transformed with a FFN equiv to E matmul\r\n",
        "        #x = torch.matmul(x, self.E)\r\n",
        "        x = rearrange(x, 'b c h w -> b (h w) c') # 64 vectors in rows representing 64 patches, each 64*3 long\r\n",
        "\r\n",
        "        cls_tokens = self.cls_token.expand(img.shape[0], -1, -1)\r\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\r\n",
        "        x += self.pos_embedding\r\n",
        "        x = self.dropout(x)\r\n",
        "\r\n",
        "        x = self.transformer(x, mask) #main game\r\n",
        "\r\n",
        "        x = self.to_cls_token(x[:, 0])\r\n",
        "        \r\n",
        "        x = self.nn1(x)\r\n",
        "        # x = self.af1(x)\r\n",
        "        # x = self.do1(x)\r\n",
        "        # x = self.nn2(x)\r\n",
        "        # x = self.do2(x)\r\n",
        "        \r\n",
        "        return x\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gG_0tWue05f"
      },
      "source": [
        "# Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtJ3g1lcVah5"
      },
      "source": [
        "## Getting images(file path) from the directories \r\n",
        "imgs = []\r\n",
        "for path, subdirs, files in os.walk('./Dataset'):\r\n",
        "    for name in files:\r\n",
        "        imgs.append(os.path.join(path, name))\r\n",
        "imgs = [x for x in imgs if '.jpg' in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1zUOBkABzv6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e1f1204c-9d19-418b-f4f8-af4618259d1f"
      },
      "source": [
        "data = pd.read_csv(\"/content/Dataset/all_meta_data.csv\")\r\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phylum</th>\n",
              "      <th>class</th>\n",
              "      <th>genus</th>\n",
              "      <th>species</th>\n",
              "      <th>form</th>\n",
              "      <th>sample</th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_url</th>\n",
              "      <th>img_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_worm4_HB.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_worm4_HB.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_HBa.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_HBa.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_wtmt.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_wtmt.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_SC_egg.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_SC_egg.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nematoda</td>\n",
              "      <td>Chromadorea</td>\n",
              "      <td>Enterobius</td>\n",
              "      <td>Enterobius vermicularis</td>\n",
              "      <td>egg</td>\n",
              "      <td>intestinal tissue</td>\n",
              "      <td>Evermicularis_egg_UVa.jpg</td>\n",
              "      <td>https://www.cdc.gov//dpdx/enterobiasis/images/...</td>\n",
              "      <td>./Dataset/Enterobius/Evermicularis_egg_UVa.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     phylum  ...                                         img_path\n",
              "0  Nematoda  ...  ./Dataset/Enterobius/Evermicularis_worm4_HB.jpg\n",
              "1  Nematoda  ...   ./Dataset/Enterobius/Evermicularis_egg_HBa.jpg\n",
              "2  Nematoda  ...  ./Dataset/Enterobius/Evermicularis_egg_wtmt.jpg\n",
              "3  Nematoda  ...    ./Dataset/Enterobius/Evermicularis_SC_egg.jpg\n",
              "4  Nematoda  ...   ./Dataset/Enterobius/Evermicularis_egg_UVa.jpg\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vLckKFYxvU"
      },
      "source": [
        "# Dropping unnecessary datapoints\r\n",
        "def check_file(x):\r\n",
        "  if x not in imgs:\r\n",
        "    return 'N\\A'\r\n",
        "  else:\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "data['img_path'] = data['img_path'].apply(check_file)\r\n",
        "data.drop(index = data[data['img_path']=='N\\A'].index,inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh--CXKMZadn"
      },
      "source": [
        "data.to_csv('/content/Parasitesv1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYxxbhAfQrI"
      },
      "source": [
        "## Custom Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPUz2T2qEXTS"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader, sampler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "class SpeciesLoader(Dataset):\r\n",
        "  def __init__(self,csv_file,transform):\r\n",
        "    super().__init__()\r\n",
        "    csv = pd.read_csv(csv_file)[['species','img_path']]\r\n",
        "    labels = csv['species'].values\r\n",
        "\r\n",
        "    self.images = csv['img_path'].values\r\n",
        "    self.transform = transform\r\n",
        "\r\n",
        "    self.LE = LabelEncoder()\r\n",
        "    self.labels = self.LE.fit_transform(labels)    \r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    # return size of dataset\r\n",
        "    return len(self.images)\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    img = Image.open(self.images[index])\r\n",
        "    img = self.transform(img)\r\n",
        "\r\n",
        "    label = self.labels[index]\r\n",
        "\r\n",
        "    return img, label"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOL5NtArJ8QY"
      },
      "source": [
        "transformer = transforms.Compose([\r\n",
        "        transforms.Resize((32,32)),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        # transforms.\r\n",
        "        # transforms.ColorJitter(hue=.05, saturation=.05),\r\n",
        "        transforms.RandomRotation(90),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W7rAlWdfU6-"
      },
      "source": [
        "## Train and Test splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0NXmSK2EFKh"
      },
      "source": [
        "dataset = SpeciesLoader('/content/Parasitesv1.csv',transform=transformer)\r\n",
        "batch_size = 16\r\n",
        "validation_split = .2\r\n",
        "shuffle_dataset = True\r\n",
        "random_seed= 42\r\n",
        "\r\n",
        "# Creating data indices for training and validation splits:\r\n",
        "dataset_size = len(dataset)\r\n",
        "indices = list(range(dataset_size))\r\n",
        "split = int(np.floor(validation_split * dataset_size))\r\n",
        "if shuffle_dataset :\r\n",
        "    np.random.seed(random_seed)\r\n",
        "    np.random.shuffle(indices)\r\n",
        "train_indices, val_indices = indices[split:], indices[:split]\r\n",
        "\r\n",
        "# Creating PT data samplers and loaders:\r\n",
        "train_sampler = SubsetRandomSampler(train_indices)\r\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \r\n",
        "                                           sampler=train_sampler)\r\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\r\n",
        "                                                sampler=valid_sampler)\r\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLedxgr9fiWx"
      },
      "source": [
        "# Train and Eval Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayXLEiWSKusR"
      },
      "source": [
        "def train(model, optimizer, data_loader, loss_history):\r\n",
        "    total_samples = len(data_loader.dataset)\r\n",
        "    model.train()\r\n",
        "\r\n",
        "    for i, (data, target) in enumerate(data_loader):\r\n",
        "        optimizer.zero_grad()\r\n",
        "        output = F.log_softmax(model(data), dim=1)\r\n",
        "        loss = F.nll_loss(output, target)\r\n",
        "\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        if i % 3 == 0:\r\n",
        "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\r\n",
        "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\r\n",
        "                  '{:6.4f}'.format(loss.item()))\r\n",
        "            loss_history.append(loss.item())\r\n",
        "\r\n",
        "def evaluate(model, data_loader, loss_history):\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    total_samples = len(data_loader.dataset)\r\n",
        "    correct_samples = 0\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, target in data_loader:\r\n",
        "            output = F.log_softmax(model(data), dim=1)\r\n",
        "            loss = F.nll_loss(output, target, reduction='sum')\r\n",
        "            _, pred = torch.max(output, dim=1)\r\n",
        "            \r\n",
        "            total_loss += loss.item()\r\n",
        "            correct_samples += pred.eq(target).sum()\r\n",
        "\r\n",
        "    avg_loss = total_loss / total_samples\r\n",
        "    loss_history.append(avg_loss)\r\n",
        "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\r\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\r\n",
        "          '{:5}'.format(total_samples) + ' (' +\r\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_USddH2fmWz"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mONSFXGxLQxz"
      },
      "source": [
        "N_EPOCHS = 150\r\n",
        "\r\n",
        "model = ImageTransformer(image_size=32, patch_size=4, num_classes=27, channels=3,\r\n",
        "            dim=64, depth=6, heads=8, mlp_dim=128)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ohg_5haLLrD",
        "outputId": "3b6b0b6f-ebaa-4191-be9e-935015dbc4e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_loss_history, test_loss_history = [], []\r\n",
        "for epoch in range(1, N_EPOCHS + 1):\r\n",
        "    print('Epoch:', epoch)\r\n",
        "    start_time = time.time()\r\n",
        "    train(model, optimizer, train_loader, train_loss_history)\r\n",
        "    print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')\r\n",
        "    evaluate(model, validation_loader, test_loss_history)\r\n",
        "\r\n",
        "print('Execution time')"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "[    0/  477 (  0%)]  Loss: 0.0534\n",
            "[   48/  477 ( 12%)]  Loss: 0.0674\n",
            "[   96/  477 ( 25%)]  Loss: 0.1605\n",
            "[  144/  477 ( 38%)]  Loss: 0.1282\n",
            "[  192/  477 ( 50%)]  Loss: 0.4535\n",
            "[  240/  477 ( 62%)]  Loss: 0.9410\n",
            "[  288/  477 ( 75%)]  Loss: 0.5718\n",
            "[  336/  477 ( 88%)]  Loss: 0.6959\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 0.9238  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 2\n",
            "[    0/  477 (  0%)]  Loss: 0.4655\n",
            "[   48/  477 ( 12%)]  Loss: 0.2678\n",
            "[   96/  477 ( 25%)]  Loss: 0.6032\n",
            "[  144/  477 ( 38%)]  Loss: 0.7084\n",
            "[  192/  477 ( 50%)]  Loss: 0.5693\n",
            "[  240/  477 ( 62%)]  Loss: 0.3855\n",
            "[  288/  477 ( 75%)]  Loss: 0.2595\n",
            "[  336/  477 ( 88%)]  Loss: 0.2672\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 0.9995  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 3\n",
            "[    0/  477 (  0%)]  Loss: 0.4735\n",
            "[   48/  477 ( 12%)]  Loss: 0.3307\n",
            "[   96/  477 ( 25%)]  Loss: 0.1794\n",
            "[  144/  477 ( 38%)]  Loss: 0.4323\n",
            "[  192/  477 ( 50%)]  Loss: 0.7136\n",
            "[  240/  477 ( 62%)]  Loss: 1.2067\n",
            "[  288/  477 ( 75%)]  Loss: 0.3450\n",
            "[  336/  477 ( 88%)]  Loss: 0.4415\n",
            "Execution time:  2.89 seconds\n",
            "\n",
            "Average test loss: 0.9625  Accuracy:   47/  477 (9.85%)\n",
            "\n",
            "Epoch: 4\n",
            "[    0/  477 (  0%)]  Loss: 0.6699\n",
            "[   48/  477 ( 12%)]  Loss: 0.6105\n",
            "[   96/  477 ( 25%)]  Loss: 0.1117\n",
            "[  144/  477 ( 38%)]  Loss: 0.9558\n",
            "[  192/  477 ( 50%)]  Loss: 0.1759\n",
            "[  240/  477 ( 62%)]  Loss: 0.8252\n",
            "[  288/  477 ( 75%)]  Loss: 0.3009\n",
            "[  336/  477 ( 88%)]  Loss: 0.2307\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0020  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 5\n",
            "[    0/  477 (  0%)]  Loss: 0.4860\n",
            "[   48/  477 ( 12%)]  Loss: 0.2476\n",
            "[   96/  477 ( 25%)]  Loss: 0.1573\n",
            "[  144/  477 ( 38%)]  Loss: 0.7212\n",
            "[  192/  477 ( 50%)]  Loss: 0.2658\n",
            "[  240/  477 ( 62%)]  Loss: 0.2423\n",
            "[  288/  477 ( 75%)]  Loss: 0.0698\n",
            "[  336/  477 ( 88%)]  Loss: 0.2897\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 0.9302  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 6\n",
            "[    0/  477 (  0%)]  Loss: 0.3933\n",
            "[   48/  477 ( 12%)]  Loss: 0.2135\n",
            "[   96/  477 ( 25%)]  Loss: 0.1957\n",
            "[  144/  477 ( 38%)]  Loss: 0.3378\n",
            "[  192/  477 ( 50%)]  Loss: 0.2957\n",
            "[  240/  477 ( 62%)]  Loss: 0.5699\n",
            "[  288/  477 ( 75%)]  Loss: 1.0182\n",
            "[  336/  477 ( 88%)]  Loss: 0.1187\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 1.1096  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 7\n",
            "[    0/  477 (  0%)]  Loss: 0.2205\n",
            "[   48/  477 ( 12%)]  Loss: 0.2389\n",
            "[   96/  477 ( 25%)]  Loss: 0.1308\n",
            "[  144/  477 ( 38%)]  Loss: 0.0266\n",
            "[  192/  477 ( 50%)]  Loss: 0.3544\n",
            "[  240/  477 ( 62%)]  Loss: 0.4663\n",
            "[  288/  477 ( 75%)]  Loss: 0.2443\n",
            "[  336/  477 ( 88%)]  Loss: 0.1306\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0794  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 8\n",
            "[    0/  477 (  0%)]  Loss: 0.3597\n",
            "[   48/  477 ( 12%)]  Loss: 0.1500\n",
            "[   96/  477 ( 25%)]  Loss: 0.0506\n",
            "[  144/  477 ( 38%)]  Loss: 0.5738\n",
            "[  192/  477 ( 50%)]  Loss: 0.3737\n",
            "[  240/  477 ( 62%)]  Loss: 0.2915\n",
            "[  288/  477 ( 75%)]  Loss: 0.3755\n",
            "[  336/  477 ( 88%)]  Loss: 0.0058\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 0.9190  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 9\n",
            "[    0/  477 (  0%)]  Loss: 0.0580\n",
            "[   48/  477 ( 12%)]  Loss: 0.2169\n",
            "[   96/  477 ( 25%)]  Loss: 0.2824\n",
            "[  144/  477 ( 38%)]  Loss: 0.2179\n",
            "[  192/  477 ( 50%)]  Loss: 0.0379\n",
            "[  240/  477 ( 62%)]  Loss: 0.3383\n",
            "[  288/  477 ( 75%)]  Loss: 0.2465\n",
            "[  336/  477 ( 88%)]  Loss: 0.7936\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9627  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 10\n",
            "[    0/  477 (  0%)]  Loss: 0.0913\n",
            "[   48/  477 ( 12%)]  Loss: 0.0448\n",
            "[   96/  477 ( 25%)]  Loss: 0.4291\n",
            "[  144/  477 ( 38%)]  Loss: 0.1456\n",
            "[  192/  477 ( 50%)]  Loss: 0.5357\n",
            "[  240/  477 ( 62%)]  Loss: 0.1619\n",
            "[  288/  477 ( 75%)]  Loss: 0.0761\n",
            "[  336/  477 ( 88%)]  Loss: 0.6579\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9969  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 11\n",
            "[    0/  477 (  0%)]  Loss: 0.2863\n",
            "[   48/  477 ( 12%)]  Loss: 0.1991\n",
            "[   96/  477 ( 25%)]  Loss: 0.3972\n",
            "[  144/  477 ( 38%)]  Loss: 0.0801\n",
            "[  192/  477 ( 50%)]  Loss: 0.2936\n",
            "[  240/  477 ( 62%)]  Loss: 0.5560\n",
            "[  288/  477 ( 75%)]  Loss: 0.0600\n",
            "[  336/  477 ( 88%)]  Loss: 0.0481\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 0.9460  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 12\n",
            "[    0/  477 (  0%)]  Loss: 0.4096\n",
            "[   48/  477 ( 12%)]  Loss: 0.1807\n",
            "[   96/  477 ( 25%)]  Loss: 0.0815\n",
            "[  144/  477 ( 38%)]  Loss: 1.5674\n",
            "[  192/  477 ( 50%)]  Loss: 0.6208\n",
            "[  240/  477 ( 62%)]  Loss: 0.2962\n",
            "[  288/  477 ( 75%)]  Loss: 0.5202\n",
            "[  336/  477 ( 88%)]  Loss: 0.2999\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.0964  Accuracy:   45/  477 (9.43%)\n",
            "\n",
            "Epoch: 13\n",
            "[    0/  477 (  0%)]  Loss: 0.5057\n",
            "[   48/  477 ( 12%)]  Loss: 0.3978\n",
            "[   96/  477 ( 25%)]  Loss: 0.7025\n",
            "[  144/  477 ( 38%)]  Loss: 0.3874\n",
            "[  192/  477 ( 50%)]  Loss: 0.3090\n",
            "[  240/  477 ( 62%)]  Loss: 0.3264\n",
            "[  288/  477 ( 75%)]  Loss: 0.1973\n",
            "[  336/  477 ( 88%)]  Loss: 0.6480\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 0.9733  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 14\n",
            "[    0/  477 (  0%)]  Loss: 0.3145\n",
            "[   48/  477 ( 12%)]  Loss: 0.4106\n",
            "[   96/  477 ( 25%)]  Loss: 0.4463\n",
            "[  144/  477 ( 38%)]  Loss: 0.2839\n",
            "[  192/  477 ( 50%)]  Loss: 0.2144\n",
            "[  240/  477 ( 62%)]  Loss: 0.2522\n",
            "[  288/  477 ( 75%)]  Loss: 0.7632\n",
            "[  336/  477 ( 88%)]  Loss: 0.8594\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 0.9202  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 15\n",
            "[    0/  477 (  0%)]  Loss: 0.0326\n",
            "[   48/  477 ( 12%)]  Loss: 0.6298\n",
            "[   96/  477 ( 25%)]  Loss: 0.2453\n",
            "[  144/  477 ( 38%)]  Loss: 0.8859\n",
            "[  192/  477 ( 50%)]  Loss: 0.6202\n",
            "[  240/  477 ( 62%)]  Loss: 0.3707\n",
            "[  288/  477 ( 75%)]  Loss: 0.1734\n",
            "[  336/  477 ( 88%)]  Loss: 0.0483\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 0.9643  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 16\n",
            "[    0/  477 (  0%)]  Loss: 0.1826\n",
            "[   48/  477 ( 12%)]  Loss: 0.1039\n",
            "[   96/  477 ( 25%)]  Loss: 0.0897\n",
            "[  144/  477 ( 38%)]  Loss: 0.0179\n",
            "[  192/  477 ( 50%)]  Loss: 0.8334\n",
            "[  240/  477 ( 62%)]  Loss: 0.0828\n",
            "[  288/  477 ( 75%)]  Loss: 0.1069\n",
            "[  336/  477 ( 88%)]  Loss: 0.1085\n",
            "Execution time:  3.04 seconds\n",
            "\n",
            "Average test loss: 1.0595  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 17\n",
            "[    0/  477 (  0%)]  Loss: 0.2941\n",
            "[   48/  477 ( 12%)]  Loss: 0.2639\n",
            "[   96/  477 ( 25%)]  Loss: 0.0699\n",
            "[  144/  477 ( 38%)]  Loss: 0.3264\n",
            "[  192/  477 ( 50%)]  Loss: 0.1603\n",
            "[  240/  477 ( 62%)]  Loss: 0.2419\n",
            "[  288/  477 ( 75%)]  Loss: 0.1954\n",
            "[  336/  477 ( 88%)]  Loss: 0.6661\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 0.9946  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 18\n",
            "[    0/  477 (  0%)]  Loss: 0.3294\n",
            "[   48/  477 ( 12%)]  Loss: 0.5054\n",
            "[   96/  477 ( 25%)]  Loss: 0.0664\n",
            "[  144/  477 ( 38%)]  Loss: 0.0616\n",
            "[  192/  477 ( 50%)]  Loss: 0.0196\n",
            "[  240/  477 ( 62%)]  Loss: 0.2408\n",
            "[  288/  477 ( 75%)]  Loss: 0.1809\n",
            "[  336/  477 ( 88%)]  Loss: 0.0865\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0943  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 19\n",
            "[    0/  477 (  0%)]  Loss: 0.4883\n",
            "[   48/  477 ( 12%)]  Loss: 0.2123\n",
            "[   96/  477 ( 25%)]  Loss: 0.0579\n",
            "[  144/  477 ( 38%)]  Loss: 0.3803\n",
            "[  192/  477 ( 50%)]  Loss: 0.5396\n",
            "[  240/  477 ( 62%)]  Loss: 0.1452\n",
            "[  288/  477 ( 75%)]  Loss: 0.3071\n",
            "[  336/  477 ( 88%)]  Loss: 0.6875\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1033  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 20\n",
            "[    0/  477 (  0%)]  Loss: 0.1640\n",
            "[   48/  477 ( 12%)]  Loss: 0.4019\n",
            "[   96/  477 ( 25%)]  Loss: 1.0450\n",
            "[  144/  477 ( 38%)]  Loss: 0.5086\n",
            "[  192/  477 ( 50%)]  Loss: 0.3033\n",
            "[  240/  477 ( 62%)]  Loss: 0.4358\n",
            "[  288/  477 ( 75%)]  Loss: 0.2911\n",
            "[  336/  477 ( 88%)]  Loss: 0.3156\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9806  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 21\n",
            "[    0/  477 (  0%)]  Loss: 0.0196\n",
            "[   48/  477 ( 12%)]  Loss: 0.9146\n",
            "[   96/  477 ( 25%)]  Loss: 0.0848\n",
            "[  144/  477 ( 38%)]  Loss: 0.3339\n",
            "[  192/  477 ( 50%)]  Loss: 0.5593\n",
            "[  240/  477 ( 62%)]  Loss: 0.1655\n",
            "[  288/  477 ( 75%)]  Loss: 0.0442\n",
            "[  336/  477 ( 88%)]  Loss: 0.3485\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9953  Accuracy:   45/  477 (9.43%)\n",
            "\n",
            "Epoch: 22\n",
            "[    0/  477 (  0%)]  Loss: 0.1768\n",
            "[   48/  477 ( 12%)]  Loss: 0.6591\n",
            "[   96/  477 ( 25%)]  Loss: 0.1887\n",
            "[  144/  477 ( 38%)]  Loss: 0.0558\n",
            "[  192/  477 ( 50%)]  Loss: 1.0134\n",
            "[  240/  477 ( 62%)]  Loss: 0.6524\n",
            "[  288/  477 ( 75%)]  Loss: 0.2450\n",
            "[  336/  477 ( 88%)]  Loss: 0.1202\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0796  Accuracy:   44/  477 (9.22%)\n",
            "\n",
            "Epoch: 23\n",
            "[    0/  477 (  0%)]  Loss: 0.3480\n",
            "[   48/  477 ( 12%)]  Loss: 0.4908\n",
            "[   96/  477 ( 25%)]  Loss: 0.0530\n",
            "[  144/  477 ( 38%)]  Loss: 0.7566\n",
            "[  192/  477 ( 50%)]  Loss: 0.7738\n",
            "[  240/  477 ( 62%)]  Loss: 0.2758\n",
            "[  288/  477 ( 75%)]  Loss: 0.3702\n",
            "[  336/  477 ( 88%)]  Loss: 0.2862\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.0505  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 24\n",
            "[    0/  477 (  0%)]  Loss: 0.5532\n",
            "[   48/  477 ( 12%)]  Loss: 0.4584\n",
            "[   96/  477 ( 25%)]  Loss: 0.3099\n",
            "[  144/  477 ( 38%)]  Loss: 0.2838\n",
            "[  192/  477 ( 50%)]  Loss: 0.1403\n",
            "[  240/  477 ( 62%)]  Loss: 0.1906\n",
            "[  288/  477 ( 75%)]  Loss: 0.2321\n",
            "[  336/  477 ( 88%)]  Loss: 0.1299\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.2380  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 25\n",
            "[    0/  477 (  0%)]  Loss: 0.2517\n",
            "[   48/  477 ( 12%)]  Loss: 0.4359\n",
            "[   96/  477 ( 25%)]  Loss: 0.7796\n",
            "[  144/  477 ( 38%)]  Loss: 0.5201\n",
            "[  192/  477 ( 50%)]  Loss: 0.5139\n",
            "[  240/  477 ( 62%)]  Loss: 0.0618\n",
            "[  288/  477 ( 75%)]  Loss: 0.3227\n",
            "[  336/  477 ( 88%)]  Loss: 0.1313\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9826  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 26\n",
            "[    0/  477 (  0%)]  Loss: 0.3294\n",
            "[   48/  477 ( 12%)]  Loss: 0.6445\n",
            "[   96/  477 ( 25%)]  Loss: 0.6200\n",
            "[  144/  477 ( 38%)]  Loss: 0.0448\n",
            "[  192/  477 ( 50%)]  Loss: 0.0265\n",
            "[  240/  477 ( 62%)]  Loss: 0.4123\n",
            "[  288/  477 ( 75%)]  Loss: 0.4820\n",
            "[  336/  477 ( 88%)]  Loss: 0.5569\n",
            "Execution time:  3.04 seconds\n",
            "\n",
            "Average test loss: 0.9230  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 27\n",
            "[    0/  477 (  0%)]  Loss: 0.4270\n",
            "[   48/  477 ( 12%)]  Loss: 0.5458\n",
            "[   96/  477 ( 25%)]  Loss: 0.2125\n",
            "[  144/  477 ( 38%)]  Loss: 0.1633\n",
            "[  192/  477 ( 50%)]  Loss: 0.4067\n",
            "[  240/  477 ( 62%)]  Loss: 0.8785\n",
            "[  288/  477 ( 75%)]  Loss: 1.0279\n",
            "[  336/  477 ( 88%)]  Loss: 0.1478\n",
            "Execution time:  3.06 seconds\n",
            "\n",
            "Average test loss: 1.0616  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 28\n",
            "[    0/  477 (  0%)]  Loss: 0.2459\n",
            "[   48/  477 ( 12%)]  Loss: 0.4413\n",
            "[   96/  477 ( 25%)]  Loss: 0.2873\n",
            "[  144/  477 ( 38%)]  Loss: 0.3575\n",
            "[  192/  477 ( 50%)]  Loss: 0.1835\n",
            "[  240/  477 ( 62%)]  Loss: 0.5641\n",
            "[  288/  477 ( 75%)]  Loss: 0.3828\n",
            "[  336/  477 ( 88%)]  Loss: 0.3021\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0326  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 29\n",
            "[    0/  477 (  0%)]  Loss: 0.2777\n",
            "[   48/  477 ( 12%)]  Loss: 0.0576\n",
            "[   96/  477 ( 25%)]  Loss: 0.1391\n",
            "[  144/  477 ( 38%)]  Loss: 0.0450\n",
            "[  192/  477 ( 50%)]  Loss: 0.0854\n",
            "[  240/  477 ( 62%)]  Loss: 0.4384\n",
            "[  288/  477 ( 75%)]  Loss: 0.0575\n",
            "[  336/  477 ( 88%)]  Loss: 0.1856\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.1090  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 30\n",
            "[    0/  477 (  0%)]  Loss: 0.2760\n",
            "[   48/  477 ( 12%)]  Loss: 0.0997\n",
            "[   96/  477 ( 25%)]  Loss: 0.3810\n",
            "[  144/  477 ( 38%)]  Loss: 0.0860\n",
            "[  192/  477 ( 50%)]  Loss: 0.1664\n",
            "[  240/  477 ( 62%)]  Loss: 0.2844\n",
            "[  288/  477 ( 75%)]  Loss: 0.1744\n",
            "[  336/  477 ( 88%)]  Loss: 1.1383\n",
            "Execution time:  3.04 seconds\n",
            "\n",
            "Average test loss: 1.1357  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 31\n",
            "[    0/  477 (  0%)]  Loss: 0.1534\n",
            "[   48/  477 ( 12%)]  Loss: 0.1905\n",
            "[   96/  477 ( 25%)]  Loss: 0.2038\n",
            "[  144/  477 ( 38%)]  Loss: 0.3177\n",
            "[  192/  477 ( 50%)]  Loss: 0.2801\n",
            "[  240/  477 ( 62%)]  Loss: 0.1445\n",
            "[  288/  477 ( 75%)]  Loss: 0.0732\n",
            "[  336/  477 ( 88%)]  Loss: 0.1379\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.0949  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 32\n",
            "[    0/  477 (  0%)]  Loss: 0.1812\n",
            "[   48/  477 ( 12%)]  Loss: 0.3775\n",
            "[   96/  477 ( 25%)]  Loss: 0.3690\n",
            "[  144/  477 ( 38%)]  Loss: 0.1253\n",
            "[  192/  477 ( 50%)]  Loss: 0.1618\n",
            "[  240/  477 ( 62%)]  Loss: 0.0210\n",
            "[  288/  477 ( 75%)]  Loss: 0.4760\n",
            "[  336/  477 ( 88%)]  Loss: 0.1746\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.0532  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 33\n",
            "[    0/  477 (  0%)]  Loss: 0.4999\n",
            "[   48/  477 ( 12%)]  Loss: 0.1835\n",
            "[   96/  477 ( 25%)]  Loss: 0.4361\n",
            "[  144/  477 ( 38%)]  Loss: 0.1308\n",
            "[  192/  477 ( 50%)]  Loss: 0.0644\n",
            "[  240/  477 ( 62%)]  Loss: 0.4992\n",
            "[  288/  477 ( 75%)]  Loss: 0.2023\n",
            "[  336/  477 ( 88%)]  Loss: 0.2604\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.3283  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 34\n",
            "[    0/  477 (  0%)]  Loss: 0.0163\n",
            "[   48/  477 ( 12%)]  Loss: 0.0318\n",
            "[   96/  477 ( 25%)]  Loss: 0.3691\n",
            "[  144/  477 ( 38%)]  Loss: 0.6865\n",
            "[  192/  477 ( 50%)]  Loss: 0.5800\n",
            "[  240/  477 ( 62%)]  Loss: 0.1310\n",
            "[  288/  477 ( 75%)]  Loss: 0.5943\n",
            "[  336/  477 ( 88%)]  Loss: 0.4739\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1317  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 35\n",
            "[    0/  477 (  0%)]  Loss: 0.2630\n",
            "[   48/  477 ( 12%)]  Loss: 0.1822\n",
            "[   96/  477 ( 25%)]  Loss: 0.2113\n",
            "[  144/  477 ( 38%)]  Loss: 0.0448\n",
            "[  192/  477 ( 50%)]  Loss: 0.1487\n",
            "[  240/  477 ( 62%)]  Loss: 0.1005\n",
            "[  288/  477 ( 75%)]  Loss: 0.7243\n",
            "[  336/  477 ( 88%)]  Loss: 0.9903\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0560  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 36\n",
            "[    0/  477 (  0%)]  Loss: 0.2961\n",
            "[   48/  477 ( 12%)]  Loss: 0.1989\n",
            "[   96/  477 ( 25%)]  Loss: 0.3693\n",
            "[  144/  477 ( 38%)]  Loss: 0.4971\n",
            "[  192/  477 ( 50%)]  Loss: 0.3594\n",
            "[  240/  477 ( 62%)]  Loss: 0.4691\n",
            "[  288/  477 ( 75%)]  Loss: 0.7950\n",
            "[  336/  477 ( 88%)]  Loss: 0.5925\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 0.9283  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 37\n",
            "[    0/  477 (  0%)]  Loss: 0.2294\n",
            "[   48/  477 ( 12%)]  Loss: 1.4661\n",
            "[   96/  477 ( 25%)]  Loss: 0.1592\n",
            "[  144/  477 ( 38%)]  Loss: 0.4635\n",
            "[  192/  477 ( 50%)]  Loss: 0.2504\n",
            "[  240/  477 ( 62%)]  Loss: 0.2452\n",
            "[  288/  477 ( 75%)]  Loss: 1.6368\n",
            "[  336/  477 ( 88%)]  Loss: 0.8225\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.0362  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 38\n",
            "[    0/  477 (  0%)]  Loss: 0.5049\n",
            "[   48/  477 ( 12%)]  Loss: 0.0586\n",
            "[   96/  477 ( 25%)]  Loss: 0.1303\n",
            "[  144/  477 ( 38%)]  Loss: 0.1226\n",
            "[  192/  477 ( 50%)]  Loss: 1.1196\n",
            "[  240/  477 ( 62%)]  Loss: 0.4152\n",
            "[  288/  477 ( 75%)]  Loss: 0.2164\n",
            "[  336/  477 ( 88%)]  Loss: 0.5324\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.0346  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 39\n",
            "[    0/  477 (  0%)]  Loss: 0.2024\n",
            "[   48/  477 ( 12%)]  Loss: 0.3877\n",
            "[   96/  477 ( 25%)]  Loss: 0.1631\n",
            "[  144/  477 ( 38%)]  Loss: 0.7170\n",
            "[  192/  477 ( 50%)]  Loss: 0.5690\n",
            "[  240/  477 ( 62%)]  Loss: 0.6895\n",
            "[  288/  477 ( 75%)]  Loss: 0.6215\n",
            "[  336/  477 ( 88%)]  Loss: 0.5907\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.0829  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 40\n",
            "[    0/  477 (  0%)]  Loss: 0.2509\n",
            "[   48/  477 ( 12%)]  Loss: 0.6048\n",
            "[   96/  477 ( 25%)]  Loss: 0.4940\n",
            "[  144/  477 ( 38%)]  Loss: 0.0050\n",
            "[  192/  477 ( 50%)]  Loss: 0.4109\n",
            "[  240/  477 ( 62%)]  Loss: 0.3267\n",
            "[  288/  477 ( 75%)]  Loss: 0.4686\n",
            "[  336/  477 ( 88%)]  Loss: 0.7421\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.0698  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 41\n",
            "[    0/  477 (  0%)]  Loss: 0.0944\n",
            "[   48/  477 ( 12%)]  Loss: 0.3824\n",
            "[   96/  477 ( 25%)]  Loss: 0.9856\n",
            "[  144/  477 ( 38%)]  Loss: 0.3105\n",
            "[  192/  477 ( 50%)]  Loss: 0.5766\n",
            "[  240/  477 ( 62%)]  Loss: 1.0113\n",
            "[  288/  477 ( 75%)]  Loss: 0.3833\n",
            "[  336/  477 ( 88%)]  Loss: 0.4864\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.1285  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 42\n",
            "[    0/  477 (  0%)]  Loss: 0.6836\n",
            "[   48/  477 ( 12%)]  Loss: 0.0324\n",
            "[   96/  477 ( 25%)]  Loss: 0.4818\n",
            "[  144/  477 ( 38%)]  Loss: 0.1170\n",
            "[  192/  477 ( 50%)]  Loss: 1.0141\n",
            "[  240/  477 ( 62%)]  Loss: 1.6134\n",
            "[  288/  477 ( 75%)]  Loss: 0.8055\n",
            "[  336/  477 ( 88%)]  Loss: 0.4876\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.0585  Accuracy:   47/  477 (9.85%)\n",
            "\n",
            "Epoch: 43\n",
            "[    0/  477 (  0%)]  Loss: 0.7157\n",
            "[   48/  477 ( 12%)]  Loss: 0.1642\n",
            "[   96/  477 ( 25%)]  Loss: 0.8269\n",
            "[  144/  477 ( 38%)]  Loss: 0.3093\n",
            "[  192/  477 ( 50%)]  Loss: 0.8067\n",
            "[  240/  477 ( 62%)]  Loss: 1.3621\n",
            "[  288/  477 ( 75%)]  Loss: 0.7311\n",
            "[  336/  477 ( 88%)]  Loss: 0.8653\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.0601  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 44\n",
            "[    0/  477 (  0%)]  Loss: 0.0231\n",
            "[   48/  477 ( 12%)]  Loss: 0.0740\n",
            "[   96/  477 ( 25%)]  Loss: 0.4015\n",
            "[  144/  477 ( 38%)]  Loss: 0.0308\n",
            "[  192/  477 ( 50%)]  Loss: 0.5525\n",
            "[  240/  477 ( 62%)]  Loss: 0.7762\n",
            "[  288/  477 ( 75%)]  Loss: 0.6906\n",
            "[  336/  477 ( 88%)]  Loss: 0.1303\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 1.0489  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 45\n",
            "[    0/  477 (  0%)]  Loss: 0.7507\n",
            "[   48/  477 ( 12%)]  Loss: 0.2581\n",
            "[   96/  477 ( 25%)]  Loss: 0.8337\n",
            "[  144/  477 ( 38%)]  Loss: 0.5947\n",
            "[  192/  477 ( 50%)]  Loss: 0.3542\n",
            "[  240/  477 ( 62%)]  Loss: 0.3632\n",
            "[  288/  477 ( 75%)]  Loss: 0.8022\n",
            "[  336/  477 ( 88%)]  Loss: 0.0623\n",
            "Execution time:  3.06 seconds\n",
            "\n",
            "Average test loss: 1.1611  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 46\n",
            "[    0/  477 (  0%)]  Loss: 0.1299\n",
            "[   48/  477 ( 12%)]  Loss: 0.2076\n",
            "[   96/  477 ( 25%)]  Loss: 0.8944\n",
            "[  144/  477 ( 38%)]  Loss: 0.9976\n",
            "[  192/  477 ( 50%)]  Loss: 0.2711\n",
            "[  240/  477 ( 62%)]  Loss: 0.0829\n",
            "[  288/  477 ( 75%)]  Loss: 0.8851\n",
            "[  336/  477 ( 88%)]  Loss: 0.4458\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 0.9947  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 47\n",
            "[    0/  477 (  0%)]  Loss: 0.1973\n",
            "[   48/  477 ( 12%)]  Loss: 0.0314\n",
            "[   96/  477 ( 25%)]  Loss: 0.4379\n",
            "[  144/  477 ( 38%)]  Loss: 0.4991\n",
            "[  192/  477 ( 50%)]  Loss: 0.0308\n",
            "[  240/  477 ( 62%)]  Loss: 0.8622\n",
            "[  288/  477 ( 75%)]  Loss: 0.5755\n",
            "[  336/  477 ( 88%)]  Loss: 0.5293\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0056  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 48\n",
            "[    0/  477 (  0%)]  Loss: 0.0989\n",
            "[   48/  477 ( 12%)]  Loss: 0.1822\n",
            "[   96/  477 ( 25%)]  Loss: 0.1579\n",
            "[  144/  477 ( 38%)]  Loss: 0.1296\n",
            "[  192/  477 ( 50%)]  Loss: 0.6383\n",
            "[  240/  477 ( 62%)]  Loss: 0.1248\n",
            "[  288/  477 ( 75%)]  Loss: 0.4788\n",
            "[  336/  477 ( 88%)]  Loss: 0.1386\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0408  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 49\n",
            "[    0/  477 (  0%)]  Loss: 0.1431\n",
            "[   48/  477 ( 12%)]  Loss: 0.5930\n",
            "[   96/  477 ( 25%)]  Loss: 0.9186\n",
            "[  144/  477 ( 38%)]  Loss: 0.6278\n",
            "[  192/  477 ( 50%)]  Loss: 0.4328\n",
            "[  240/  477 ( 62%)]  Loss: 0.0297\n",
            "[  288/  477 ( 75%)]  Loss: 0.5164\n",
            "[  336/  477 ( 88%)]  Loss: 0.9797\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0162  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 50\n",
            "[    0/  477 (  0%)]  Loss: 0.0424\n",
            "[   48/  477 ( 12%)]  Loss: 0.0348\n",
            "[   96/  477 ( 25%)]  Loss: 0.1425\n",
            "[  144/  477 ( 38%)]  Loss: 0.0550\n",
            "[  192/  477 ( 50%)]  Loss: 0.6258\n",
            "[  240/  477 ( 62%)]  Loss: 0.2916\n",
            "[  288/  477 ( 75%)]  Loss: 0.0828\n",
            "[  336/  477 ( 88%)]  Loss: 0.7413\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 0.9945  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 51\n",
            "[    0/  477 (  0%)]  Loss: 0.2048\n",
            "[   48/  477 ( 12%)]  Loss: 0.1515\n",
            "[   96/  477 ( 25%)]  Loss: 0.5133\n",
            "[  144/  477 ( 38%)]  Loss: 0.8948\n",
            "[  192/  477 ( 50%)]  Loss: 0.5202\n",
            "[  240/  477 ( 62%)]  Loss: 1.4747\n",
            "[  288/  477 ( 75%)]  Loss: 0.0358\n",
            "[  336/  477 ( 88%)]  Loss: 0.4591\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.1848  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 52\n",
            "[    0/  477 (  0%)]  Loss: 0.3639\n",
            "[   48/  477 ( 12%)]  Loss: 0.4666\n",
            "[   96/  477 ( 25%)]  Loss: 0.3385\n",
            "[  144/  477 ( 38%)]  Loss: 0.2792\n",
            "[  192/  477 ( 50%)]  Loss: 0.0848\n",
            "[  240/  477 ( 62%)]  Loss: 0.1201\n",
            "[  288/  477 ( 75%)]  Loss: 0.3043\n",
            "[  336/  477 ( 88%)]  Loss: 0.1523\n",
            "Execution time:  3.10 seconds\n",
            "\n",
            "Average test loss: 0.9754  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 53\n",
            "[    0/  477 (  0%)]  Loss: 0.3305\n",
            "[   48/  477 ( 12%)]  Loss: 0.0315\n",
            "[   96/  477 ( 25%)]  Loss: 0.1972\n",
            "[  144/  477 ( 38%)]  Loss: 0.6307\n",
            "[  192/  477 ( 50%)]  Loss: 0.1335\n",
            "[  240/  477 ( 62%)]  Loss: 0.0067\n",
            "[  288/  477 ( 75%)]  Loss: 0.5147\n",
            "[  336/  477 ( 88%)]  Loss: 0.3749\n",
            "Execution time:  3.03 seconds\n",
            "\n",
            "Average test loss: 1.0029  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 54\n",
            "[    0/  477 (  0%)]  Loss: 0.4953\n",
            "[   48/  477 ( 12%)]  Loss: 0.2079\n",
            "[   96/  477 ( 25%)]  Loss: 0.0467\n",
            "[  144/  477 ( 38%)]  Loss: 0.7524\n",
            "[  192/  477 ( 50%)]  Loss: 0.2614\n",
            "[  240/  477 ( 62%)]  Loss: 0.7599\n",
            "[  288/  477 ( 75%)]  Loss: 0.2816\n",
            "[  336/  477 ( 88%)]  Loss: 0.3457\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 0.9823  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 55\n",
            "[    0/  477 (  0%)]  Loss: 0.4414\n",
            "[   48/  477 ( 12%)]  Loss: 0.2147\n",
            "[   96/  477 ( 25%)]  Loss: 0.2809\n",
            "[  144/  477 ( 38%)]  Loss: 0.4717\n",
            "[  192/  477 ( 50%)]  Loss: 0.6912\n",
            "[  240/  477 ( 62%)]  Loss: 0.2031\n",
            "[  288/  477 ( 75%)]  Loss: 0.7513\n",
            "[  336/  477 ( 88%)]  Loss: 0.1018\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.1072  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 56\n",
            "[    0/  477 (  0%)]  Loss: 0.8124\n",
            "[   48/  477 ( 12%)]  Loss: 0.1341\n",
            "[   96/  477 ( 25%)]  Loss: 0.4400\n",
            "[  144/  477 ( 38%)]  Loss: 0.5582\n",
            "[  192/  477 ( 50%)]  Loss: 0.0953\n",
            "[  240/  477 ( 62%)]  Loss: 0.4429\n",
            "[  288/  477 ( 75%)]  Loss: 0.2432\n",
            "[  336/  477 ( 88%)]  Loss: 1.4049\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0200  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 57\n",
            "[    0/  477 (  0%)]  Loss: 0.4839\n",
            "[   48/  477 ( 12%)]  Loss: 0.0294\n",
            "[   96/  477 ( 25%)]  Loss: 0.3320\n",
            "[  144/  477 ( 38%)]  Loss: 0.0573\n",
            "[  192/  477 ( 50%)]  Loss: 0.1383\n",
            "[  240/  477 ( 62%)]  Loss: 1.1957\n",
            "[  288/  477 ( 75%)]  Loss: 0.1702\n",
            "[  336/  477 ( 88%)]  Loss: 0.1182\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1325  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 58\n",
            "[    0/  477 (  0%)]  Loss: 0.0789\n",
            "[   48/  477 ( 12%)]  Loss: 0.0350\n",
            "[   96/  477 ( 25%)]  Loss: 0.0298\n",
            "[  144/  477 ( 38%)]  Loss: 0.5026\n",
            "[  192/  477 ( 50%)]  Loss: 0.2973\n",
            "[  240/  477 ( 62%)]  Loss: 0.1904\n",
            "[  288/  477 ( 75%)]  Loss: 0.0128\n",
            "[  336/  477 ( 88%)]  Loss: 0.1355\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0263  Accuracy:   57/  477 (11.95%)\n",
            "\n",
            "Epoch: 59\n",
            "[    0/  477 (  0%)]  Loss: 0.0893\n",
            "[   48/  477 ( 12%)]  Loss: 0.8081\n",
            "[   96/  477 ( 25%)]  Loss: 0.0428\n",
            "[  144/  477 ( 38%)]  Loss: 0.2426\n",
            "[  192/  477 ( 50%)]  Loss: 0.0896\n",
            "[  240/  477 ( 62%)]  Loss: 0.1759\n",
            "[  288/  477 ( 75%)]  Loss: 0.0267\n",
            "[  336/  477 ( 88%)]  Loss: 0.0340\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0221  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 60\n",
            "[    0/  477 (  0%)]  Loss: 0.0192\n",
            "[   48/  477 ( 12%)]  Loss: 0.0028\n",
            "[   96/  477 ( 25%)]  Loss: 0.4027\n",
            "[  144/  477 ( 38%)]  Loss: 0.0638\n",
            "[  192/  477 ( 50%)]  Loss: 0.3727\n",
            "[  240/  477 ( 62%)]  Loss: 0.0542\n",
            "[  288/  477 ( 75%)]  Loss: 0.0921\n",
            "[  336/  477 ( 88%)]  Loss: 0.7258\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.0759  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 61\n",
            "[    0/  477 (  0%)]  Loss: 0.2909\n",
            "[   48/  477 ( 12%)]  Loss: 0.5524\n",
            "[   96/  477 ( 25%)]  Loss: 0.1268\n",
            "[  144/  477 ( 38%)]  Loss: 0.1493\n",
            "[  192/  477 ( 50%)]  Loss: 0.0835\n",
            "[  240/  477 ( 62%)]  Loss: 0.2003\n",
            "[  288/  477 ( 75%)]  Loss: 0.0393\n",
            "[  336/  477 ( 88%)]  Loss: 0.2113\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.1333  Accuracy:   45/  477 (9.43%)\n",
            "\n",
            "Epoch: 62\n",
            "[    0/  477 (  0%)]  Loss: 0.0315\n",
            "[   48/  477 ( 12%)]  Loss: 0.0042\n",
            "[   96/  477 ( 25%)]  Loss: 0.4274\n",
            "[  144/  477 ( 38%)]  Loss: 0.0896\n",
            "[  192/  477 ( 50%)]  Loss: 0.4817\n",
            "[  240/  477 ( 62%)]  Loss: 0.1341\n",
            "[  288/  477 ( 75%)]  Loss: 0.1225\n",
            "[  336/  477 ( 88%)]  Loss: 0.5169\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.1021  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 63\n",
            "[    0/  477 (  0%)]  Loss: 0.0701\n",
            "[   48/  477 ( 12%)]  Loss: 0.2987\n",
            "[   96/  477 ( 25%)]  Loss: 0.3216\n",
            "[  144/  477 ( 38%)]  Loss: 0.0508\n",
            "[  192/  477 ( 50%)]  Loss: 1.0722\n",
            "[  240/  477 ( 62%)]  Loss: 0.5977\n",
            "[  288/  477 ( 75%)]  Loss: 0.1210\n",
            "[  336/  477 ( 88%)]  Loss: 1.2064\n",
            "Execution time:  3.09 seconds\n",
            "\n",
            "Average test loss: 1.1437  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 64\n",
            "[    0/  477 (  0%)]  Loss: 0.1711\n",
            "[   48/  477 ( 12%)]  Loss: 0.3700\n",
            "[   96/  477 ( 25%)]  Loss: 0.1655\n",
            "[  144/  477 ( 38%)]  Loss: 0.0881\n",
            "[  192/  477 ( 50%)]  Loss: 0.2513\n",
            "[  240/  477 ( 62%)]  Loss: 0.1128\n",
            "[  288/  477 ( 75%)]  Loss: 0.1591\n",
            "[  336/  477 ( 88%)]  Loss: 0.1496\n",
            "Execution time:  3.05 seconds\n",
            "\n",
            "Average test loss: 1.1276  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 65\n",
            "[    0/  477 (  0%)]  Loss: 0.1238\n",
            "[   48/  477 ( 12%)]  Loss: 0.0210\n",
            "[   96/  477 ( 25%)]  Loss: 0.1116\n",
            "[  144/  477 ( 38%)]  Loss: 1.4425\n",
            "[  192/  477 ( 50%)]  Loss: 0.3610\n",
            "[  240/  477 ( 62%)]  Loss: 0.0545\n",
            "[  288/  477 ( 75%)]  Loss: 0.1074\n",
            "[  336/  477 ( 88%)]  Loss: 0.1244\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.1263  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 66\n",
            "[    0/  477 (  0%)]  Loss: 0.0928\n",
            "[   48/  477 ( 12%)]  Loss: 0.2319\n",
            "[   96/  477 ( 25%)]  Loss: 0.0336\n",
            "[  144/  477 ( 38%)]  Loss: 0.6067\n",
            "[  192/  477 ( 50%)]  Loss: 0.2538\n",
            "[  240/  477 ( 62%)]  Loss: 0.7112\n",
            "[  288/  477 ( 75%)]  Loss: 0.0525\n",
            "[  336/  477 ( 88%)]  Loss: 0.3124\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.2303  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 67\n",
            "[    0/  477 (  0%)]  Loss: 0.2918\n",
            "[   48/  477 ( 12%)]  Loss: 0.0296\n",
            "[   96/  477 ( 25%)]  Loss: 0.2440\n",
            "[  144/  477 ( 38%)]  Loss: 0.1772\n",
            "[  192/  477 ( 50%)]  Loss: 0.2846\n",
            "[  240/  477 ( 62%)]  Loss: 0.4379\n",
            "[  288/  477 ( 75%)]  Loss: 0.4420\n",
            "[  336/  477 ( 88%)]  Loss: 0.1251\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0166  Accuracy:   60/  477 (12.58%)\n",
            "\n",
            "Epoch: 68\n",
            "[    0/  477 (  0%)]  Loss: 0.7485\n",
            "[   48/  477 ( 12%)]  Loss: 0.7822\n",
            "[   96/  477 ( 25%)]  Loss: 0.5072\n",
            "[  144/  477 ( 38%)]  Loss: 0.2528\n",
            "[  192/  477 ( 50%)]  Loss: 0.3004\n",
            "[  240/  477 ( 62%)]  Loss: 0.6174\n",
            "[  288/  477 ( 75%)]  Loss: 0.2503\n",
            "[  336/  477 ( 88%)]  Loss: 0.3026\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.1411  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 69\n",
            "[    0/  477 (  0%)]  Loss: 0.2693\n",
            "[   48/  477 ( 12%)]  Loss: 0.0185\n",
            "[   96/  477 ( 25%)]  Loss: 0.6528\n",
            "[  144/  477 ( 38%)]  Loss: 1.1088\n",
            "[  192/  477 ( 50%)]  Loss: 0.1291\n",
            "[  240/  477 ( 62%)]  Loss: 0.1479\n",
            "[  288/  477 ( 75%)]  Loss: 0.2011\n",
            "[  336/  477 ( 88%)]  Loss: 0.2382\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 1.0370  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 70\n",
            "[    0/  477 (  0%)]  Loss: 0.1851\n",
            "[   48/  477 ( 12%)]  Loss: 0.0593\n",
            "[   96/  477 ( 25%)]  Loss: 0.1453\n",
            "[  144/  477 ( 38%)]  Loss: 0.7794\n",
            "[  192/  477 ( 50%)]  Loss: 0.0919\n",
            "[  240/  477 ( 62%)]  Loss: 1.0701\n",
            "[  288/  477 ( 75%)]  Loss: 0.3427\n",
            "[  336/  477 ( 88%)]  Loss: 0.0197\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.1952  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 71\n",
            "[    0/  477 (  0%)]  Loss: 0.5745\n",
            "[   48/  477 ( 12%)]  Loss: 0.6287\n",
            "[   96/  477 ( 25%)]  Loss: 0.1019\n",
            "[  144/  477 ( 38%)]  Loss: 0.2000\n",
            "[  192/  477 ( 50%)]  Loss: 0.5025\n",
            "[  240/  477 ( 62%)]  Loss: 0.1567\n",
            "[  288/  477 ( 75%)]  Loss: 0.3106\n",
            "[  336/  477 ( 88%)]  Loss: 0.1096\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1688  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 72\n",
            "[    0/  477 (  0%)]  Loss: 0.4527\n",
            "[   48/  477 ( 12%)]  Loss: 0.0116\n",
            "[   96/  477 ( 25%)]  Loss: 0.3754\n",
            "[  144/  477 ( 38%)]  Loss: 0.1175\n",
            "[  192/  477 ( 50%)]  Loss: 0.5617\n",
            "[  240/  477 ( 62%)]  Loss: 0.3002\n",
            "[  288/  477 ( 75%)]  Loss: 0.5235\n",
            "[  336/  477 ( 88%)]  Loss: 0.1222\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.2264  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 73\n",
            "[    0/  477 (  0%)]  Loss: 0.4837\n",
            "[   48/  477 ( 12%)]  Loss: 0.4148\n",
            "[   96/  477 ( 25%)]  Loss: 0.1405\n",
            "[  144/  477 ( 38%)]  Loss: 0.5286\n",
            "[  192/  477 ( 50%)]  Loss: 0.6049\n",
            "[  240/  477 ( 62%)]  Loss: 0.4903\n",
            "[  288/  477 ( 75%)]  Loss: 0.3480\n",
            "[  336/  477 ( 88%)]  Loss: 0.8934\n",
            "Execution time:  3.04 seconds\n",
            "\n",
            "Average test loss: 1.0871  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 74\n",
            "[    0/  477 (  0%)]  Loss: 0.1810\n",
            "[   48/  477 ( 12%)]  Loss: 0.0342\n",
            "[   96/  477 ( 25%)]  Loss: 0.2377\n",
            "[  144/  477 ( 38%)]  Loss: 0.6872\n",
            "[  192/  477 ( 50%)]  Loss: 0.2194\n",
            "[  240/  477 ( 62%)]  Loss: 0.1643\n",
            "[  288/  477 ( 75%)]  Loss: 0.4107\n",
            "[  336/  477 ( 88%)]  Loss: 0.1202\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.1514  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 75\n",
            "[    0/  477 (  0%)]  Loss: 0.1735\n",
            "[   48/  477 ( 12%)]  Loss: 0.1047\n",
            "[   96/  477 ( 25%)]  Loss: 0.0830\n",
            "[  144/  477 ( 38%)]  Loss: 0.2618\n",
            "[  192/  477 ( 50%)]  Loss: 0.2270\n",
            "[  240/  477 ( 62%)]  Loss: 0.5792\n",
            "[  288/  477 ( 75%)]  Loss: 0.1321\n",
            "[  336/  477 ( 88%)]  Loss: 0.1463\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1073  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 76\n",
            "[    0/  477 (  0%)]  Loss: 0.4133\n",
            "[   48/  477 ( 12%)]  Loss: 0.9289\n",
            "[   96/  477 ( 25%)]  Loss: 0.1635\n",
            "[  144/  477 ( 38%)]  Loss: 0.3271\n",
            "[  192/  477 ( 50%)]  Loss: 0.3025\n",
            "[  240/  477 ( 62%)]  Loss: 0.8252\n",
            "[  288/  477 ( 75%)]  Loss: 0.0745\n",
            "[  336/  477 ( 88%)]  Loss: 0.8517\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.1967  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 77\n",
            "[    0/  477 (  0%)]  Loss: 0.0135\n",
            "[   48/  477 ( 12%)]  Loss: 0.2248\n",
            "[   96/  477 ( 25%)]  Loss: 0.0262\n",
            "[  144/  477 ( 38%)]  Loss: 0.2321\n",
            "[  192/  477 ( 50%)]  Loss: 0.0700\n",
            "[  240/  477 ( 62%)]  Loss: 0.1119\n",
            "[  288/  477 ( 75%)]  Loss: 0.3251\n",
            "[  336/  477 ( 88%)]  Loss: 0.1170\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 1.1436  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 78\n",
            "[    0/  477 (  0%)]  Loss: 0.1382\n",
            "[   48/  477 ( 12%)]  Loss: 0.1572\n",
            "[   96/  477 ( 25%)]  Loss: 0.0115\n",
            "[  144/  477 ( 38%)]  Loss: 0.0262\n",
            "[  192/  477 ( 50%)]  Loss: 0.0538\n",
            "[  240/  477 ( 62%)]  Loss: 0.1874\n",
            "[  288/  477 ( 75%)]  Loss: 0.0017\n",
            "[  336/  477 ( 88%)]  Loss: 0.4148\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.0293  Accuracy:   59/  477 (12.37%)\n",
            "\n",
            "Epoch: 79\n",
            "[    0/  477 (  0%)]  Loss: 0.0023\n",
            "[   48/  477 ( 12%)]  Loss: 0.0249\n",
            "[   96/  477 ( 25%)]  Loss: 0.0707\n",
            "[  144/  477 ( 38%)]  Loss: 0.2436\n",
            "[  192/  477 ( 50%)]  Loss: 0.2481\n",
            "[  240/  477 ( 62%)]  Loss: 0.0045\n",
            "[  288/  477 ( 75%)]  Loss: 0.0165\n",
            "[  336/  477 ( 88%)]  Loss: 0.0738\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0875  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 80\n",
            "[    0/  477 (  0%)]  Loss: 0.0315\n",
            "[   48/  477 ( 12%)]  Loss: 0.0268\n",
            "[   96/  477 ( 25%)]  Loss: 1.1166\n",
            "[  144/  477 ( 38%)]  Loss: 0.3304\n",
            "[  192/  477 ( 50%)]  Loss: 0.1682\n",
            "[  240/  477 ( 62%)]  Loss: 0.2004\n",
            "[  288/  477 ( 75%)]  Loss: 1.0764\n",
            "[  336/  477 ( 88%)]  Loss: 0.2146\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.1117  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 81\n",
            "[    0/  477 (  0%)]  Loss: 0.0138\n",
            "[   48/  477 ( 12%)]  Loss: 0.2569\n",
            "[   96/  477 ( 25%)]  Loss: 0.2629\n",
            "[  144/  477 ( 38%)]  Loss: 0.0434\n",
            "[  192/  477 ( 50%)]  Loss: 0.4700\n",
            "[  240/  477 ( 62%)]  Loss: 0.1254\n",
            "[  288/  477 ( 75%)]  Loss: 0.1770\n",
            "[  336/  477 ( 88%)]  Loss: 0.5193\n",
            "Execution time:  3.03 seconds\n",
            "\n",
            "Average test loss: 1.0204  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 82\n",
            "[    0/  477 (  0%)]  Loss: 0.2477\n",
            "[   48/  477 ( 12%)]  Loss: 0.0076\n",
            "[   96/  477 ( 25%)]  Loss: 0.1019\n",
            "[  144/  477 ( 38%)]  Loss: 0.1110\n",
            "[  192/  477 ( 50%)]  Loss: 0.2218\n",
            "[  240/  477 ( 62%)]  Loss: 0.2363\n",
            "[  288/  477 ( 75%)]  Loss: 0.2248\n",
            "[  336/  477 ( 88%)]  Loss: 0.0485\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 1.0010  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 83\n",
            "[    0/  477 (  0%)]  Loss: 0.4756\n",
            "[   48/  477 ( 12%)]  Loss: 0.2429\n",
            "[   96/  477 ( 25%)]  Loss: 0.0634\n",
            "[  144/  477 ( 38%)]  Loss: 0.0784\n",
            "[  192/  477 ( 50%)]  Loss: 0.2847\n",
            "[  240/  477 ( 62%)]  Loss: 0.1269\n",
            "[  288/  477 ( 75%)]  Loss: 0.4590\n",
            "[  336/  477 ( 88%)]  Loss: 0.0654\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.0353  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 84\n",
            "[    0/  477 (  0%)]  Loss: 0.3706\n",
            "[   48/  477 ( 12%)]  Loss: 0.0067\n",
            "[   96/  477 ( 25%)]  Loss: 0.0316\n",
            "[  144/  477 ( 38%)]  Loss: 0.0864\n",
            "[  192/  477 ( 50%)]  Loss: 0.0197\n",
            "[  240/  477 ( 62%)]  Loss: 0.2723\n",
            "[  288/  477 ( 75%)]  Loss: 0.1475\n",
            "[  336/  477 ( 88%)]  Loss: 0.2632\n",
            "Execution time:  3.05 seconds\n",
            "\n",
            "Average test loss: 1.0153  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 85\n",
            "[    0/  477 (  0%)]  Loss: 0.1355\n",
            "[   48/  477 ( 12%)]  Loss: 0.2334\n",
            "[   96/  477 ( 25%)]  Loss: 0.2564\n",
            "[  144/  477 ( 38%)]  Loss: 0.0053\n",
            "[  192/  477 ( 50%)]  Loss: 0.1053\n",
            "[  240/  477 ( 62%)]  Loss: 0.0789\n",
            "[  288/  477 ( 75%)]  Loss: 0.1077\n",
            "[  336/  477 ( 88%)]  Loss: 0.1663\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.0040  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 86\n",
            "[    0/  477 (  0%)]  Loss: 0.0561\n",
            "[   48/  477 ( 12%)]  Loss: 0.3780\n",
            "[   96/  477 ( 25%)]  Loss: 0.4660\n",
            "[  144/  477 ( 38%)]  Loss: 0.1269\n",
            "[  192/  477 ( 50%)]  Loss: 0.8334\n",
            "[  240/  477 ( 62%)]  Loss: 0.0203\n",
            "[  288/  477 ( 75%)]  Loss: 1.3410\n",
            "[  336/  477 ( 88%)]  Loss: 0.1092\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.1014  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 87\n",
            "[    0/  477 (  0%)]  Loss: 0.8924\n",
            "[   48/  477 ( 12%)]  Loss: 0.0172\n",
            "[   96/  477 ( 25%)]  Loss: 0.3524\n",
            "[  144/  477 ( 38%)]  Loss: 0.0336\n",
            "[  192/  477 ( 50%)]  Loss: 0.1324\n",
            "[  240/  477 ( 62%)]  Loss: 0.0959\n",
            "[  288/  477 ( 75%)]  Loss: 0.0771\n",
            "[  336/  477 ( 88%)]  Loss: 0.3523\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.1043  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 88\n",
            "[    0/  477 (  0%)]  Loss: 0.6659\n",
            "[   48/  477 ( 12%)]  Loss: 0.1318\n",
            "[   96/  477 ( 25%)]  Loss: 0.2280\n",
            "[  144/  477 ( 38%)]  Loss: 0.1059\n",
            "[  192/  477 ( 50%)]  Loss: 0.0286\n",
            "[  240/  477 ( 62%)]  Loss: 0.0908\n",
            "[  288/  477 ( 75%)]  Loss: 0.0852\n",
            "[  336/  477 ( 88%)]  Loss: 0.2626\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0612  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 89\n",
            "[    0/  477 (  0%)]  Loss: 0.2932\n",
            "[   48/  477 ( 12%)]  Loss: 0.0165\n",
            "[   96/  477 ( 25%)]  Loss: 0.1400\n",
            "[  144/  477 ( 38%)]  Loss: 0.1591\n",
            "[  192/  477 ( 50%)]  Loss: 0.0157\n",
            "[  240/  477 ( 62%)]  Loss: 0.0910\n",
            "[  288/  477 ( 75%)]  Loss: 0.0510\n",
            "[  336/  477 ( 88%)]  Loss: 0.5214\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.1453  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 90\n",
            "[    0/  477 (  0%)]  Loss: 0.3601\n",
            "[   48/  477 ( 12%)]  Loss: 0.0565\n",
            "[   96/  477 ( 25%)]  Loss: 0.1323\n",
            "[  144/  477 ( 38%)]  Loss: 0.0623\n",
            "[  192/  477 ( 50%)]  Loss: 0.6083\n",
            "[  240/  477 ( 62%)]  Loss: 0.0779\n",
            "[  288/  477 ( 75%)]  Loss: 0.3072\n",
            "[  336/  477 ( 88%)]  Loss: 0.3914\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0616  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 91\n",
            "[    0/  477 (  0%)]  Loss: 0.0985\n",
            "[   48/  477 ( 12%)]  Loss: 0.1746\n",
            "[   96/  477 ( 25%)]  Loss: 0.0331\n",
            "[  144/  477 ( 38%)]  Loss: 0.0847\n",
            "[  192/  477 ( 50%)]  Loss: 0.0727\n",
            "[  240/  477 ( 62%)]  Loss: 0.1309\n",
            "[  288/  477 ( 75%)]  Loss: 0.2461\n",
            "[  336/  477 ( 88%)]  Loss: 0.0191\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.0490  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 92\n",
            "[    0/  477 (  0%)]  Loss: 0.0081\n",
            "[   48/  477 ( 12%)]  Loss: 0.0668\n",
            "[   96/  477 ( 25%)]  Loss: 0.1311\n",
            "[  144/  477 ( 38%)]  Loss: 1.3250\n",
            "[  192/  477 ( 50%)]  Loss: 0.0271\n",
            "[  240/  477 ( 62%)]  Loss: 0.0248\n",
            "[  288/  477 ( 75%)]  Loss: 0.1435\n",
            "[  336/  477 ( 88%)]  Loss: 0.8716\n",
            "Execution time:  3.03 seconds\n",
            "\n",
            "Average test loss: 1.0923  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 93\n",
            "[    0/  477 (  0%)]  Loss: 0.0249\n",
            "[   48/  477 ( 12%)]  Loss: 0.5113\n",
            "[   96/  477 ( 25%)]  Loss: 0.1145\n",
            "[  144/  477 ( 38%)]  Loss: 0.0468\n",
            "[  192/  477 ( 50%)]  Loss: 0.0412\n",
            "[  240/  477 ( 62%)]  Loss: 0.0091\n",
            "[  288/  477 ( 75%)]  Loss: 0.4231\n",
            "[  336/  477 ( 88%)]  Loss: 0.1251\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.1904  Accuracy:   47/  477 (9.85%)\n",
            "\n",
            "Epoch: 94\n",
            "[    0/  477 (  0%)]  Loss: 0.4715\n",
            "[   48/  477 ( 12%)]  Loss: 0.1113\n",
            "[   96/  477 ( 25%)]  Loss: 0.0827\n",
            "[  144/  477 ( 38%)]  Loss: 0.7420\n",
            "[  192/  477 ( 50%)]  Loss: 0.2614\n",
            "[  240/  477 ( 62%)]  Loss: 0.1184\n",
            "[  288/  477 ( 75%)]  Loss: 0.0595\n",
            "[  336/  477 ( 88%)]  Loss: 0.0467\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.1377  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 95\n",
            "[    0/  477 (  0%)]  Loss: 0.1830\n",
            "[   48/  477 ( 12%)]  Loss: 0.1919\n",
            "[   96/  477 ( 25%)]  Loss: 0.5199\n",
            "[  144/  477 ( 38%)]  Loss: 0.6496\n",
            "[  192/  477 ( 50%)]  Loss: 0.2997\n",
            "[  240/  477 ( 62%)]  Loss: 1.2842\n",
            "[  288/  477 ( 75%)]  Loss: 0.2397\n",
            "[  336/  477 ( 88%)]  Loss: 0.8184\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 1.1303  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 96\n",
            "[    0/  477 (  0%)]  Loss: 0.4536\n",
            "[   48/  477 ( 12%)]  Loss: 0.1798\n",
            "[   96/  477 ( 25%)]  Loss: 0.1092\n",
            "[  144/  477 ( 38%)]  Loss: 0.1552\n",
            "[  192/  477 ( 50%)]  Loss: 0.3057\n",
            "[  240/  477 ( 62%)]  Loss: 0.1494\n",
            "[  288/  477 ( 75%)]  Loss: 0.1582\n",
            "[  336/  477 ( 88%)]  Loss: 0.0588\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.1136  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 97\n",
            "[    0/  477 (  0%)]  Loss: 0.1686\n",
            "[   48/  477 ( 12%)]  Loss: 0.2734\n",
            "[   96/  477 ( 25%)]  Loss: 0.2072\n",
            "[  144/  477 ( 38%)]  Loss: 0.0731\n",
            "[  192/  477 ( 50%)]  Loss: 0.0741\n",
            "[  240/  477 ( 62%)]  Loss: 1.1260\n",
            "[  288/  477 ( 75%)]  Loss: 0.3288\n",
            "[  336/  477 ( 88%)]  Loss: 0.2725\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.1066  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 98\n",
            "[    0/  477 (  0%)]  Loss: 0.1625\n",
            "[   48/  477 ( 12%)]  Loss: 0.1641\n",
            "[   96/  477 ( 25%)]  Loss: 0.0338\n",
            "[  144/  477 ( 38%)]  Loss: 0.6524\n",
            "[  192/  477 ( 50%)]  Loss: 0.1379\n",
            "[  240/  477 ( 62%)]  Loss: 0.2258\n",
            "[  288/  477 ( 75%)]  Loss: 0.4366\n",
            "[  336/  477 ( 88%)]  Loss: 0.3098\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1326  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 99\n",
            "[    0/  477 (  0%)]  Loss: 1.1126\n",
            "[   48/  477 ( 12%)]  Loss: 0.1932\n",
            "[   96/  477 ( 25%)]  Loss: 1.3170\n",
            "[  144/  477 ( 38%)]  Loss: 0.4614\n",
            "[  192/  477 ( 50%)]  Loss: 0.6317\n",
            "[  240/  477 ( 62%)]  Loss: 0.1029\n",
            "[  288/  477 ( 75%)]  Loss: 0.1083\n",
            "[  336/  477 ( 88%)]  Loss: 0.3843\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.0307  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 100\n",
            "[    0/  477 (  0%)]  Loss: 1.4819\n",
            "[   48/  477 ( 12%)]  Loss: 0.2297\n",
            "[   96/  477 ( 25%)]  Loss: 0.0614\n",
            "[  144/  477 ( 38%)]  Loss: 0.5404\n",
            "[  192/  477 ( 50%)]  Loss: 1.7776\n",
            "[  240/  477 ( 62%)]  Loss: 1.8448\n",
            "[  288/  477 ( 75%)]  Loss: 0.0577\n",
            "[  336/  477 ( 88%)]  Loss: 2.4563\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.1377  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 101\n",
            "[    0/  477 (  0%)]  Loss: 1.5430\n",
            "[   48/  477 ( 12%)]  Loss: 0.3228\n",
            "[   96/  477 ( 25%)]  Loss: 0.3118\n",
            "[  144/  477 ( 38%)]  Loss: 0.3008\n",
            "[  192/  477 ( 50%)]  Loss: 0.2794\n",
            "[  240/  477 ( 62%)]  Loss: 0.5979\n",
            "[  288/  477 ( 75%)]  Loss: 0.7433\n",
            "[  336/  477 ( 88%)]  Loss: 0.8586\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.2223  Accuracy:   43/  477 (9.01%)\n",
            "\n",
            "Epoch: 102\n",
            "[    0/  477 (  0%)]  Loss: 0.6111\n",
            "[   48/  477 ( 12%)]  Loss: 1.9180\n",
            "[   96/  477 ( 25%)]  Loss: 0.7221\n",
            "[  144/  477 ( 38%)]  Loss: 0.1857\n",
            "[  192/  477 ( 50%)]  Loss: 0.9556\n",
            "[  240/  477 ( 62%)]  Loss: 0.9852\n",
            "[  288/  477 ( 75%)]  Loss: 0.0940\n",
            "[  336/  477 ( 88%)]  Loss: 1.0896\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.0658  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 103\n",
            "[    0/  477 (  0%)]  Loss: 0.3551\n",
            "[   48/  477 ( 12%)]  Loss: 0.3424\n",
            "[   96/  477 ( 25%)]  Loss: 1.9674\n",
            "[  144/  477 ( 38%)]  Loss: 0.4892\n",
            "[  192/  477 ( 50%)]  Loss: 0.4100\n",
            "[  240/  477 ( 62%)]  Loss: 0.0959\n",
            "[  288/  477 ( 75%)]  Loss: 0.1622\n",
            "[  336/  477 ( 88%)]  Loss: 0.1798\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.1212  Accuracy:   49/  477 (10.27%)\n",
            "\n",
            "Epoch: 104\n",
            "[    0/  477 (  0%)]  Loss: 0.4518\n",
            "[   48/  477 ( 12%)]  Loss: 0.2139\n",
            "[   96/  477 ( 25%)]  Loss: 0.0115\n",
            "[  144/  477 ( 38%)]  Loss: 0.4320\n",
            "[  192/  477 ( 50%)]  Loss: 0.5812\n",
            "[  240/  477 ( 62%)]  Loss: 0.0790\n",
            "[  288/  477 ( 75%)]  Loss: 0.0439\n",
            "[  336/  477 ( 88%)]  Loss: 0.1772\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1368  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 105\n",
            "[    0/  477 (  0%)]  Loss: 0.1975\n",
            "[   48/  477 ( 12%)]  Loss: 0.9041\n",
            "[   96/  477 ( 25%)]  Loss: 0.3086\n",
            "[  144/  477 ( 38%)]  Loss: 0.2454\n",
            "[  192/  477 ( 50%)]  Loss: 0.4337\n",
            "[  240/  477 ( 62%)]  Loss: 0.0130\n",
            "[  288/  477 ( 75%)]  Loss: 0.4740\n",
            "[  336/  477 ( 88%)]  Loss: 1.3493\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0941  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 106\n",
            "[    0/  477 (  0%)]  Loss: 0.3554\n",
            "[   48/  477 ( 12%)]  Loss: 0.2448\n",
            "[   96/  477 ( 25%)]  Loss: 0.0865\n",
            "[  144/  477 ( 38%)]  Loss: 0.7211\n",
            "[  192/  477 ( 50%)]  Loss: 0.3817\n",
            "[  240/  477 ( 62%)]  Loss: 1.3386\n",
            "[  288/  477 ( 75%)]  Loss: 0.3122\n",
            "[  336/  477 ( 88%)]  Loss: 0.3196\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 0.9843  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 107\n",
            "[    0/  477 (  0%)]  Loss: 0.2856\n",
            "[   48/  477 ( 12%)]  Loss: 0.2527\n",
            "[   96/  477 ( 25%)]  Loss: 0.0440\n",
            "[  144/  477 ( 38%)]  Loss: 0.0458\n",
            "[  192/  477 ( 50%)]  Loss: 0.1830\n",
            "[  240/  477 ( 62%)]  Loss: 0.1412\n",
            "[  288/  477 ( 75%)]  Loss: 0.0524\n",
            "[  336/  477 ( 88%)]  Loss: 0.2032\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.0183  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 108\n",
            "[    0/  477 (  0%)]  Loss: 0.0819\n",
            "[   48/  477 ( 12%)]  Loss: 0.0287\n",
            "[   96/  477 ( 25%)]  Loss: 0.1483\n",
            "[  144/  477 ( 38%)]  Loss: 0.0515\n",
            "[  192/  477 ( 50%)]  Loss: 0.1685\n",
            "[  240/  477 ( 62%)]  Loss: 0.1569\n",
            "[  288/  477 ( 75%)]  Loss: 0.1338\n",
            "[  336/  477 ( 88%)]  Loss: 0.0311\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 1.0283  Accuracy:   46/  477 (9.64%)\n",
            "\n",
            "Epoch: 109\n",
            "[    0/  477 (  0%)]  Loss: 0.0376\n",
            "[   48/  477 ( 12%)]  Loss: 0.0543\n",
            "[   96/  477 ( 25%)]  Loss: 0.5301\n",
            "[  144/  477 ( 38%)]  Loss: 0.2383\n",
            "[  192/  477 ( 50%)]  Loss: 0.1047\n",
            "[  240/  477 ( 62%)]  Loss: 0.4722\n",
            "[  288/  477 ( 75%)]  Loss: 0.2447\n",
            "[  336/  477 ( 88%)]  Loss: 0.4546\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.0851  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 110\n",
            "[    0/  477 (  0%)]  Loss: 0.0266\n",
            "[   48/  477 ( 12%)]  Loss: 0.0666\n",
            "[   96/  477 ( 25%)]  Loss: 0.0367\n",
            "[  144/  477 ( 38%)]  Loss: 0.2449\n",
            "[  192/  477 ( 50%)]  Loss: 0.0779\n",
            "[  240/  477 ( 62%)]  Loss: 0.0019\n",
            "[  288/  477 ( 75%)]  Loss: 0.3229\n",
            "[  336/  477 ( 88%)]  Loss: 0.0702\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.0869  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 111\n",
            "[    0/  477 (  0%)]  Loss: 0.0797\n",
            "[   48/  477 ( 12%)]  Loss: 0.0962\n",
            "[   96/  477 ( 25%)]  Loss: 0.1636\n",
            "[  144/  477 ( 38%)]  Loss: 0.2043\n",
            "[  192/  477 ( 50%)]  Loss: 0.0349\n",
            "[  240/  477 ( 62%)]  Loss: 0.0196\n",
            "[  288/  477 ( 75%)]  Loss: 0.0298\n",
            "[  336/  477 ( 88%)]  Loss: 0.0265\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 0.8857  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 112\n",
            "[    0/  477 (  0%)]  Loss: 0.3342\n",
            "[   48/  477 ( 12%)]  Loss: 0.0640\n",
            "[   96/  477 ( 25%)]  Loss: 0.0103\n",
            "[  144/  477 ( 38%)]  Loss: 0.0574\n",
            "[  192/  477 ( 50%)]  Loss: 0.1002\n",
            "[  240/  477 ( 62%)]  Loss: 0.1305\n",
            "[  288/  477 ( 75%)]  Loss: 0.1251\n",
            "[  336/  477 ( 88%)]  Loss: 0.2120\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 0.9912  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 113\n",
            "[    0/  477 (  0%)]  Loss: 0.0955\n",
            "[   48/  477 ( 12%)]  Loss: 0.0034\n",
            "[   96/  477 ( 25%)]  Loss: 0.3096\n",
            "[  144/  477 ( 38%)]  Loss: 0.0855\n",
            "[  192/  477 ( 50%)]  Loss: 0.2095\n",
            "[  240/  477 ( 62%)]  Loss: 0.4951\n",
            "[  288/  477 ( 75%)]  Loss: 0.2139\n",
            "[  336/  477 ( 88%)]  Loss: 0.2767\n",
            "Execution time:  3.05 seconds\n",
            "\n",
            "Average test loss: 0.9578  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 114\n",
            "[    0/  477 (  0%)]  Loss: 0.0160\n",
            "[   48/  477 ( 12%)]  Loss: 0.3695\n",
            "[   96/  477 ( 25%)]  Loss: 0.0413\n",
            "[  144/  477 ( 38%)]  Loss: 1.0741\n",
            "[  192/  477 ( 50%)]  Loss: 0.3591\n",
            "[  240/  477 ( 62%)]  Loss: 0.1957\n",
            "[  288/  477 ( 75%)]  Loss: 0.4385\n",
            "[  336/  477 ( 88%)]  Loss: 0.6225\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0364  Accuracy:   47/  477 (9.85%)\n",
            "\n",
            "Epoch: 115\n",
            "[    0/  477 (  0%)]  Loss: 0.1428\n",
            "[   48/  477 ( 12%)]  Loss: 1.0827\n",
            "[   96/  477 ( 25%)]  Loss: 0.3007\n",
            "[  144/  477 ( 38%)]  Loss: 0.1516\n",
            "[  192/  477 ( 50%)]  Loss: 0.1018\n",
            "[  240/  477 ( 62%)]  Loss: 0.1028\n",
            "[  288/  477 ( 75%)]  Loss: 0.1524\n",
            "[  336/  477 ( 88%)]  Loss: 0.0370\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.0240  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 116\n",
            "[    0/  477 (  0%)]  Loss: 0.1051\n",
            "[   48/  477 ( 12%)]  Loss: 0.7077\n",
            "[   96/  477 ( 25%)]  Loss: 0.0254\n",
            "[  144/  477 ( 38%)]  Loss: 0.2120\n",
            "[  192/  477 ( 50%)]  Loss: 0.1659\n",
            "[  240/  477 ( 62%)]  Loss: 0.3185\n",
            "[  288/  477 ( 75%)]  Loss: 0.1855\n",
            "[  336/  477 ( 88%)]  Loss: 0.3175\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.1399  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 117\n",
            "[    0/  477 (  0%)]  Loss: 0.0669\n",
            "[   48/  477 ( 12%)]  Loss: 0.1517\n",
            "[   96/  477 ( 25%)]  Loss: 0.0160\n",
            "[  144/  477 ( 38%)]  Loss: 0.2292\n",
            "[  192/  477 ( 50%)]  Loss: 0.4129\n",
            "[  240/  477 ( 62%)]  Loss: 0.0595\n",
            "[  288/  477 ( 75%)]  Loss: 0.0419\n",
            "[  336/  477 ( 88%)]  Loss: 0.2262\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 1.2099  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 118\n",
            "[    0/  477 (  0%)]  Loss: 0.9414\n",
            "[   48/  477 ( 12%)]  Loss: 0.7654\n",
            "[   96/  477 ( 25%)]  Loss: 0.1988\n",
            "[  144/  477 ( 38%)]  Loss: 0.0141\n",
            "[  192/  477 ( 50%)]  Loss: 0.6964\n",
            "[  240/  477 ( 62%)]  Loss: 0.2785\n",
            "[  288/  477 ( 75%)]  Loss: 0.6095\n",
            "[  336/  477 ( 88%)]  Loss: 0.0983\n",
            "Execution time:  3.04 seconds\n",
            "\n",
            "Average test loss: 1.0551  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 119\n",
            "[    0/  477 (  0%)]  Loss: 0.2003\n",
            "[   48/  477 ( 12%)]  Loss: 0.1994\n",
            "[   96/  477 ( 25%)]  Loss: 0.1854\n",
            "[  144/  477 ( 38%)]  Loss: 0.6805\n",
            "[  192/  477 ( 50%)]  Loss: 0.2909\n",
            "[  240/  477 ( 62%)]  Loss: 0.0475\n",
            "[  288/  477 ( 75%)]  Loss: 0.3669\n",
            "[  336/  477 ( 88%)]  Loss: 0.1192\n",
            "Execution time:  3.03 seconds\n",
            "\n",
            "Average test loss: 1.0930  Accuracy:   44/  477 (9.22%)\n",
            "\n",
            "Epoch: 120\n",
            "[    0/  477 (  0%)]  Loss: 0.1620\n",
            "[   48/  477 ( 12%)]  Loss: 0.0229\n",
            "[   96/  477 ( 25%)]  Loss: 0.6834\n",
            "[  144/  477 ( 38%)]  Loss: 0.1515\n",
            "[  192/  477 ( 50%)]  Loss: 0.0316\n",
            "[  240/  477 ( 62%)]  Loss: 0.3988\n",
            "[  288/  477 ( 75%)]  Loss: 0.0458\n",
            "[  336/  477 ( 88%)]  Loss: 0.2275\n",
            "Execution time:  3.06 seconds\n",
            "\n",
            "Average test loss: 1.0699  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 121\n",
            "[    0/  477 (  0%)]  Loss: 0.2607\n",
            "[   48/  477 ( 12%)]  Loss: 0.2255\n",
            "[   96/  477 ( 25%)]  Loss: 0.3107\n",
            "[  144/  477 ( 38%)]  Loss: 0.0013\n",
            "[  192/  477 ( 50%)]  Loss: 0.0446\n",
            "[  240/  477 ( 62%)]  Loss: 0.1936\n",
            "[  288/  477 ( 75%)]  Loss: 0.6775\n",
            "[  336/  477 ( 88%)]  Loss: 0.3049\n",
            "Execution time:  2.99 seconds\n",
            "\n",
            "Average test loss: 1.1433  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 122\n",
            "[    0/  477 (  0%)]  Loss: 0.0073\n",
            "[   48/  477 ( 12%)]  Loss: 0.1468\n",
            "[   96/  477 ( 25%)]  Loss: 0.0318\n",
            "[  144/  477 ( 38%)]  Loss: 0.0720\n",
            "[  192/  477 ( 50%)]  Loss: 0.0808\n",
            "[  240/  477 ( 62%)]  Loss: 0.1562\n",
            "[  288/  477 ( 75%)]  Loss: 0.2907\n",
            "[  336/  477 ( 88%)]  Loss: 0.5076\n",
            "Execution time:  2.90 seconds\n",
            "\n",
            "Average test loss: 1.0949  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 123\n",
            "[    0/  477 (  0%)]  Loss: 0.7514\n",
            "[   48/  477 ( 12%)]  Loss: 0.2173\n",
            "[   96/  477 ( 25%)]  Loss: 0.0319\n",
            "[  144/  477 ( 38%)]  Loss: 0.0415\n",
            "[  192/  477 ( 50%)]  Loss: 0.3028\n",
            "[  240/  477 ( 62%)]  Loss: 0.0701\n",
            "[  288/  477 ( 75%)]  Loss: 0.0809\n",
            "[  336/  477 ( 88%)]  Loss: 0.4674\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 1.1950  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 124\n",
            "[    0/  477 (  0%)]  Loss: 0.0737\n",
            "[   48/  477 ( 12%)]  Loss: 0.0467\n",
            "[   96/  477 ( 25%)]  Loss: 0.1444\n",
            "[  144/  477 ( 38%)]  Loss: 0.1804\n",
            "[  192/  477 ( 50%)]  Loss: 0.3894\n",
            "[  240/  477 ( 62%)]  Loss: 0.0892\n",
            "[  288/  477 ( 75%)]  Loss: 0.1227\n",
            "[  336/  477 ( 88%)]  Loss: 0.3315\n",
            "Execution time:  3.02 seconds\n",
            "\n",
            "Average test loss: 1.1421  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 125\n",
            "[    0/  477 (  0%)]  Loss: 0.2869\n",
            "[   48/  477 ( 12%)]  Loss: 0.0585\n",
            "[   96/  477 ( 25%)]  Loss: 0.3088\n",
            "[  144/  477 ( 38%)]  Loss: 0.1998\n",
            "[  192/  477 ( 50%)]  Loss: 0.5571\n",
            "[  240/  477 ( 62%)]  Loss: 0.3849\n",
            "[  288/  477 ( 75%)]  Loss: 0.6859\n",
            "[  336/  477 ( 88%)]  Loss: 0.0381\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1465  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 126\n",
            "[    0/  477 (  0%)]  Loss: 0.0233\n",
            "[   48/  477 ( 12%)]  Loss: 0.4673\n",
            "[   96/  477 ( 25%)]  Loss: 0.3647\n",
            "[  144/  477 ( 38%)]  Loss: 0.2442\n",
            "[  192/  477 ( 50%)]  Loss: 0.0512\n",
            "[  240/  477 ( 62%)]  Loss: 0.0598\n",
            "[  288/  477 ( 75%)]  Loss: 0.0872\n",
            "[  336/  477 ( 88%)]  Loss: 0.1953\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.1388  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 127\n",
            "[    0/  477 (  0%)]  Loss: 0.5362\n",
            "[   48/  477 ( 12%)]  Loss: 0.0063\n",
            "[   96/  477 ( 25%)]  Loss: 0.1625\n",
            "[  144/  477 ( 38%)]  Loss: 0.0236\n",
            "[  192/  477 ( 50%)]  Loss: 0.0116\n",
            "[  240/  477 ( 62%)]  Loss: 0.3235\n",
            "[  288/  477 ( 75%)]  Loss: 0.0320\n",
            "[  336/  477 ( 88%)]  Loss: 0.3050\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.1623  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 128\n",
            "[    0/  477 (  0%)]  Loss: 0.0461\n",
            "[   48/  477 ( 12%)]  Loss: 0.5578\n",
            "[   96/  477 ( 25%)]  Loss: 0.0674\n",
            "[  144/  477 ( 38%)]  Loss: 0.2501\n",
            "[  192/  477 ( 50%)]  Loss: 0.2006\n",
            "[  240/  477 ( 62%)]  Loss: 0.0356\n",
            "[  288/  477 ( 75%)]  Loss: 0.0523\n",
            "[  336/  477 ( 88%)]  Loss: 0.4648\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 1.1626  Accuracy:   55/  477 (11.53%)\n",
            "\n",
            "Epoch: 129\n",
            "[    0/  477 (  0%)]  Loss: 0.2241\n",
            "[   48/  477 ( 12%)]  Loss: 0.2495\n",
            "[   96/  477 ( 25%)]  Loss: 0.1592\n",
            "[  144/  477 ( 38%)]  Loss: 0.6160\n",
            "[  192/  477 ( 50%)]  Loss: 0.5062\n",
            "[  240/  477 ( 62%)]  Loss: 0.9770\n",
            "[  288/  477 ( 75%)]  Loss: 0.2364\n",
            "[  336/  477 ( 88%)]  Loss: 0.0782\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.1904  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 130\n",
            "[    0/  477 (  0%)]  Loss: 0.4137\n",
            "[   48/  477 ( 12%)]  Loss: 0.1589\n",
            "[   96/  477 ( 25%)]  Loss: 0.0861\n",
            "[  144/  477 ( 38%)]  Loss: 0.1194\n",
            "[  192/  477 ( 50%)]  Loss: 0.5764\n",
            "[  240/  477 ( 62%)]  Loss: 0.1959\n",
            "[  288/  477 ( 75%)]  Loss: 0.0599\n",
            "[  336/  477 ( 88%)]  Loss: 0.2991\n",
            "Execution time:  2.92 seconds\n",
            "\n",
            "Average test loss: 1.1266  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 131\n",
            "[    0/  477 (  0%)]  Loss: 0.0575\n",
            "[   48/  477 ( 12%)]  Loss: 1.4645\n",
            "[   96/  477 ( 25%)]  Loss: 0.2780\n",
            "[  144/  477 ( 38%)]  Loss: 0.3750\n",
            "[  192/  477 ( 50%)]  Loss: 0.0589\n",
            "[  240/  477 ( 62%)]  Loss: 0.0730\n",
            "[  288/  477 ( 75%)]  Loss: 0.8620\n",
            "[  336/  477 ( 88%)]  Loss: 0.3639\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.2761  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 132\n",
            "[    0/  477 (  0%)]  Loss: 0.3273\n",
            "[   48/  477 ( 12%)]  Loss: 0.0866\n",
            "[   96/  477 ( 25%)]  Loss: 0.8387\n",
            "[  144/  477 ( 38%)]  Loss: 0.2963\n",
            "[  192/  477 ( 50%)]  Loss: 0.2875\n",
            "[  240/  477 ( 62%)]  Loss: 0.3845\n",
            "[  288/  477 ( 75%)]  Loss: 0.6504\n",
            "[  336/  477 ( 88%)]  Loss: 0.0739\n",
            "Execution time:  3.00 seconds\n",
            "\n",
            "Average test loss: 1.1454  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 133\n",
            "[    0/  477 (  0%)]  Loss: 0.0264\n",
            "[   48/  477 ( 12%)]  Loss: 0.1227\n",
            "[   96/  477 ( 25%)]  Loss: 0.0516\n",
            "[  144/  477 ( 38%)]  Loss: 0.2619\n",
            "[  192/  477 ( 50%)]  Loss: 0.1448\n",
            "[  240/  477 ( 62%)]  Loss: 0.0086\n",
            "[  288/  477 ( 75%)]  Loss: 0.5783\n",
            "[  336/  477 ( 88%)]  Loss: 0.7869\n",
            "Execution time:  2.97 seconds\n",
            "\n",
            "Average test loss: 1.1241  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 134\n",
            "[    0/  477 (  0%)]  Loss: 0.0485\n",
            "[   48/  477 ( 12%)]  Loss: 0.0386\n",
            "[   96/  477 ( 25%)]  Loss: 0.1046\n",
            "[  144/  477 ( 38%)]  Loss: 0.0774\n",
            "[  192/  477 ( 50%)]  Loss: 0.0863\n",
            "[  240/  477 ( 62%)]  Loss: 0.1291\n",
            "[  288/  477 ( 75%)]  Loss: 0.0498\n",
            "[  336/  477 ( 88%)]  Loss: 0.6365\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.3391  Accuracy:   42/  477 (8.81%)\n",
            "\n",
            "Epoch: 135\n",
            "[    0/  477 (  0%)]  Loss: 0.5351\n",
            "[   48/  477 ( 12%)]  Loss: 0.2571\n",
            "[   96/  477 ( 25%)]  Loss: 1.4500\n",
            "[  144/  477 ( 38%)]  Loss: 0.2736\n",
            "[  192/  477 ( 50%)]  Loss: 1.0722\n",
            "[  240/  477 ( 62%)]  Loss: 0.8210\n",
            "[  288/  477 ( 75%)]  Loss: 0.3331\n",
            "[  336/  477 ( 88%)]  Loss: 0.6771\n",
            "Execution time:  2.95 seconds\n",
            "\n",
            "Average test loss: 1.2694  Accuracy:   50/  477 (10.48%)\n",
            "\n",
            "Epoch: 136\n",
            "[    0/  477 (  0%)]  Loss: 0.7556\n",
            "[   48/  477 ( 12%)]  Loss: 0.0806\n",
            "[   96/  477 ( 25%)]  Loss: 0.8138\n",
            "[  144/  477 ( 38%)]  Loss: 0.3350\n",
            "[  192/  477 ( 50%)]  Loss: 0.1155\n",
            "[  240/  477 ( 62%)]  Loss: 0.0145\n",
            "[  288/  477 ( 75%)]  Loss: 0.5990\n",
            "[  336/  477 ( 88%)]  Loss: 0.1663\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 0.9544  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 137\n",
            "[    0/  477 (  0%)]  Loss: 0.0162\n",
            "[   48/  477 ( 12%)]  Loss: 0.1879\n",
            "[   96/  477 ( 25%)]  Loss: 0.5750\n",
            "[  144/  477 ( 38%)]  Loss: 0.6552\n",
            "[  192/  477 ( 50%)]  Loss: 0.4309\n",
            "[  240/  477 ( 62%)]  Loss: 0.3056\n",
            "[  288/  477 ( 75%)]  Loss: 0.2936\n",
            "[  336/  477 ( 88%)]  Loss: 0.2014\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.2841  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 138\n",
            "[    0/  477 (  0%)]  Loss: 0.1374\n",
            "[   48/  477 ( 12%)]  Loss: 0.1121\n",
            "[   96/  477 ( 25%)]  Loss: 0.1712\n",
            "[  144/  477 ( 38%)]  Loss: 0.8569\n",
            "[  192/  477 ( 50%)]  Loss: 0.7283\n",
            "[  240/  477 ( 62%)]  Loss: 0.1976\n",
            "[  288/  477 ( 75%)]  Loss: 0.0872\n",
            "[  336/  477 ( 88%)]  Loss: 0.0831\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.0355  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 139\n",
            "[    0/  477 (  0%)]  Loss: 0.0639\n",
            "[   48/  477 ( 12%)]  Loss: 0.0353\n",
            "[   96/  477 ( 25%)]  Loss: 0.0401\n",
            "[  144/  477 ( 38%)]  Loss: 0.5180\n",
            "[  192/  477 ( 50%)]  Loss: 0.2519\n",
            "[  240/  477 ( 62%)]  Loss: 0.0947\n",
            "[  288/  477 ( 75%)]  Loss: 0.7719\n",
            "[  336/  477 ( 88%)]  Loss: 0.1094\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.2366  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Epoch: 140\n",
            "[    0/  477 (  0%)]  Loss: 0.5474\n",
            "[   48/  477 ( 12%)]  Loss: 0.2086\n",
            "[   96/  477 ( 25%)]  Loss: 0.0316\n",
            "[  144/  477 ( 38%)]  Loss: 0.0300\n",
            "[  192/  477 ( 50%)]  Loss: 0.4106\n",
            "[  240/  477 ( 62%)]  Loss: 0.0057\n",
            "[  288/  477 ( 75%)]  Loss: 0.1721\n",
            "[  336/  477 ( 88%)]  Loss: 0.2100\n",
            "Execution time:  3.05 seconds\n",
            "\n",
            "Average test loss: 1.1983  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 141\n",
            "[    0/  477 (  0%)]  Loss: 0.0103\n",
            "[   48/  477 ( 12%)]  Loss: 0.4101\n",
            "[   96/  477 ( 25%)]  Loss: 0.1409\n",
            "[  144/  477 ( 38%)]  Loss: 0.2451\n",
            "[  192/  477 ( 50%)]  Loss: 0.0931\n",
            "[  240/  477 ( 62%)]  Loss: 0.3964\n",
            "[  288/  477 ( 75%)]  Loss: 0.4065\n",
            "[  336/  477 ( 88%)]  Loss: 0.1972\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.1060  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 142\n",
            "[    0/  477 (  0%)]  Loss: 0.2113\n",
            "[   48/  477 ( 12%)]  Loss: 0.0058\n",
            "[   96/  477 ( 25%)]  Loss: 0.2631\n",
            "[  144/  477 ( 38%)]  Loss: 0.1725\n",
            "[  192/  477 ( 50%)]  Loss: 0.1406\n",
            "[  240/  477 ( 62%)]  Loss: 0.0715\n",
            "[  288/  477 ( 75%)]  Loss: 0.0244\n",
            "[  336/  477 ( 88%)]  Loss: 0.0124\n",
            "Execution time:  2.91 seconds\n",
            "\n",
            "Average test loss: 1.1082  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 143\n",
            "[    0/  477 (  0%)]  Loss: 0.0802\n",
            "[   48/  477 ( 12%)]  Loss: 0.0655\n",
            "[   96/  477 ( 25%)]  Loss: 0.0613\n",
            "[  144/  477 ( 38%)]  Loss: 0.2405\n",
            "[  192/  477 ( 50%)]  Loss: 0.0952\n",
            "[  240/  477 ( 62%)]  Loss: 0.0099\n",
            "[  288/  477 ( 75%)]  Loss: 0.2676\n",
            "[  336/  477 ( 88%)]  Loss: 0.4858\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.1425  Accuracy:   56/  477 (11.74%)\n",
            "\n",
            "Epoch: 144\n",
            "[    0/  477 (  0%)]  Loss: 0.4051\n",
            "[   48/  477 ( 12%)]  Loss: 0.0100\n",
            "[   96/  477 ( 25%)]  Loss: 0.1573\n",
            "[  144/  477 ( 38%)]  Loss: 0.0225\n",
            "[  192/  477 ( 50%)]  Loss: 0.2125\n",
            "[  240/  477 ( 62%)]  Loss: 0.0546\n",
            "[  288/  477 ( 75%)]  Loss: 0.0074\n",
            "[  336/  477 ( 88%)]  Loss: 0.0938\n",
            "Execution time:  2.98 seconds\n",
            "\n",
            "Average test loss: 1.2995  Accuracy:   52/  477 (10.90%)\n",
            "\n",
            "Epoch: 145\n",
            "[    0/  477 (  0%)]  Loss: 0.0902\n",
            "[   48/  477 ( 12%)]  Loss: 0.0580\n",
            "[   96/  477 ( 25%)]  Loss: 0.2540\n",
            "[  144/  477 ( 38%)]  Loss: 0.0608\n",
            "[  192/  477 ( 50%)]  Loss: 0.4403\n",
            "[  240/  477 ( 62%)]  Loss: 0.1515\n",
            "[  288/  477 ( 75%)]  Loss: 0.0546\n",
            "[  336/  477 ( 88%)]  Loss: 0.0206\n",
            "Execution time:  2.94 seconds\n",
            "\n",
            "Average test loss: 1.4081  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 146\n",
            "[    0/  477 (  0%)]  Loss: 0.2944\n",
            "[   48/  477 ( 12%)]  Loss: 0.4158\n",
            "[   96/  477 ( 25%)]  Loss: 0.4261\n",
            "[  144/  477 ( 38%)]  Loss: 0.0357\n",
            "[  192/  477 ( 50%)]  Loss: 0.2142\n",
            "[  240/  477 ( 62%)]  Loss: 0.0430\n",
            "[  288/  477 ( 75%)]  Loss: 0.2739\n",
            "[  336/  477 ( 88%)]  Loss: 0.9559\n",
            "Execution time:  2.93 seconds\n",
            "\n",
            "Average test loss: 1.3141  Accuracy:   53/  477 (11.11%)\n",
            "\n",
            "Epoch: 147\n",
            "[    0/  477 (  0%)]  Loss: 0.0550\n",
            "[   48/  477 ( 12%)]  Loss: 0.0976\n",
            "[   96/  477 ( 25%)]  Loss: 0.2482\n",
            "[  144/  477 ( 38%)]  Loss: 0.1956\n",
            "[  192/  477 ( 50%)]  Loss: 0.0269\n",
            "[  240/  477 ( 62%)]  Loss: 0.2407\n",
            "[  288/  477 ( 75%)]  Loss: 0.3382\n",
            "[  336/  477 ( 88%)]  Loss: 1.2882\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.2540  Accuracy:   48/  477 (10.06%)\n",
            "\n",
            "Epoch: 148\n",
            "[    0/  477 (  0%)]  Loss: 0.3539\n",
            "[   48/  477 ( 12%)]  Loss: 0.2347\n",
            "[   96/  477 ( 25%)]  Loss: 0.4177\n",
            "[  144/  477 ( 38%)]  Loss: 0.3102\n",
            "[  192/  477 ( 50%)]  Loss: 0.3298\n",
            "[  240/  477 ( 62%)]  Loss: 0.3714\n",
            "[  288/  477 ( 75%)]  Loss: 0.0137\n",
            "[  336/  477 ( 88%)]  Loss: 1.1428\n",
            "Execution time:  3.12 seconds\n",
            "\n",
            "Average test loss: 1.2419  Accuracy:   58/  477 (12.16%)\n",
            "\n",
            "Epoch: 149\n",
            "[    0/  477 (  0%)]  Loss: 0.0261\n",
            "[   48/  477 ( 12%)]  Loss: 0.4615\n",
            "[   96/  477 ( 25%)]  Loss: 0.0707\n",
            "[  144/  477 ( 38%)]  Loss: 0.1826\n",
            "[  192/  477 ( 50%)]  Loss: 0.7074\n",
            "[  240/  477 ( 62%)]  Loss: 0.0607\n",
            "[  288/  477 ( 75%)]  Loss: 0.0892\n",
            "[  336/  477 ( 88%)]  Loss: 1.1302\n",
            "Execution time:  3.01 seconds\n",
            "\n",
            "Average test loss: 1.1244  Accuracy:   54/  477 (11.32%)\n",
            "\n",
            "Epoch: 150\n",
            "[    0/  477 (  0%)]  Loss: 0.6668\n",
            "[   48/  477 ( 12%)]  Loss: 0.1231\n",
            "[   96/  477 ( 25%)]  Loss: 0.2349\n",
            "[  144/  477 ( 38%)]  Loss: 0.0314\n",
            "[  192/  477 ( 50%)]  Loss: 0.4497\n",
            "[  240/  477 ( 62%)]  Loss: 0.0801\n",
            "[  288/  477 ( 75%)]  Loss: 0.1404\n",
            "[  336/  477 ( 88%)]  Loss: 0.5085\n",
            "Execution time:  2.96 seconds\n",
            "\n",
            "Average test loss: 1.1728  Accuracy:   51/  477 (10.69%)\n",
            "\n",
            "Execution time\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}